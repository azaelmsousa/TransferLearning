{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorflow version: 1.12.0-rc0\n",
    "scikit-learn version: 0.17\n",
    "keras version: 2.2.4\n",
    "tensorboard version: 1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "In this assignment, we will use the weights of a network pre-trained in a particular problem as starting point to train our CNN to a different problem. As training a network from scratch is time-consuming and demands a lot of data, this is a frequent strategy, specially if both datasets (the one used for pre-training and the target) shares similar structures/elements/concepts. \n",
    "\n",
    "This is specially true when working with images. Most filters learned in initial convolutional layers will detect low-level elements, such as borders, corners and color blobs, which are common to most problems in the image domain. \n",
    "\n",
    "In this notebook, we will load the SqueezeNet architecture trained in the ImageNet dataset and fine-tune it to CIFAR-10.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.5/dist-packages (2.2.4)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (2.8.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.15.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (3.13)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.0.5)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.0.6)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.20.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "if (sklearn.__version__ == '0.20.0'):\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "else:\n",
    "    from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "#======================================\n",
    "# Global definitions\n",
    "#======================================\n",
    "n_epochs         = 100\n",
    "learning_rate    = 1e-4\n",
    "n_classes        = 10\n",
    "train_batch_size = 32\n",
    "val_batch_size   = 10\n",
    "    \n",
    "#Utility to plot\n",
    "def plotImages(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "        \n",
    "        \n",
    "def plotImage(img):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.imshow(np.uint8(img), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SqueezeNet definition\n",
    "These methods define our architecture and load the weights obtained using ImageNet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Module Definition\n",
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "#SqueezeNet model definition\n",
    "def SqueezeNet(input_shape):\n",
    "    img_input = Input(shape=input_shape) #placeholder\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(1000, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    # Download and load ImageNet weights\n",
    "    model.load_weights('./squeezenet_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The class are **airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val data. X:  (50000, 32, 32, 3) , Y:  (50000, 1)\n",
      "Test data. X:  (10000, 32, 32, 3) , Y:  (10000, 1)\n",
      "--- Splitting data into train and val\n",
      "Train data. X: (5, 40000, 32, 32, 3) Y: (5, 40000, 1)\n",
      "Val data. X: (5, 10000, 32, 32, 3) Y: (5, 10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "(trainVal_data, trainVal_label), (X_test, y_test) = cifar10.load_data()\n",
    "print(\"Train/Val data. X: \", trainVal_data.shape, \", Y: \", trainVal_label.shape)\n",
    "print(\"Test data. X: \", X_test.shape, \", Y: \", y_test.shape)\n",
    "\n",
    "# Normalizing the data\n",
    "trainVal_data = (trainVal_data / 127.5) - 1.\n",
    "X_test = (X_test  / 127.5) - 1.\n",
    "\n",
    "#=====================================\n",
    "# Prepare the data\n",
    "#=====================================\n",
    "\n",
    "#--- Dividing the data into training and validation\n",
    "folds = 5\n",
    "if (sklearn.__version__ == '0.20.0'):\n",
    "    sss = StratifiedShuffleSplit(folds, test_size=0.2, random_state=42)\n",
    "    sss = sss.split(trainVal_data,trainVal_label)\n",
    "else:\n",
    "    sss = StratifiedShuffleSplit(trainVal_label, folds, test_size=0.2, random_state=42)\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "for train_index, val_index in sss:\n",
    "    X_train.append(trainVal_data[train_index])\n",
    "    X_val.append(trainVal_data[val_index])\n",
    "    y_train.append(trainVal_label[train_index])\n",
    "    y_val.append(trainVal_label[val_index])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "    \n",
    "print(\"--- Splitting data into train and val\")\n",
    "print(\"Train data. X:\",X_train.shape,\"Y:\",y_train.shape)\n",
    "print(\"Val data. X:\",X_val.shape,\"Y:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cheking if the splits are balanced\n",
    "for i in range(folds):\n",
    "    hist = np.histogram(np.squeeze(y_train[i]))[0]\n",
    "    print(hist)    \n",
    "    plt.bar(hist,np.amax(hist),alpha=0.5)\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## SqueezeNet with frozen layers\n",
    "Our initial attempt will be to remove SqueezeNet's top layers --- responsible for the classification into ImageNet classes --- and train a new set of layers to our CIFAR-10 classes. We will also freeze the layers before `drop9`. Our architecture will be like this:\n",
    "\n",
    "<img src=\"frozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 10)     5130        drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 10)     0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 10)           0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 10)           0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 727,626\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 722,496\n",
      "__________________________________________________________________________________________________\n",
      "input_1 False\n",
      "conv1 False\n",
      "relu_conv1 False\n",
      "pool1 False\n",
      "fire2/squeeze1x1 False\n",
      "fire2/relu_squeeze1x1 False\n",
      "fire2/expand1x1 False\n",
      "fire2/expand3x3 False\n",
      "fire2/relu_expand1x1 False\n",
      "fire2/relu_expand3x3 False\n",
      "fire2/concat False\n",
      "fire3/squeeze1x1 False\n",
      "fire3/relu_squeeze1x1 False\n",
      "fire3/expand1x1 False\n",
      "fire3/expand3x3 False\n",
      "fire3/relu_expand1x1 False\n",
      "fire3/relu_expand3x3 False\n",
      "fire3/concat False\n",
      "pool3 False\n",
      "fire4/squeeze1x1 False\n",
      "fire4/relu_squeeze1x1 False\n",
      "fire4/expand1x1 False\n",
      "fire4/expand3x3 False\n",
      "fire4/relu_expand1x1 False\n",
      "fire4/relu_expand3x3 False\n",
      "fire4/concat False\n",
      "fire5/squeeze1x1 False\n",
      "fire5/relu_squeeze1x1 False\n",
      "fire5/expand1x1 False\n",
      "fire5/expand3x3 False\n",
      "fire5/relu_expand1x1 False\n",
      "fire5/relu_expand3x3 False\n",
      "fire5/concat False\n",
      "pool5 False\n",
      "fire6/squeeze1x1 False\n",
      "fire6/relu_squeeze1x1 False\n",
      "fire6/expand1x1 False\n",
      "fire6/expand3x3 False\n",
      "fire6/relu_expand1x1 False\n",
      "fire6/relu_expand3x3 False\n",
      "fire6/concat False\n",
      "fire7/squeeze1x1 False\n",
      "fire7/relu_squeeze1x1 False\n",
      "fire7/expand1x1 False\n",
      "fire7/expand3x3 False\n",
      "fire7/relu_expand1x1 False\n",
      "fire7/relu_expand3x3 False\n",
      "fire7/concat False\n",
      "fire8/squeeze1x1 False\n",
      "fire8/relu_squeeze1x1 False\n",
      "fire8/expand1x1 False\n",
      "fire8/expand3x3 False\n",
      "fire8/relu_expand1x1 False\n",
      "fire8/relu_expand3x3 False\n",
      "fire8/concat False\n",
      "fire9/squeeze1x1 False\n",
      "fire9/relu_squeeze1x1 False\n",
      "fire9/expand1x1 False\n",
      "fire9/expand3x3 False\n",
      "fire9/relu_expand1x1 False\n",
      "fire9/relu_expand3x3 False\n",
      "fire9/concat False\n",
      "drop9 False\n",
      "conv10 True\n",
      "relu_conv10 True\n",
      "global_average_pooling2d_2 True\n",
      "loss True\n"
     ]
    }
   ],
   "source": [
    "def get_squeezenet_ft():\n",
    "    #=====================================\n",
    "    # Freezing layers\n",
    "    #=====================================\n",
    "\n",
    "    squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "    #freeze layers\n",
    "    for layer in squeezeNetModel.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #=====================================\n",
    "    # Add new classification layers\n",
    "    #=====================================\n",
    "\n",
    "    #--- Removing layers until drop 9\n",
    "    squeezeNetModel.layers.pop() #Convolution2D\n",
    "    squeezeNetModel.layers.pop() #Activation ReLU\n",
    "    squeezeNetModel.layers.pop() #Global Avg Pool\n",
    "    squeezeNetModel.layers.pop() #Activation Softmax\n",
    "\n",
    "    #--- Adding classification layer for 10 classes\n",
    "    out = Convolution2D(n_classes, (1, 1), padding='valid', name='conv10')(squeezeNetModel.layers[-1].output)\n",
    "    out = Activation('relu', name='relu_conv10')(out)\n",
    "\n",
    "    out = GlobalAveragePooling2D()(out)\n",
    "    out = Activation('softmax', name='loss')(out)\n",
    "\n",
    "    #=====================================\n",
    "    # New Model\n",
    "    #=====================================\n",
    "    model = Model(squeezeNetModel.inputs, out, name='squeezenet_new')\n",
    "    #=====================================\n",
    "    # Compile model\n",
    "    #=====================================\n",
    "\n",
    "    #--- Compile the model\n",
    "    # It means to configure the model for training.\n",
    "    # Other types of optimizer:\n",
    "    #    optimizers.Adam(lr=learning_rate)\n",
    "    opt = optimizer=optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#SGD(lr=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model  = get_squeezenet_ft()\n",
    "model.summary()\n",
    "\n",
    "#--- Check the trainable status of the individual layers\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Split: 0\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 7s 165us/step - loss: 2.3011 - acc: 0.1310 - val_loss: 2.2523 - val_acc: 0.2311\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 6s 139us/step - loss: 2.2011 - acc: 0.2064 - val_loss: 2.0665 - val_acc: 0.3217\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 5s 135us/step - loss: 2.0892 - acc: 0.2584 - val_loss: 1.9691 - val_acc: 0.3593\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 2.0204 - acc: 0.2921 - val_loss: 1.9215 - val_acc: 0.3683\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.9528 - acc: 0.3071 - val_loss: 1.8487 - val_acc: 0.3812\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.9078 - acc: 0.3230 - val_loss: 1.8170 - val_acc: 0.3918\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.8794 - acc: 0.3308 - val_loss: 1.7931 - val_acc: 0.3960\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.8609 - acc: 0.3374 - val_loss: 1.7753 - val_acc: 0.3945\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.8464 - acc: 0.3415 - val_loss: 1.7612 - val_acc: 0.4030\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.8347 - acc: 0.3466 - val_loss: 1.7495 - val_acc: 0.4061\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.8253 - acc: 0.3465 - val_loss: 1.7400 - val_acc: 0.4053\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.8220 - acc: 0.3503 - val_loss: 1.7320 - val_acc: 0.4100\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.8160 - acc: 0.3554 - val_loss: 1.7248 - val_acc: 0.4063\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.8095 - acc: 0.3560 - val_loss: 1.7190 - val_acc: 0.4130\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.8064 - acc: 0.3571 - val_loss: 1.7130 - val_acc: 0.4110\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.8046 - acc: 0.3557 - val_loss: 1.7093 - val_acc: 0.4126\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.8001 - acc: 0.3563 - val_loss: 1.7045 - val_acc: 0.4163\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7983 - acc: 0.3566 - val_loss: 1.7016 - val_acc: 0.4158\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7923 - acc: 0.3603 - val_loss: 1.6976 - val_acc: 0.4157\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7904 - acc: 0.3605 - val_loss: 1.6942 - val_acc: 0.4147\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7917 - acc: 0.3618 - val_loss: 1.6920 - val_acc: 0.4181\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7855 - acc: 0.3663 - val_loss: 1.6891 - val_acc: 0.4169\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7845 - acc: 0.3571 - val_loss: 1.6869 - val_acc: 0.4188\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7815 - acc: 0.3640 - val_loss: 1.6841 - val_acc: 0.4190\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7848 - acc: 0.3634 - val_loss: 1.6824 - val_acc: 0.4162\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7826 - acc: 0.3662 - val_loss: 1.6810 - val_acc: 0.4221\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7794 - acc: 0.3609 - val_loss: 1.6783 - val_acc: 0.4221\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7778 - acc: 0.3636 - val_loss: 1.6768 - val_acc: 0.4204\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7750 - acc: 0.3658 - val_loss: 1.6747 - val_acc: 0.4198\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7777 - acc: 0.3635 - val_loss: 1.6740 - val_acc: 0.4195\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7737 - acc: 0.3673 - val_loss: 1.6720 - val_acc: 0.4216\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7696 - acc: 0.3663 - val_loss: 1.6713 - val_acc: 0.4189\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7731 - acc: 0.3646 - val_loss: 1.6709 - val_acc: 0.4199\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7716 - acc: 0.3682 - val_loss: 1.6683 - val_acc: 0.4198\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7707 - acc: 0.3630 - val_loss: 1.6670 - val_acc: 0.4202\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7770 - acc: 0.3639 - val_loss: 1.6666 - val_acc: 0.4198\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7685 - acc: 0.3645 - val_loss: 1.6658 - val_acc: 0.4211\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7701 - acc: 0.3692 - val_loss: 1.6640 - val_acc: 0.4224\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7682 - acc: 0.3662 - val_loss: 1.6628 - val_acc: 0.4236\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7652 - acc: 0.3723 - val_loss: 1.6627 - val_acc: 0.4233\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7664 - acc: 0.3675 - val_loss: 1.6619 - val_acc: 0.4205\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7612 - acc: 0.3700 - val_loss: 1.6608 - val_acc: 0.4230\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7660 - acc: 0.3650 - val_loss: 1.6599 - val_acc: 0.4245\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7623 - acc: 0.3690 - val_loss: 1.6587 - val_acc: 0.4214\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7624 - acc: 0.3714 - val_loss: 1.6582 - val_acc: 0.4216\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7630 - acc: 0.3682 - val_loss: 1.6572 - val_acc: 0.4249\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7602 - acc: 0.3714 - val_loss: 1.6569 - val_acc: 0.4240\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 6s 143us/step - loss: 1.7644 - acc: 0.3679 - val_loss: 1.6564 - val_acc: 0.4223\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 6s 143us/step - loss: 1.7591 - acc: 0.3690 - val_loss: 1.6556 - val_acc: 0.4240\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 6s 142us/step - loss: 1.7597 - acc: 0.3722 - val_loss: 1.6552 - val_acc: 0.4258\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7598 - acc: 0.3712 - val_loss: 1.6542 - val_acc: 0.4267\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 6s 143us/step - loss: 1.7599 - acc: 0.3678 - val_loss: 1.6533 - val_acc: 0.4230\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 6s 143us/step - loss: 1.7602 - acc: 0.3696 - val_loss: 1.6534 - val_acc: 0.4244\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 6s 143us/step - loss: 1.7606 - acc: 0.3683 - val_loss: 1.6526 - val_acc: 0.4236\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 6s 143us/step - loss: 1.7604 - acc: 0.3719 - val_loss: 1.6530 - val_acc: 0.4259\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 6s 142us/step - loss: 1.7582 - acc: 0.3705 - val_loss: 1.6526 - val_acc: 0.4271\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7589 - acc: 0.3706 - val_loss: 1.6514 - val_acc: 0.4245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 6s 142us/step - loss: 1.7575 - acc: 0.3709 - val_loss: 1.6510 - val_acc: 0.4252\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 6s 142us/step - loss: 1.7572 - acc: 0.3715 - val_loss: 1.6507 - val_acc: 0.4266\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7591 - acc: 0.3717 - val_loss: 1.6495 - val_acc: 0.4252\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7535 - acc: 0.3707 - val_loss: 1.6497 - val_acc: 0.4274\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7555 - acc: 0.3703 - val_loss: 1.6487 - val_acc: 0.4265\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7571 - acc: 0.3740 - val_loss: 1.6486 - val_acc: 0.4261\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7571 - acc: 0.3710 - val_loss: 1.6489 - val_acc: 0.4260\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7560 - acc: 0.3733 - val_loss: 1.6483 - val_acc: 0.4267\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7587 - acc: 0.3695 - val_loss: 1.6481 - val_acc: 0.4235\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 6s 142us/step - loss: 1.7581 - acc: 0.3694 - val_loss: 1.6477 - val_acc: 0.4257\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7574 - acc: 0.3722 - val_loss: 1.6471 - val_acc: 0.4267\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7563 - acc: 0.3720 - val_loss: 1.6471 - val_acc: 0.4263\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7547 - acc: 0.3700 - val_loss: 1.6469 - val_acc: 0.4258\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7586 - acc: 0.3700 - val_loss: 1.6471 - val_acc: 0.4247\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7528 - acc: 0.3733 - val_loss: 1.6458 - val_acc: 0.4259\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.7544 - acc: 0.3693 - val_loss: 1.6460 - val_acc: 0.4269\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7536 - acc: 0.3711 - val_loss: 1.6465 - val_acc: 0.4269\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7513 - acc: 0.3724 - val_loss: 1.6447 - val_acc: 0.4263\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7533 - acc: 0.3727 - val_loss: 1.6446 - val_acc: 0.4262\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7548 - acc: 0.3741 - val_loss: 1.6443 - val_acc: 0.4252\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7542 - acc: 0.3714 - val_loss: 1.6444 - val_acc: 0.4266\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7505 - acc: 0.3743 - val_loss: 1.6440 - val_acc: 0.4259\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7538 - acc: 0.3722 - val_loss: 1.6434 - val_acc: 0.4312\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7503 - acc: 0.3706 - val_loss: 1.6433 - val_acc: 0.4285\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7541 - acc: 0.3715 - val_loss: 1.6426 - val_acc: 0.4271\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7526 - acc: 0.3719 - val_loss: 1.6431 - val_acc: 0.4254\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7512 - acc: 0.3740 - val_loss: 1.6427 - val_acc: 0.4274\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7519 - acc: 0.3735 - val_loss: 1.6422 - val_acc: 0.4274\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 6s 143us/step - loss: 1.7497 - acc: 0.3716 - val_loss: 1.6422 - val_acc: 0.4259\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7506 - acc: 0.3708 - val_loss: 1.6420 - val_acc: 0.4267\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7515 - acc: 0.3688 - val_loss: 1.6420 - val_acc: 0.4294\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7489 - acc: 0.3723 - val_loss: 1.6411 - val_acc: 0.4265\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7534 - acc: 0.3730 - val_loss: 1.6409 - val_acc: 0.4283\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7545 - acc: 0.3710 - val_loss: 1.6412 - val_acc: 0.4278\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 6s 143us/step - loss: 1.7521 - acc: 0.3704 - val_loss: 1.6407 - val_acc: 0.4278\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 6s 143us/step - loss: 1.7492 - acc: 0.3729 - val_loss: 1.6412 - val_acc: 0.4304\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7520 - acc: 0.3732 - val_loss: 1.6409 - val_acc: 0.4281\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7475 - acc: 0.3736 - val_loss: 1.6397 - val_acc: 0.4284\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.7508 - acc: 0.3727 - val_loss: 1.6405 - val_acc: 0.4268\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7515 - acc: 0.3713 - val_loss: 1.6388 - val_acc: 0.4282\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.7515 - acc: 0.3717 - val_loss: 1.6390 - val_acc: 0.4286\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7518 - acc: 0.3700 - val_loss: 1.6391 - val_acc: 0.4279\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7509 - acc: 0.3738 - val_loss: 1.6391 - val_acc: 0.4277\n",
      "10000/10000 [==============================] - 3s 254us/step\n",
      "Validation loss: 1.639105289697647\n",
      "Validation accuracy (NORMALIZED): 0.4277000068128109\n",
      "================================================\n",
      "Split: 1\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 2.3072 - acc: 0.1323 - val_loss: 2.2351 - val_acc: 0.2445\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 2.2019 - acc: 0.2103 - val_loss: 2.0814 - val_acc: 0.3090\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 2.0735 - acc: 0.2624 - val_loss: 1.9349 - val_acc: 0.3603\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 7s 166us/step - loss: 1.9806 - acc: 0.2940 - val_loss: 1.8736 - val_acc: 0.3745\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.9276 - acc: 0.3112 - val_loss: 1.8355 - val_acc: 0.3821\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.8934 - acc: 0.3235 - val_loss: 1.8089 - val_acc: 0.3866\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.8734 - acc: 0.3297 - val_loss: 1.7895 - val_acc: 0.3973\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.8545 - acc: 0.3403 - val_loss: 1.7736 - val_acc: 0.3978\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.8464 - acc: 0.3424 - val_loss: 1.7609 - val_acc: 0.4015\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 1.8326 - acc: 0.3424 - val_loss: 1.7500 - val_acc: 0.4059\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.8266 - acc: 0.3468 - val_loss: 1.7413 - val_acc: 0.4075\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.8192 - acc: 0.3533 - val_loss: 1.7337 - val_acc: 0.4093\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.8121 - acc: 0.3556 - val_loss: 1.7271 - val_acc: 0.4098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.8096 - acc: 0.3555 - val_loss: 1.7216 - val_acc: 0.4108\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.8060 - acc: 0.3547 - val_loss: 1.7168 - val_acc: 0.4123\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.8015 - acc: 0.3568 - val_loss: 1.7121 - val_acc: 0.4111\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7968 - acc: 0.3600 - val_loss: 1.7073 - val_acc: 0.4156\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7957 - acc: 0.3594 - val_loss: 1.7045 - val_acc: 0.4139\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7937 - acc: 0.3630 - val_loss: 1.7011 - val_acc: 0.4145\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7895 - acc: 0.3611 - val_loss: 1.6979 - val_acc: 0.4148\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7877 - acc: 0.3620 - val_loss: 1.6955 - val_acc: 0.4170\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7816 - acc: 0.3662 - val_loss: 1.6932 - val_acc: 0.4151\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7850 - acc: 0.3619 - val_loss: 1.6909 - val_acc: 0.4187\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7802 - acc: 0.3639 - val_loss: 1.6880 - val_acc: 0.4181\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7820 - acc: 0.3625 - val_loss: 1.6864 - val_acc: 0.4190\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7777 - acc: 0.3610 - val_loss: 1.6849 - val_acc: 0.4183\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7779 - acc: 0.3634 - val_loss: 1.6830 - val_acc: 0.4206\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7784 - acc: 0.3651 - val_loss: 1.6816 - val_acc: 0.4206\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7720 - acc: 0.3669 - val_loss: 1.6802 - val_acc: 0.4185\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7754 - acc: 0.3655 - val_loss: 1.6783 - val_acc: 0.4223\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7711 - acc: 0.3636 - val_loss: 1.6774 - val_acc: 0.4209\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7721 - acc: 0.3641 - val_loss: 1.6759 - val_acc: 0.4218\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7720 - acc: 0.3656 - val_loss: 1.6746 - val_acc: 0.4213\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7723 - acc: 0.3638 - val_loss: 1.6737 - val_acc: 0.4227\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7626 - acc: 0.3660 - val_loss: 1.6719 - val_acc: 0.4208\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7699 - acc: 0.3669 - val_loss: 1.6710 - val_acc: 0.4231\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7699 - acc: 0.3676 - val_loss: 1.6704 - val_acc: 0.4233\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7685 - acc: 0.3690 - val_loss: 1.6701 - val_acc: 0.4248\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7653 - acc: 0.3673 - val_loss: 1.6686 - val_acc: 0.4231\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7683 - acc: 0.3674 - val_loss: 1.6680 - val_acc: 0.4238\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7635 - acc: 0.3682 - val_loss: 1.6666 - val_acc: 0.4256\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7640 - acc: 0.3682 - val_loss: 1.6660 - val_acc: 0.4242\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7645 - acc: 0.3678 - val_loss: 1.6657 - val_acc: 0.4243\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7609 - acc: 0.3685 - val_loss: 1.6650 - val_acc: 0.4222\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7689 - acc: 0.3645 - val_loss: 1.6653 - val_acc: 0.4252\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7664 - acc: 0.3690 - val_loss: 1.6636 - val_acc: 0.4234\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7621 - acc: 0.3712 - val_loss: 1.6629 - val_acc: 0.4245\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7613 - acc: 0.3678 - val_loss: 1.6623 - val_acc: 0.4243\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7607 - acc: 0.3690 - val_loss: 1.6613 - val_acc: 0.4262\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7567 - acc: 0.3699 - val_loss: 1.6600 - val_acc: 0.4274\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7625 - acc: 0.3693 - val_loss: 1.6613 - val_acc: 0.4219\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7605 - acc: 0.3692 - val_loss: 1.6600 - val_acc: 0.4231\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7590 - acc: 0.3722 - val_loss: 1.6597 - val_acc: 0.4249\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7593 - acc: 0.3705 - val_loss: 1.6585 - val_acc: 0.4271\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7571 - acc: 0.3682 - val_loss: 1.6585 - val_acc: 0.4250\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7565 - acc: 0.3704 - val_loss: 1.6584 - val_acc: 0.4263\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7551 - acc: 0.3715 - val_loss: 1.6572 - val_acc: 0.4240\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7597 - acc: 0.3699 - val_loss: 1.6571 - val_acc: 0.4252\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7564 - acc: 0.3713 - val_loss: 1.6563 - val_acc: 0.4268\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7530 - acc: 0.3736 - val_loss: 1.6556 - val_acc: 0.4280\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7572 - acc: 0.3728 - val_loss: 1.6553 - val_acc: 0.4275\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7535 - acc: 0.3728 - val_loss: 1.6554 - val_acc: 0.4268\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7536 - acc: 0.3718 - val_loss: 1.6543 - val_acc: 0.4279\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7568 - acc: 0.3709 - val_loss: 1.6544 - val_acc: 0.4254\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7575 - acc: 0.3705 - val_loss: 1.6537 - val_acc: 0.4276\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7561 - acc: 0.3725 - val_loss: 1.6542 - val_acc: 0.4273\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7544 - acc: 0.3712 - val_loss: 1.6532 - val_acc: 0.4280\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7518 - acc: 0.3709 - val_loss: 1.6530 - val_acc: 0.4277\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7522 - acc: 0.3717 - val_loss: 1.6529 - val_acc: 0.4265\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7516 - acc: 0.3720 - val_loss: 1.6522 - val_acc: 0.4276\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7503 - acc: 0.3729 - val_loss: 1.6521 - val_acc: 0.4256\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7551 - acc: 0.3725 - val_loss: 1.6518 - val_acc: 0.4287\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 1.7533 - acc: 0.3731 - val_loss: 1.6518 - val_acc: 0.4263\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7562 - acc: 0.3719 - val_loss: 1.6514 - val_acc: 0.4260\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7550 - acc: 0.3727 - val_loss: 1.6511 - val_acc: 0.4264\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7518 - acc: 0.3716 - val_loss: 1.6515 - val_acc: 0.4281\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7509 - acc: 0.3716 - val_loss: 1.6515 - val_acc: 0.4276\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7497 - acc: 0.3716 - val_loss: 1.6501 - val_acc: 0.4307\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7513 - acc: 0.3723 - val_loss: 1.6495 - val_acc: 0.4304\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7516 - acc: 0.3744 - val_loss: 1.6497 - val_acc: 0.4275\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7499 - acc: 0.3742 - val_loss: 1.6492 - val_acc: 0.4297\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7513 - acc: 0.3727 - val_loss: 1.6499 - val_acc: 0.4301\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7483 - acc: 0.3732 - val_loss: 1.6491 - val_acc: 0.4275\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7478 - acc: 0.3752 - val_loss: 1.6484 - val_acc: 0.4276\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7485 - acc: 0.3745 - val_loss: 1.6486 - val_acc: 0.4270\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7494 - acc: 0.3737 - val_loss: 1.6483 - val_acc: 0.4298\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7466 - acc: 0.3773 - val_loss: 1.6488 - val_acc: 0.4268\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7475 - acc: 0.3731 - val_loss: 1.6478 - val_acc: 0.4300\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7468 - acc: 0.3744 - val_loss: 1.6478 - val_acc: 0.4293\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7474 - acc: 0.3751 - val_loss: 1.6476 - val_acc: 0.4268\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7469 - acc: 0.3737 - val_loss: 1.6473 - val_acc: 0.4282\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7454 - acc: 0.3749 - val_loss: 1.6473 - val_acc: 0.4274\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7483 - acc: 0.3749 - val_loss: 1.6474 - val_acc: 0.4292\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7469 - acc: 0.3712 - val_loss: 1.6471 - val_acc: 0.4249\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7537 - acc: 0.3743 - val_loss: 1.6469 - val_acc: 0.4285\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7494 - acc: 0.3727 - val_loss: 1.6467 - val_acc: 0.4300\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7451 - acc: 0.3755 - val_loss: 1.6464 - val_acc: 0.4281\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7487 - acc: 0.3748 - val_loss: 1.6463 - val_acc: 0.4309\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7475 - acc: 0.3744 - val_loss: 1.6458 - val_acc: 0.4285\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7446 - acc: 0.3777 - val_loss: 1.6465 - val_acc: 0.4277\n",
      "10000/10000 [==============================] - 2s 248us/step\n",
      "Validation loss: 1.6465386847257615\n",
      "Validation accuracy (NORMALIZED): 0.42770000714808704\n",
      "================================================\n",
      "Split: 2\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 2.3051 - acc: 0.1384 - val_loss: 2.2377 - val_acc: 0.2439\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 2.2141 - acc: 0.2001 - val_loss: 2.1085 - val_acc: 0.2894\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 2.1238 - acc: 0.2430 - val_loss: 1.9662 - val_acc: 0.3571\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 2.0091 - acc: 0.2797 - val_loss: 1.8805 - val_acc: 0.3784\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.9440 - acc: 0.3089 - val_loss: 1.8352 - val_acc: 0.3907\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.9075 - acc: 0.3210 - val_loss: 1.8048 - val_acc: 0.3900\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.8812 - acc: 0.3318 - val_loss: 1.7817 - val_acc: 0.3965\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.8606 - acc: 0.3380 - val_loss: 1.7645 - val_acc: 0.4037\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.8472 - acc: 0.3442 - val_loss: 1.7500 - val_acc: 0.4030\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.8417 - acc: 0.3436 - val_loss: 1.7388 - val_acc: 0.4042\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.8315 - acc: 0.3465 - val_loss: 1.7293 - val_acc: 0.4052\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.8255 - acc: 0.3497 - val_loss: 1.7212 - val_acc: 0.4084\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.8165 - acc: 0.3509 - val_loss: 1.7142 - val_acc: 0.4125\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.8136 - acc: 0.3532 - val_loss: 1.7085 - val_acc: 0.4144\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.8142 - acc: 0.3510 - val_loss: 1.7035 - val_acc: 0.4127\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.8032 - acc: 0.3550 - val_loss: 1.6984 - val_acc: 0.4162\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.8063 - acc: 0.3589 - val_loss: 1.6949 - val_acc: 0.4130\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7961 - acc: 0.3623 - val_loss: 1.6900 - val_acc: 0.4164\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7987 - acc: 0.3571 - val_loss: 1.6871 - val_acc: 0.4191\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7903 - acc: 0.3640 - val_loss: 1.6832 - val_acc: 0.4174\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7913 - acc: 0.3604 - val_loss: 1.6808 - val_acc: 0.4188\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7898 - acc: 0.3611 - val_loss: 1.6785 - val_acc: 0.4174\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7891 - acc: 0.3598 - val_loss: 1.6757 - val_acc: 0.4178\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7859 - acc: 0.3603 - val_loss: 1.6738 - val_acc: 0.4211\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7863 - acc: 0.3639 - val_loss: 1.6709 - val_acc: 0.4250\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7835 - acc: 0.3645 - val_loss: 1.6691 - val_acc: 0.4214\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7812 - acc: 0.3605 - val_loss: 1.6672 - val_acc: 0.4245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7797 - acc: 0.3623 - val_loss: 1.6658 - val_acc: 0.4247\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 7s 177us/step - loss: 1.7792 - acc: 0.3651 - val_loss: 1.6641 - val_acc: 0.4254\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 1.7802 - acc: 0.3653 - val_loss: 1.6623 - val_acc: 0.4248\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7769 - acc: 0.3667 - val_loss: 1.6615 - val_acc: 0.4251\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7775 - acc: 0.3634 - val_loss: 1.6601 - val_acc: 0.4242\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7715 - acc: 0.3681 - val_loss: 1.6582 - val_acc: 0.4257\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7768 - acc: 0.3652 - val_loss: 1.6574 - val_acc: 0.4252\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7758 - acc: 0.3662 - val_loss: 1.6562 - val_acc: 0.4245\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7766 - acc: 0.3643 - val_loss: 1.6551 - val_acc: 0.4239\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7707 - acc: 0.3655 - val_loss: 1.6544 - val_acc: 0.4259\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7707 - acc: 0.3686 - val_loss: 1.6535 - val_acc: 0.4264\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7681 - acc: 0.3687 - val_loss: 1.6528 - val_acc: 0.4248\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7715 - acc: 0.3657 - val_loss: 1.6520 - val_acc: 0.4273\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.7704 - acc: 0.3664 - val_loss: 1.6508 - val_acc: 0.4280\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 7s 170us/step - loss: 1.7691 - acc: 0.3640 - val_loss: 1.6510 - val_acc: 0.4248\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7667 - acc: 0.3687 - val_loss: 1.6494 - val_acc: 0.4289\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7694 - acc: 0.3660 - val_loss: 1.6482 - val_acc: 0.4288\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7663 - acc: 0.3678 - val_loss: 1.6476 - val_acc: 0.4289\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7640 - acc: 0.3691 - val_loss: 1.6473 - val_acc: 0.4271\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7632 - acc: 0.3706 - val_loss: 1.6460 - val_acc: 0.4286\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 1.7660 - acc: 0.3673 - val_loss: 1.6457 - val_acc: 0.4296\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 1.7631 - acc: 0.3705 - val_loss: 1.6449 - val_acc: 0.4315\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7657 - acc: 0.3681 - val_loss: 1.6440 - val_acc: 0.4299\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7634 - acc: 0.3698 - val_loss: 1.6434 - val_acc: 0.4301\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.7670 - acc: 0.3659 - val_loss: 1.6430 - val_acc: 0.4296\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7605 - acc: 0.3711 - val_loss: 1.6422 - val_acc: 0.4296\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.7635 - acc: 0.3662 - val_loss: 1.6416 - val_acc: 0.4311\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.7599 - acc: 0.3724 - val_loss: 1.6410 - val_acc: 0.4311\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7643 - acc: 0.3719 - val_loss: 1.6414 - val_acc: 0.4269\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7630 - acc: 0.3715 - val_loss: 1.6404 - val_acc: 0.4307\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7605 - acc: 0.3686 - val_loss: 1.6401 - val_acc: 0.4294\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7629 - acc: 0.3699 - val_loss: 1.6399 - val_acc: 0.4310\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7583 - acc: 0.3703 - val_loss: 1.6390 - val_acc: 0.4317\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7587 - acc: 0.3708 - val_loss: 1.6388 - val_acc: 0.4329\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7605 - acc: 0.3669 - val_loss: 1.6381 - val_acc: 0.4311\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7564 - acc: 0.3712 - val_loss: 1.6378 - val_acc: 0.4297\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7629 - acc: 0.3680 - val_loss: 1.6379 - val_acc: 0.4277\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7561 - acc: 0.3700 - val_loss: 1.6369 - val_acc: 0.4307\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7575 - acc: 0.3686 - val_loss: 1.6366 - val_acc: 0.4320\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7598 - acc: 0.3725 - val_loss: 1.6363 - val_acc: 0.4323\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7579 - acc: 0.3696 - val_loss: 1.6360 - val_acc: 0.4318\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7575 - acc: 0.3696 - val_loss: 1.6357 - val_acc: 0.4315\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7567 - acc: 0.3712 - val_loss: 1.6358 - val_acc: 0.4309\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7537 - acc: 0.3726 - val_loss: 1.6354 - val_acc: 0.4305\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 1.7574 - acc: 0.3704 - val_loss: 1.6352 - val_acc: 0.4318\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7607 - acc: 0.3699 - val_loss: 1.6356 - val_acc: 0.4325\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.7564 - acc: 0.3701 - val_loss: 1.6349 - val_acc: 0.4311\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.7536 - acc: 0.3726 - val_loss: 1.6340 - val_acc: 0.4305\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 7s 166us/step - loss: 1.7546 - acc: 0.3706 - val_loss: 1.6335 - val_acc: 0.4335\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 1.7538 - acc: 0.3750 - val_loss: 1.6332 - val_acc: 0.4316\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7554 - acc: 0.3733 - val_loss: 1.6331 - val_acc: 0.4301\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7553 - acc: 0.3735 - val_loss: 1.6329 - val_acc: 0.4322\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7534 - acc: 0.3715 - val_loss: 1.6327 - val_acc: 0.4320\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7542 - acc: 0.3755 - val_loss: 1.6325 - val_acc: 0.4324\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7511 - acc: 0.3736 - val_loss: 1.6318 - val_acc: 0.4324\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7554 - acc: 0.3756 - val_loss: 1.6318 - val_acc: 0.4326\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7566 - acc: 0.3706 - val_loss: 1.6318 - val_acc: 0.4293\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.7544 - acc: 0.3721 - val_loss: 1.6312 - val_acc: 0.4337\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7550 - acc: 0.3735 - val_loss: 1.6310 - val_acc: 0.4325\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7542 - acc: 0.3715 - val_loss: 1.6311 - val_acc: 0.4345\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7486 - acc: 0.3754 - val_loss: 1.6308 - val_acc: 0.4287\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 6s 149us/step - loss: 1.7520 - acc: 0.3730 - val_loss: 1.6302 - val_acc: 0.4340\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7551 - acc: 0.3731 - val_loss: 1.6303 - val_acc: 0.4328\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7490 - acc: 0.3721 - val_loss: 1.6305 - val_acc: 0.4301\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7570 - acc: 0.3721 - val_loss: 1.6302 - val_acc: 0.4314\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7546 - acc: 0.3728 - val_loss: 1.6297 - val_acc: 0.4335\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7499 - acc: 0.3748 - val_loss: 1.6293 - val_acc: 0.4343\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7544 - acc: 0.3742 - val_loss: 1.6291 - val_acc: 0.4328\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 6s 150us/step - loss: 1.7538 - acc: 0.3702 - val_loss: 1.6289 - val_acc: 0.4323\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7491 - acc: 0.3740 - val_loss: 1.6288 - val_acc: 0.4327\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.7525 - acc: 0.3715 - val_loss: 1.6292 - val_acc: 0.4314\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7466 - acc: 0.3737 - val_loss: 1.6288 - val_acc: 0.4329\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7476 - acc: 0.3747 - val_loss: 1.6285 - val_acc: 0.4322\n",
      "10000/10000 [==============================] - 2s 244us/step\n",
      "Validation loss: 1.6285417018532753\n",
      "Validation accuracy (NORMALIZED): 0.43220000743865966\n",
      "================================================\n",
      "Split: 3\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 7s 179us/step - loss: 2.2960 - acc: 0.1405 - val_loss: 2.2301 - val_acc: 0.2444\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 2.1977 - acc: 0.2121 - val_loss: 2.0638 - val_acc: 0.3044\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 2.0799 - acc: 0.2601 - val_loss: 1.9351 - val_acc: 0.3513\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.9887 - acc: 0.2880 - val_loss: 1.8712 - val_acc: 0.3753\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.9332 - acc: 0.3082 - val_loss: 1.8337 - val_acc: 0.3828\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.9027 - acc: 0.3214 - val_loss: 1.8046 - val_acc: 0.3917\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.8756 - acc: 0.3303 - val_loss: 1.7837 - val_acc: 0.3966\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.8619 - acc: 0.3382 - val_loss: 1.7677 - val_acc: 0.3959\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.8472 - acc: 0.3395 - val_loss: 1.7546 - val_acc: 0.4021\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.8356 - acc: 0.3447 - val_loss: 1.7438 - val_acc: 0.4055\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 7s 174us/step - loss: 1.8291 - acc: 0.3487 - val_loss: 1.7347 - val_acc: 0.4022\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.8226 - acc: 0.3501 - val_loss: 1.7271 - val_acc: 0.4073\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 7s 168us/step - loss: 1.8177 - acc: 0.3512 - val_loss: 1.7203 - val_acc: 0.4106\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.8118 - acc: 0.3494 - val_loss: 1.7148 - val_acc: 0.4087\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.8101 - acc: 0.3533 - val_loss: 1.7097 - val_acc: 0.4119\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.8049 - acc: 0.3558 - val_loss: 1.7051 - val_acc: 0.4121\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.8010 - acc: 0.3548 - val_loss: 1.7005 - val_acc: 0.4133\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7963 - acc: 0.3573 - val_loss: 1.6972 - val_acc: 0.4121\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7943 - acc: 0.3601 - val_loss: 1.6938 - val_acc: 0.4140\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.7908 - acc: 0.3601 - val_loss: 1.6904 - val_acc: 0.4159\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.7939 - acc: 0.3593 - val_loss: 1.6885 - val_acc: 0.4161\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7858 - acc: 0.3619 - val_loss: 1.6856 - val_acc: 0.4184\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.7851 - acc: 0.3621 - val_loss: 1.6830 - val_acc: 0.4170\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.7874 - acc: 0.3608 - val_loss: 1.6808 - val_acc: 0.4174\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7827 - acc: 0.3608 - val_loss: 1.6798 - val_acc: 0.4189\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7834 - acc: 0.3608 - val_loss: 1.6770 - val_acc: 0.4201\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 7s 166us/step - loss: 1.7812 - acc: 0.3645 - val_loss: 1.6771 - val_acc: 0.4217\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 7s 173us/step - loss: 1.7745 - acc: 0.3660 - val_loss: 1.6734 - val_acc: 0.4213\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.7760 - acc: 0.3653 - val_loss: 1.6722 - val_acc: 0.4198\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.7761 - acc: 0.3642 - val_loss: 1.6708 - val_acc: 0.4198\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7786 - acc: 0.3643 - val_loss: 1.6692 - val_acc: 0.4219\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.7724 - acc: 0.3678 - val_loss: 1.6682 - val_acc: 0.4212\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7723 - acc: 0.3664 - val_loss: 1.6667 - val_acc: 0.4205\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7711 - acc: 0.3682 - val_loss: 1.6654 - val_acc: 0.4224\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7747 - acc: 0.3655 - val_loss: 1.6646 - val_acc: 0.4219\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7636 - acc: 0.3684 - val_loss: 1.6628 - val_acc: 0.4236\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.7687 - acc: 0.3680 - val_loss: 1.6623 - val_acc: 0.4240\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.7685 - acc: 0.3695 - val_loss: 1.6612 - val_acc: 0.4204\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7716 - acc: 0.3665 - val_loss: 1.6605 - val_acc: 0.4227\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7692 - acc: 0.3657 - val_loss: 1.6594 - val_acc: 0.4216\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7701 - acc: 0.3680 - val_loss: 1.6597 - val_acc: 0.4223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7696 - acc: 0.3669 - val_loss: 1.6583 - val_acc: 0.4245\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.7637 - acc: 0.3711 - val_loss: 1.6573 - val_acc: 0.4262\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.7658 - acc: 0.3665 - val_loss: 1.6569 - val_acc: 0.4231\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7621 - acc: 0.3682 - val_loss: 1.6560 - val_acc: 0.4231\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.7634 - acc: 0.3703 - val_loss: 1.6554 - val_acc: 0.4241\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.7671 - acc: 0.3692 - val_loss: 1.6546 - val_acc: 0.4230\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7615 - acc: 0.3705 - val_loss: 1.6542 - val_acc: 0.4255\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7630 - acc: 0.3684 - val_loss: 1.6541 - val_acc: 0.4237\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7595 - acc: 0.3714 - val_loss: 1.6531 - val_acc: 0.4269\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 7s 163us/step - loss: 1.7589 - acc: 0.3738 - val_loss: 1.6513 - val_acc: 0.4260\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7613 - acc: 0.3719 - val_loss: 1.6509 - val_acc: 0.4243\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7594 - acc: 0.3730 - val_loss: 1.6510 - val_acc: 0.4269\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7602 - acc: 0.3714 - val_loss: 1.6509 - val_acc: 0.4262\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7611 - acc: 0.3699 - val_loss: 1.6491 - val_acc: 0.4272\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7607 - acc: 0.3693 - val_loss: 1.6491 - val_acc: 0.4261\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7593 - acc: 0.3716 - val_loss: 1.6495 - val_acc: 0.4256\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7629 - acc: 0.3704 - val_loss: 1.6489 - val_acc: 0.4260\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7578 - acc: 0.3691 - val_loss: 1.6477 - val_acc: 0.4267\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7575 - acc: 0.3719 - val_loss: 1.6475 - val_acc: 0.4288\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7549 - acc: 0.3732 - val_loss: 1.6473 - val_acc: 0.4263\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7572 - acc: 0.3703 - val_loss: 1.6467 - val_acc: 0.4289\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7585 - acc: 0.3713 - val_loss: 1.6466 - val_acc: 0.4269\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7534 - acc: 0.3754 - val_loss: 1.6460 - val_acc: 0.4282\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7560 - acc: 0.3723 - val_loss: 1.6456 - val_acc: 0.4281\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 7s 169us/step - loss: 1.7582 - acc: 0.3705 - val_loss: 1.6452 - val_acc: 0.4269\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7549 - acc: 0.3723 - val_loss: 1.6448 - val_acc: 0.4259\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7533 - acc: 0.3733 - val_loss: 1.6439 - val_acc: 0.4256\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 7s 172us/step - loss: 1.7563 - acc: 0.3709 - val_loss: 1.6444 - val_acc: 0.4276\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.7541 - acc: 0.3750 - val_loss: 1.6440 - val_acc: 0.4267\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 7s 172us/step - loss: 1.7561 - acc: 0.3708 - val_loss: 1.6434 - val_acc: 0.4276\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7590 - acc: 0.3715 - val_loss: 1.6431 - val_acc: 0.4276\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.7562 - acc: 0.3723 - val_loss: 1.6436 - val_acc: 0.4259\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7528 - acc: 0.3729 - val_loss: 1.6423 - val_acc: 0.4282\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7554 - acc: 0.3732 - val_loss: 1.6421 - val_acc: 0.4272\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7538 - acc: 0.3718 - val_loss: 1.6421 - val_acc: 0.4278\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7546 - acc: 0.3724 - val_loss: 1.6416 - val_acc: 0.4298\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.7502 - acc: 0.3741 - val_loss: 1.6412 - val_acc: 0.4270\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7521 - acc: 0.3755 - val_loss: 1.6410 - val_acc: 0.4294\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7513 - acc: 0.3752 - val_loss: 1.6407 - val_acc: 0.4283\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 1.7530 - acc: 0.3761 - val_loss: 1.6404 - val_acc: 0.4281\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.7518 - acc: 0.3749 - val_loss: 1.6397 - val_acc: 0.4265\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 1.7478 - acc: 0.3760 - val_loss: 1.6396 - val_acc: 0.4269\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 7s 174us/step - loss: 1.7552 - acc: 0.3700 - val_loss: 1.6403 - val_acc: 0.4267\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 7s 171us/step - loss: 1.7556 - acc: 0.3720 - val_loss: 1.6395 - val_acc: 0.4279\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 7s 171us/step - loss: 1.7529 - acc: 0.3688 - val_loss: 1.6398 - val_acc: 0.4283\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.7489 - acc: 0.3721 - val_loss: 1.6397 - val_acc: 0.4271\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7471 - acc: 0.3762 - val_loss: 1.6384 - val_acc: 0.4280\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.7521 - acc: 0.3739 - val_loss: 1.6389 - val_acc: 0.4294\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7518 - acc: 0.3731 - val_loss: 1.6383 - val_acc: 0.4295\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 7s 165us/step - loss: 1.7537 - acc: 0.3729 - val_loss: 1.6380 - val_acc: 0.4308\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7486 - acc: 0.3732 - val_loss: 1.6381 - val_acc: 0.4277\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 7s 165us/step - loss: 1.7489 - acc: 0.3729 - val_loss: 1.6376 - val_acc: 0.4261\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7531 - acc: 0.3711 - val_loss: 1.6374 - val_acc: 0.4253\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.7555 - acc: 0.3705 - val_loss: 1.6376 - val_acc: 0.4283\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7496 - acc: 0.3742 - val_loss: 1.6372 - val_acc: 0.4294\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 7s 166us/step - loss: 1.7485 - acc: 0.3734 - val_loss: 1.6375 - val_acc: 0.4285\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 6s 162us/step - loss: 1.7524 - acc: 0.3728 - val_loss: 1.6368 - val_acc: 0.4293\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7516 - acc: 0.3720 - val_loss: 1.6371 - val_acc: 0.4299\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7529 - acc: 0.3729 - val_loss: 1.6374 - val_acc: 0.4277\n",
      "10000/10000 [==============================] - 3s 261us/step\n",
      "Validation loss: 1.637387619972229\n",
      "Validation accuracy (NORMALIZED): 0.4277000068500638\n",
      "================================================\n",
      "Split: 4\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 7s 174us/step - loss: 2.2892 - acc: 0.1413 - val_loss: 2.2367 - val_acc: 0.2323\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 2.1945 - acc: 0.2116 - val_loss: 2.0693 - val_acc: 0.3249\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 2.0901 - acc: 0.2602 - val_loss: 1.9663 - val_acc: 0.3574\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 6s 160us/step - loss: 1.9935 - acc: 0.2905 - val_loss: 1.8734 - val_acc: 0.3814\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.9359 - acc: 0.3132 - val_loss: 1.8310 - val_acc: 0.3880\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.9015 - acc: 0.3234 - val_loss: 1.8022 - val_acc: 0.3981\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 7s 172us/step - loss: 1.8751 - acc: 0.3356 - val_loss: 1.7807 - val_acc: 0.3971\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.8558 - acc: 0.3407 - val_loss: 1.7637 - val_acc: 0.4003\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.8433 - acc: 0.3434 - val_loss: 1.7503 - val_acc: 0.4018\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.8365 - acc: 0.3465 - val_loss: 1.7406 - val_acc: 0.4036\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.8292 - acc: 0.3506 - val_loss: 1.7309 - val_acc: 0.4050\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.8208 - acc: 0.3496 - val_loss: 1.7232 - val_acc: 0.4077\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.8148 - acc: 0.3526 - val_loss: 1.7166 - val_acc: 0.4119\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.8125 - acc: 0.3544 - val_loss: 1.7111 - val_acc: 0.4115\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.8071 - acc: 0.3543 - val_loss: 1.7060 - val_acc: 0.4126\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.8016 - acc: 0.3571 - val_loss: 1.7011 - val_acc: 0.4110\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.8027 - acc: 0.3572 - val_loss: 1.6971 - val_acc: 0.4147\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 7s 164us/step - loss: 1.7956 - acc: 0.3576 - val_loss: 1.6935 - val_acc: 0.4124\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 6s 161us/step - loss: 1.7937 - acc: 0.3589 - val_loss: 1.6904 - val_acc: 0.4160\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7967 - acc: 0.3596 - val_loss: 1.6885 - val_acc: 0.4141\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7877 - acc: 0.3639 - val_loss: 1.6851 - val_acc: 0.4165\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7854 - acc: 0.3640 - val_loss: 1.6822 - val_acc: 0.4168\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7890 - acc: 0.3609 - val_loss: 1.6802 - val_acc: 0.4158\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7850 - acc: 0.3629 - val_loss: 1.6789 - val_acc: 0.4171\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7819 - acc: 0.3657 - val_loss: 1.6757 - val_acc: 0.4193\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7849 - acc: 0.3634 - val_loss: 1.6738 - val_acc: 0.4184\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7821 - acc: 0.3637 - val_loss: 1.6726 - val_acc: 0.4185\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7801 - acc: 0.3644 - val_loss: 1.6707 - val_acc: 0.4187\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7760 - acc: 0.3657 - val_loss: 1.6692 - val_acc: 0.4207\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7782 - acc: 0.3640 - val_loss: 1.6677 - val_acc: 0.4206\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7744 - acc: 0.3641 - val_loss: 1.6663 - val_acc: 0.4174\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7709 - acc: 0.3667 - val_loss: 1.6644 - val_acc: 0.4185\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7686 - acc: 0.3659 - val_loss: 1.6635 - val_acc: 0.4223\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7722 - acc: 0.3674 - val_loss: 1.6625 - val_acc: 0.4210\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7731 - acc: 0.3647 - val_loss: 1.6615 - val_acc: 0.4200\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7728 - acc: 0.3688 - val_loss: 1.6602 - val_acc: 0.4210\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7707 - acc: 0.3699 - val_loss: 1.6593 - val_acc: 0.4209\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7701 - acc: 0.3640 - val_loss: 1.6583 - val_acc: 0.4201\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7677 - acc: 0.3653 - val_loss: 1.6575 - val_acc: 0.4218\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7683 - acc: 0.3691 - val_loss: 1.6566 - val_acc: 0.4225\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7681 - acc: 0.3678 - val_loss: 1.6558 - val_acc: 0.4232\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7633 - acc: 0.3698 - val_loss: 1.6544 - val_acc: 0.4215\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7657 - acc: 0.3684 - val_loss: 1.6540 - val_acc: 0.4228\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7665 - acc: 0.3674 - val_loss: 1.6543 - val_acc: 0.4220\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7694 - acc: 0.3658 - val_loss: 1.6532 - val_acc: 0.4201\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7691 - acc: 0.3679 - val_loss: 1.6525 - val_acc: 0.4236\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7623 - acc: 0.3684 - val_loss: 1.6518 - val_acc: 0.4214\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7663 - acc: 0.3696 - val_loss: 1.6510 - val_acc: 0.4228\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7671 - acc: 0.3707 - val_loss: 1.6506 - val_acc: 0.4215\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7670 - acc: 0.3665 - val_loss: 1.6509 - val_acc: 0.4219\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7633 - acc: 0.3687 - val_loss: 1.6496 - val_acc: 0.4242\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7613 - acc: 0.3724 - val_loss: 1.6488 - val_acc: 0.4243\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7643 - acc: 0.3702 - val_loss: 1.6482 - val_acc: 0.4227\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7647 - acc: 0.3685 - val_loss: 1.6480 - val_acc: 0.4237\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7618 - acc: 0.3700 - val_loss: 1.6474 - val_acc: 0.4222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7624 - acc: 0.3702 - val_loss: 1.6475 - val_acc: 0.4241\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7601 - acc: 0.3695 - val_loss: 1.6466 - val_acc: 0.4235\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7577 - acc: 0.3710 - val_loss: 1.6461 - val_acc: 0.4236\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 1.7588 - acc: 0.3707 - val_loss: 1.6457 - val_acc: 0.4233\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7548 - acc: 0.3724 - val_loss: 1.6455 - val_acc: 0.4247\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 1.7627 - acc: 0.3698 - val_loss: 1.6447 - val_acc: 0.4214\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7569 - acc: 0.3718 - val_loss: 1.6445 - val_acc: 0.4224\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7575 - acc: 0.3706 - val_loss: 1.6437 - val_acc: 0.4250\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7565 - acc: 0.3714 - val_loss: 1.6435 - val_acc: 0.4244\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7569 - acc: 0.3705 - val_loss: 1.6433 - val_acc: 0.4239\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7609 - acc: 0.3717 - val_loss: 1.6429 - val_acc: 0.4257\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7581 - acc: 0.3705 - val_loss: 1.6425 - val_acc: 0.4230\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7592 - acc: 0.3711 - val_loss: 1.6418 - val_acc: 0.4249\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7519 - acc: 0.3729 - val_loss: 1.6416 - val_acc: 0.4244\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 1.7597 - acc: 0.3697 - val_loss: 1.6415 - val_acc: 0.4251\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7573 - acc: 0.3715 - val_loss: 1.6409 - val_acc: 0.4257\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7524 - acc: 0.3716 - val_loss: 1.6402 - val_acc: 0.4263\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7570 - acc: 0.3734 - val_loss: 1.6406 - val_acc: 0.4247\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7494 - acc: 0.3718 - val_loss: 1.6398 - val_acc: 0.4219\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 6s 155us/step - loss: 1.7550 - acc: 0.3721 - val_loss: 1.6393 - val_acc: 0.4252\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 6s 157us/step - loss: 1.7570 - acc: 0.3712 - val_loss: 1.6391 - val_acc: 0.4230\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7531 - acc: 0.3707 - val_loss: 1.6390 - val_acc: 0.4244\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 1.7579 - acc: 0.3712 - val_loss: 1.6394 - val_acc: 0.4258\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 6s 158us/step - loss: 1.7542 - acc: 0.3741 - val_loss: 1.6387 - val_acc: 0.4256\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 6s 156us/step - loss: 1.7484 - acc: 0.3755 - val_loss: 1.6388 - val_acc: 0.4255\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 6s 148us/step - loss: 1.7557 - acc: 0.3703 - val_loss: 1.6382 - val_acc: 0.4256\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 6s 141us/step - loss: 1.7488 - acc: 0.3735 - val_loss: 1.6383 - val_acc: 0.4240\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 6s 141us/step - loss: 1.7500 - acc: 0.3711 - val_loss: 1.6376 - val_acc: 0.4254\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 6s 142us/step - loss: 1.7525 - acc: 0.3719 - val_loss: 1.6373 - val_acc: 0.4252\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 6s 141us/step - loss: 1.7582 - acc: 0.3701 - val_loss: 1.6376 - val_acc: 0.4276\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 6s 141us/step - loss: 1.7515 - acc: 0.3714 - val_loss: 1.6376 - val_acc: 0.4243\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 6s 140us/step - loss: 1.7538 - acc: 0.3739 - val_loss: 1.6369 - val_acc: 0.4266\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 6s 139us/step - loss: 1.7562 - acc: 0.3734 - val_loss: 1.6369 - val_acc: 0.4249\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 6s 139us/step - loss: 1.7521 - acc: 0.3726 - val_loss: 1.6362 - val_acc: 0.4249\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 6s 140us/step - loss: 1.7519 - acc: 0.3736 - val_loss: 1.6365 - val_acc: 0.4258\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 6s 139us/step - loss: 1.7526 - acc: 0.3752 - val_loss: 1.6363 - val_acc: 0.4285\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 6s 138us/step - loss: 1.7471 - acc: 0.3780 - val_loss: 1.6355 - val_acc: 0.4248\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 6s 139us/step - loss: 1.7550 - acc: 0.3752 - val_loss: 1.6354 - val_acc: 0.4253\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 6s 139us/step - loss: 1.7475 - acc: 0.3765 - val_loss: 1.6352 - val_acc: 0.4272\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 6s 141us/step - loss: 1.7534 - acc: 0.3704 - val_loss: 1.6350 - val_acc: 0.4260\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 6s 140us/step - loss: 1.7482 - acc: 0.3752 - val_loss: 1.6349 - val_acc: 0.4243\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 6s 138us/step - loss: 1.7482 - acc: 0.3715 - val_loss: 1.6343 - val_acc: 0.4257\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 6s 139us/step - loss: 1.7525 - acc: 0.3744 - val_loss: 1.6349 - val_acc: 0.4262\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 6s 138us/step - loss: 1.7496 - acc: 0.3756 - val_loss: 1.6344 - val_acc: 0.4253\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 6s 139us/step - loss: 1.7484 - acc: 0.3727 - val_loss: 1.6346 - val_acc: 0.4276\n",
      "10000/10000 [==============================] - 2s 239us/step\n",
      "Validation loss: 1.6346342141628265\n",
      "Validation accuracy (NORMALIZED): 0.42760000710189344\n",
      "[[1.639105289697647, 0.4277000068128109], [1.6465386847257615, 0.42770000714808704], [1.6285417018532753, 0.43220000743865966], [1.637387619972229, 0.4277000068500638], [1.6346342141628265, 0.42760000710189344]]\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Training model and Evaluation\n",
    "#=====================================\n",
    "\n",
    "y_train_categorical = to_categorical(y_train, num_classes=n_classes)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=n_classes)\n",
    "\n",
    "scores = []\n",
    "for i in range(folds):\n",
    "    #--- Loading model\n",
    "    model  = get_squeezenet_ft()\n",
    "    \n",
    "    #--- Evaluating the model for split i\n",
    "    print(\"================================================\")\n",
    "    print(\"Split: \"+str(i))\n",
    "    print(\"Number of Epochs: \"+str(n_epochs))\n",
    "    print(\"Train shape:\",X_train[i].shape)\n",
    "    print(\"Train batch size: \"+str(train_batch_size))\n",
    "    print(\"Val batch size: \"+str(val_batch_size))\n",
    "    print(\"================================================\")\n",
    "    \n",
    "    # Training without data augmentation\n",
    "    model.fit(X_train[i],y_train_categorical[i], batch_size=train_batch_size,\n",
    "              epochs=n_epochs, \n",
    "              validation_data=(X_val[i],y_val_categorical[i]),\n",
    "              verbose=1)\n",
    "    \n",
    "    #--- Evaluating the model for split i\n",
    "    score = model.evaluate(x=X_val[i], y=y_val_categorical[i], batch_size=val_batch_size, verbose=1)\n",
    "    scores.append(score)\n",
    "    print('Validation loss:', score[0])\n",
    "    print('Validation accuracy (NORMALIZED):', score[1])\n",
    "    \n",
    "#--- Showing scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation loss: 1.6372415020823479\n",
      "Mean Validation accuracy (NORMALIZED): 0.4285800070703029\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Evaluate on validation\n",
    "#=====================================\n",
    "\n",
    "#--- The evaluation of the model \n",
    "np_aux = np.array(scores).mean(axis=0)\n",
    "\n",
    "print('Mean Validation loss:', np_aux[0])\n",
    "print('Mean Validation accuracy (NORMALIZED):', np_aux[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "-----------------\n",
    "\n",
    "# Training last 2 Fire Modules + classification layers\n",
    "As we could see, the frozen network performed very poorly. By freezing most layers, we do not allow SqueezeNet to adapt its weights to features present in CIFAR-10.\n",
    "\n",
    "Let's try to unfreeze the last two fire modules and train once more. The architecture will be:\n",
    "<img src=\"partFrozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 10)     5130        drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 10)     0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_14 (Gl (None, 10)           0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 10)           0           global_average_pooling2d_14[0][0]\n",
      "==================================================================================================\n",
      "Total params: 727,626\n",
      "Trainable params: 391,306\n",
      "Non-trainable params: 336,320\n",
      "__________________________________________________________________________________________________\n",
      "input_7 False\n",
      "conv1 False\n",
      "relu_conv1 False\n",
      "pool1 False\n",
      "fire2/squeeze1x1 False\n",
      "fire2/relu_squeeze1x1 False\n",
      "fire2/expand1x1 False\n",
      "fire2/expand3x3 False\n",
      "fire2/relu_expand1x1 False\n",
      "fire2/relu_expand3x3 False\n",
      "fire2/concat False\n",
      "fire3/squeeze1x1 False\n",
      "fire3/relu_squeeze1x1 False\n",
      "fire3/expand1x1 False\n",
      "fire3/expand3x3 False\n",
      "fire3/relu_expand1x1 False\n",
      "fire3/relu_expand3x3 False\n",
      "fire3/concat False\n",
      "pool3 False\n",
      "fire4/squeeze1x1 False\n",
      "fire4/relu_squeeze1x1 False\n",
      "fire4/expand1x1 False\n",
      "fire4/expand3x3 False\n",
      "fire4/relu_expand1x1 False\n",
      "fire4/relu_expand3x3 False\n",
      "fire4/concat False\n",
      "fire5/squeeze1x1 False\n",
      "fire5/relu_squeeze1x1 False\n",
      "fire5/expand1x1 False\n",
      "fire5/expand3x3 False\n",
      "fire5/relu_expand1x1 False\n",
      "fire5/relu_expand3x3 False\n",
      "fire5/concat False\n",
      "pool5 False\n",
      "fire6/squeeze1x1 False\n",
      "fire6/relu_squeeze1x1 False\n",
      "fire6/expand1x1 False\n",
      "fire6/expand3x3 False\n",
      "fire6/relu_expand1x1 False\n",
      "fire6/relu_expand3x3 False\n",
      "fire6/concat False\n",
      "fire7/squeeze1x1 False\n",
      "fire7/relu_squeeze1x1 False\n",
      "fire7/expand1x1 False\n",
      "fire7/expand3x3 False\n",
      "fire7/relu_expand1x1 False\n",
      "fire7/relu_expand3x3 False\n",
      "fire7/concat False\n",
      "fire8/squeeze1x1 True\n",
      "fire8/relu_squeeze1x1 True\n",
      "fire8/expand1x1 True\n",
      "fire8/expand3x3 True\n",
      "fire8/relu_expand1x1 True\n",
      "fire8/relu_expand3x3 True\n",
      "fire8/concat True\n",
      "fire9/squeeze1x1 True\n",
      "fire9/relu_squeeze1x1 True\n",
      "fire9/expand1x1 True\n",
      "fire9/expand3x3 True\n",
      "fire9/relu_expand1x1 True\n",
      "fire9/relu_expand3x3 True\n",
      "fire9/concat True\n",
      "drop9 True\n",
      "conv10 True\n",
      "relu_conv10 True\n",
      "global_average_pooling2d_14 True\n",
      "loss True\n"
     ]
    }
   ],
   "source": [
    "def get_squeezenet_ft2():\n",
    "    squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "    #=====================================\n",
    "    # Freezing mentioned layers\n",
    "    #=====================================\n",
    "\n",
    "    trainable_layer_index = 19\n",
    "    for i in range(len(squeezeNetModel.layers)-trainable_layer_index):\n",
    "        squeezeNetModel.layers[i].trainable = False\n",
    "\n",
    "    #=====================================\n",
    "    # Add new classification layers\n",
    "    #=====================================\n",
    "\n",
    "    #--- Removing layers until drop 9\n",
    "    squeezeNetModel.layers.pop() #Convolution2D\n",
    "    squeezeNetModel.layers.pop() #Activation ReLU\n",
    "    squeezeNetModel.layers.pop() #Global Avg Pool\n",
    "    squeezeNetModel.layers.pop() #Activation Softmax\n",
    "\n",
    "    #--- Adding classification layer for 10 classes\n",
    "    out = Convolution2D(n_classes, (1, 1), padding='valid', name='conv10')(squeezeNetModel.layers[-1].output)\n",
    "    out = Activation('relu', name='relu_conv10')(out)\n",
    "\n",
    "    out = GlobalAveragePooling2D()(out)\n",
    "    out = Activation('softmax', name='loss')(out)\n",
    "\n",
    "    #=====================================\n",
    "    # New Model\n",
    "    #=====================================\n",
    "    model = Model(squeezeNetModel.inputs, out, name='squeezenet_new')\n",
    "    opt = optimizer=optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#SGD(lr=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_squeezenet_ft2()\n",
    "model.summary()\n",
    "\n",
    "#--- Check the trainable status of the individual layers\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Split: 0\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 11s 266us/step - loss: 1.8300 - acc: 0.3448 - val_loss: 1.5034 - val_acc: 0.4692\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 1.5429 - acc: 0.4519 - val_loss: 1.4419 - val_acc: 0.4908\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.4797 - acc: 0.4744 - val_loss: 1.4120 - val_acc: 0.5039\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.4379 - acc: 0.4932 - val_loss: 1.3832 - val_acc: 0.5089\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.4131 - acc: 0.5014 - val_loss: 1.3697 - val_acc: 0.5144\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 9s 223us/step - loss: 1.3926 - acc: 0.5093 - val_loss: 1.3624 - val_acc: 0.5220\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 9s 221us/step - loss: 1.3744 - acc: 0.5160 - val_loss: 1.3418 - val_acc: 0.5264\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 9s 221us/step - loss: 1.3571 - acc: 0.5205 - val_loss: 1.3381 - val_acc: 0.5281\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 1.3472 - acc: 0.5234 - val_loss: 1.3387 - val_acc: 0.5275\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.3340 - acc: 0.5286 - val_loss: 1.3209 - val_acc: 0.5301\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.3214 - acc: 0.5329 - val_loss: 1.3209 - val_acc: 0.5335\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.3134 - acc: 0.5377 - val_loss: 1.3284 - val_acc: 0.5276\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 1.3048 - acc: 0.5375 - val_loss: 1.3099 - val_acc: 0.5329\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 1.2958 - acc: 0.5430 - val_loss: 1.3175 - val_acc: 0.5367\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.2883 - acc: 0.5449 - val_loss: 1.3046 - val_acc: 0.5414\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 1.2836 - acc: 0.5441 - val_loss: 1.3025 - val_acc: 0.5394\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 1.2778 - acc: 0.5486 - val_loss: 1.2913 - val_acc: 0.5429\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.2678 - acc: 0.5522 - val_loss: 1.2933 - val_acc: 0.5439\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.2609 - acc: 0.5560 - val_loss: 1.2957 - val_acc: 0.5401\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 9s 221us/step - loss: 1.2548 - acc: 0.5546 - val_loss: 1.2895 - val_acc: 0.5474\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.2467 - acc: 0.5565 - val_loss: 1.2878 - val_acc: 0.5451\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 9s 223us/step - loss: 1.2424 - acc: 0.5612 - val_loss: 1.2859 - val_acc: 0.5479\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 1.2353 - acc: 0.5622 - val_loss: 1.2869 - val_acc: 0.5497\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.2272 - acc: 0.5637 - val_loss: 1.2791 - val_acc: 0.5463\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.2235 - acc: 0.5680 - val_loss: 1.2769 - val_acc: 0.5484\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 1.2216 - acc: 0.5673 - val_loss: 1.2910 - val_acc: 0.5494\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.2140 - acc: 0.5712 - val_loss: 1.3045 - val_acc: 0.5467\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 9s 223us/step - loss: 1.2115 - acc: 0.5724 - val_loss: 1.2782 - val_acc: 0.5523\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 1.2034 - acc: 0.5736 - val_loss: 1.2779 - val_acc: 0.5480\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.1983 - acc: 0.5758 - val_loss: 1.2724 - val_acc: 0.5504\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 1.1935 - acc: 0.5776 - val_loss: 1.2726 - val_acc: 0.5517\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.1874 - acc: 0.5791 - val_loss: 1.2779 - val_acc: 0.5538\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 1.1819 - acc: 0.5791 - val_loss: 1.2714 - val_acc: 0.5559\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 9s 216us/step - loss: 1.1794 - acc: 0.5811 - val_loss: 1.2675 - val_acc: 0.5512\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 1.1715 - acc: 0.5823 - val_loss: 1.2708 - val_acc: 0.5565\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.1672 - acc: 0.5844 - val_loss: 1.2764 - val_acc: 0.5505\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.1642 - acc: 0.5842 - val_loss: 1.2675 - val_acc: 0.5559\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.1615 - acc: 0.5907 - val_loss: 1.2727 - val_acc: 0.5552\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.1528 - acc: 0.5909 - val_loss: 1.2878 - val_acc: 0.5503\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.1496 - acc: 0.5915 - val_loss: 1.2791 - val_acc: 0.5538\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.1430 - acc: 0.5949 - val_loss: 1.2825 - val_acc: 0.5549\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.1387 - acc: 0.5946 - val_loss: 1.2749 - val_acc: 0.5547\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 1.1343 - acc: 0.5953 - val_loss: 1.2730 - val_acc: 0.5562\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.1291 - acc: 0.5986 - val_loss: 1.2669 - val_acc: 0.5514\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 9s 221us/step - loss: 1.1239 - acc: 0.6003 - val_loss: 1.2747 - val_acc: 0.5591\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 1.1196 - acc: 0.6018 - val_loss: 1.2830 - val_acc: 0.5542\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.1155 - acc: 0.6029 - val_loss: 1.2735 - val_acc: 0.5554\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.1100 - acc: 0.6032 - val_loss: 1.2951 - val_acc: 0.5503\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 1.1063 - acc: 0.6051 - val_loss: 1.2772 - val_acc: 0.5574\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.1007 - acc: 0.6074 - val_loss: 1.2826 - val_acc: 0.5514\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 9s 213us/step - loss: 1.0958 - acc: 0.6095 - val_loss: 1.2726 - val_acc: 0.5590\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 1.0905 - acc: 0.6098 - val_loss: 1.2841 - val_acc: 0.5546\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.0872 - acc: 0.6161 - val_loss: 1.2802 - val_acc: 0.5552\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 1.0840 - acc: 0.6168 - val_loss: 1.2815 - val_acc: 0.5538\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 1.0768 - acc: 0.6182 - val_loss: 1.2893 - val_acc: 0.5562\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.0738 - acc: 0.6191 - val_loss: 1.2913 - val_acc: 0.5572\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 9s 215us/step - loss: 1.0709 - acc: 0.6203 - val_loss: 1.2959 - val_acc: 0.5548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.0660 - acc: 0.6213 - val_loss: 1.2953 - val_acc: 0.5544\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.0606 - acc: 0.6221 - val_loss: 1.2846 - val_acc: 0.5546\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.0555 - acc: 0.6235 - val_loss: 1.2893 - val_acc: 0.5568\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 9s 216us/step - loss: 1.0519 - acc: 0.6249 - val_loss: 1.3012 - val_acc: 0.5485\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 9s 216us/step - loss: 1.0460 - acc: 0.6289 - val_loss: 1.3066 - val_acc: 0.5552\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 1.0422 - acc: 0.6288 - val_loss: 1.2943 - val_acc: 0.5541\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.0378 - acc: 0.6320 - val_loss: 1.2863 - val_acc: 0.5515\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 9s 221us/step - loss: 1.0275 - acc: 0.6329 - val_loss: 1.2933 - val_acc: 0.5511\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 1.0240 - acc: 0.6341 - val_loss: 1.3058 - val_acc: 0.5564\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 9s 216us/step - loss: 1.0235 - acc: 0.6346 - val_loss: 1.3044 - val_acc: 0.5524\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 1.0156 - acc: 0.6354 - val_loss: 1.3074 - val_acc: 0.5556\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 1.0121 - acc: 0.6370 - val_loss: 1.3073 - val_acc: 0.5550\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 9s 216us/step - loss: 1.0067 - acc: 0.6421 - val_loss: 1.3177 - val_acc: 0.5540\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 1.0034 - acc: 0.6451 - val_loss: 1.3225 - val_acc: 0.5552\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 0.9969 - acc: 0.6451 - val_loss: 1.3410 - val_acc: 0.5479\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 0.9932 - acc: 0.6437 - val_loss: 1.3172 - val_acc: 0.5504\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 9s 218us/step - loss: 0.9894 - acc: 0.6471 - val_loss: 1.3363 - val_acc: 0.5523\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 0.9836 - acc: 0.6484 - val_loss: 1.3200 - val_acc: 0.5516\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 0.9784 - acc: 0.6488 - val_loss: 1.3388 - val_acc: 0.5468\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 9s 217us/step - loss: 0.9767 - acc: 0.6518 - val_loss: 1.3441 - val_acc: 0.5510\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 0.9695 - acc: 0.6561 - val_loss: 1.3172 - val_acc: 0.5542\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 9s 213us/step - loss: 0.9651 - acc: 0.6538 - val_loss: 1.3326 - val_acc: 0.5479\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 9s 224us/step - loss: 0.9623 - acc: 0.6563 - val_loss: 1.3375 - val_acc: 0.5497\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.9552 - acc: 0.6592 - val_loss: 1.3471 - val_acc: 0.5499\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.9510 - acc: 0.6620 - val_loss: 1.3491 - val_acc: 0.5540\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 0.9435 - acc: 0.6639 - val_loss: 1.3447 - val_acc: 0.5493\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 0.9421 - acc: 0.6663 - val_loss: 1.3554 - val_acc: 0.5543\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 9s 224us/step - loss: 0.9365 - acc: 0.6643 - val_loss: 1.3685 - val_acc: 0.5515\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 0.9322 - acc: 0.6675 - val_loss: 1.3596 - val_acc: 0.5453\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 9s 224us/step - loss: 0.9235 - acc: 0.6715 - val_loss: 1.3702 - val_acc: 0.5485\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 0.9206 - acc: 0.6720 - val_loss: 1.3663 - val_acc: 0.5484\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 9s 221us/step - loss: 0.9185 - acc: 0.6717 - val_loss: 1.3877 - val_acc: 0.5496\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.9167 - acc: 0.6734 - val_loss: 1.3854 - val_acc: 0.5479\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 0.9078 - acc: 0.6746 - val_loss: 1.3873 - val_acc: 0.5475\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.9063 - acc: 0.6778 - val_loss: 1.3884 - val_acc: 0.5466\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 0.9020 - acc: 0.6788 - val_loss: 1.3927 - val_acc: 0.5468\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.8958 - acc: 0.6798 - val_loss: 1.3754 - val_acc: 0.5434\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 0.8914 - acc: 0.6812 - val_loss: 1.4049 - val_acc: 0.5431\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 0.8871 - acc: 0.6830 - val_loss: 1.4203 - val_acc: 0.5445\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.8790 - acc: 0.6863 - val_loss: 1.4096 - val_acc: 0.5478\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 9s 221us/step - loss: 0.8769 - acc: 0.6865 - val_loss: 1.4176 - val_acc: 0.5454\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 9s 214us/step - loss: 0.8698 - acc: 0.6898 - val_loss: 1.4192 - val_acc: 0.5431\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 9s 216us/step - loss: 0.8663 - acc: 0.6928 - val_loss: 1.4241 - val_acc: 0.5449\n",
      "10000/10000 [==============================] - 3s 253us/step\n",
      "Validation loss: 1.4240833519101144\n",
      "Validation accuracy (NORMALIZED): 0.5449000060409307\n",
      "================================================\n",
      "Split: 1\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 10s 261us/step - loss: 1.8442 - acc: 0.3413 - val_loss: 1.5345 - val_acc: 0.4519\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.5567 - acc: 0.4475 - val_loss: 1.4514 - val_acc: 0.4837\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.4840 - acc: 0.4756 - val_loss: 1.4235 - val_acc: 0.4950\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.4455 - acc: 0.4893 - val_loss: 1.4059 - val_acc: 0.4985\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.4185 - acc: 0.4981 - val_loss: 1.3804 - val_acc: 0.5074\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.3968 - acc: 0.5067 - val_loss: 1.3710 - val_acc: 0.5120\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.3789 - acc: 0.5127 - val_loss: 1.3651 - val_acc: 0.5122\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.3654 - acc: 0.5210 - val_loss: 1.3511 - val_acc: 0.5162\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.3507 - acc: 0.5236 - val_loss: 1.3419 - val_acc: 0.5230\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.3382 - acc: 0.5267 - val_loss: 1.3449 - val_acc: 0.5202\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.3288 - acc: 0.5331 - val_loss: 1.3355 - val_acc: 0.5226\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.3205 - acc: 0.5337 - val_loss: 1.3300 - val_acc: 0.5284\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.3106 - acc: 0.5388 - val_loss: 1.3287 - val_acc: 0.5258\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.3051 - acc: 0.5387 - val_loss: 1.3162 - val_acc: 0.5308\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.2946 - acc: 0.5415 - val_loss: 1.3162 - val_acc: 0.5357\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.2884 - acc: 0.5436 - val_loss: 1.3128 - val_acc: 0.5342\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.2800 - acc: 0.5477 - val_loss: 1.3091 - val_acc: 0.5386\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.2715 - acc: 0.5509 - val_loss: 1.3062 - val_acc: 0.5388\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 9s 223us/step - loss: 1.2649 - acc: 0.5542 - val_loss: 1.3078 - val_acc: 0.5360\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 9s 223us/step - loss: 1.2606 - acc: 0.5546 - val_loss: 1.3059 - val_acc: 0.5399\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 10s 257us/step - loss: 1.2539 - acc: 0.5564 - val_loss: 1.3037 - val_acc: 0.5433\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 10s 257us/step - loss: 1.2478 - acc: 0.5585 - val_loss: 1.3003 - val_acc: 0.5401\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 11s 263us/step - loss: 1.2448 - acc: 0.5594 - val_loss: 1.2935 - val_acc: 0.5437\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.2356 - acc: 0.5632 - val_loss: 1.2993 - val_acc: 0.5442\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.2287 - acc: 0.5645 - val_loss: 1.2971 - val_acc: 0.5439\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.2256 - acc: 0.5653 - val_loss: 1.2943 - val_acc: 0.5432\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.2219 - acc: 0.5686 - val_loss: 1.2911 - val_acc: 0.5463\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.2133 - acc: 0.5696 - val_loss: 1.2938 - val_acc: 0.5444\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 9s 222us/step - loss: 1.2081 - acc: 0.5728 - val_loss: 1.2861 - val_acc: 0.5492\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.2038 - acc: 0.5737 - val_loss: 1.3047 - val_acc: 0.5416\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.1986 - acc: 0.5744 - val_loss: 1.2957 - val_acc: 0.5491\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.1964 - acc: 0.5761 - val_loss: 1.2851 - val_acc: 0.5488\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.1875 - acc: 0.5792 - val_loss: 1.2878 - val_acc: 0.5484\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.1848 - acc: 0.5812 - val_loss: 1.2874 - val_acc: 0.5512\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 9s 221us/step - loss: 1.1811 - acc: 0.5813 - val_loss: 1.2907 - val_acc: 0.5487\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 9s 219us/step - loss: 1.1733 - acc: 0.5829 - val_loss: 1.2905 - val_acc: 0.5487\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 9s 224us/step - loss: 1.1732 - acc: 0.5857 - val_loss: 1.2973 - val_acc: 0.5479\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.1643 - acc: 0.5870 - val_loss: 1.3089 - val_acc: 0.5495\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.1602 - acc: 0.5910 - val_loss: 1.2976 - val_acc: 0.5441\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.1566 - acc: 0.5887 - val_loss: 1.2977 - val_acc: 0.5498\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.1513 - acc: 0.5922 - val_loss: 1.2972 - val_acc: 0.5487\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.1466 - acc: 0.5943 - val_loss: 1.2991 - val_acc: 0.5495\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.1404 - acc: 0.5948 - val_loss: 1.2870 - val_acc: 0.5521\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.1382 - acc: 0.5964 - val_loss: 1.2936 - val_acc: 0.5535\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.1340 - acc: 0.5975 - val_loss: 1.2874 - val_acc: 0.5534\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.1272 - acc: 0.6010 - val_loss: 1.2995 - val_acc: 0.5541\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.1242 - acc: 0.6014 - val_loss: 1.2945 - val_acc: 0.5545\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.1192 - acc: 0.6039 - val_loss: 1.2959 - val_acc: 0.5553\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.1125 - acc: 0.6061 - val_loss: 1.3046 - val_acc: 0.5548\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.1105 - acc: 0.6064 - val_loss: 1.2957 - val_acc: 0.5527\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.1037 - acc: 0.6070 - val_loss: 1.3016 - val_acc: 0.5508\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.1011 - acc: 0.6097 - val_loss: 1.3016 - val_acc: 0.5534\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.0925 - acc: 0.6121 - val_loss: 1.3026 - val_acc: 0.5533\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.0890 - acc: 0.6117 - val_loss: 1.2940 - val_acc: 0.5559\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.0875 - acc: 0.6131 - val_loss: 1.3026 - val_acc: 0.5508\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.0813 - acc: 0.6149 - val_loss: 1.2982 - val_acc: 0.5500\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.0770 - acc: 0.6175 - val_loss: 1.3131 - val_acc: 0.5515\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.0736 - acc: 0.6170 - val_loss: 1.3015 - val_acc: 0.5552\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.0691 - acc: 0.6179 - val_loss: 1.3158 - val_acc: 0.5525\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.0667 - acc: 0.6198 - val_loss: 1.3251 - val_acc: 0.5491\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.0572 - acc: 0.6229 - val_loss: 1.3174 - val_acc: 0.5495\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.0567 - acc: 0.6238 - val_loss: 1.3199 - val_acc: 0.5489\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.0482 - acc: 0.6282 - val_loss: 1.3161 - val_acc: 0.5519\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 9s 222us/step - loss: 1.0480 - acc: 0.6271 - val_loss: 1.3206 - val_acc: 0.5514\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.0420 - acc: 0.6273 - val_loss: 1.3226 - val_acc: 0.5487\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.0384 - acc: 0.6305 - val_loss: 1.3306 - val_acc: 0.5489\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.0329 - acc: 0.6310 - val_loss: 1.3276 - val_acc: 0.5541\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.0291 - acc: 0.6326 - val_loss: 1.3169 - val_acc: 0.5519\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.0231 - acc: 0.6367 - val_loss: 1.3332 - val_acc: 0.5485\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.0196 - acc: 0.6374 - val_loss: 1.3387 - val_acc: 0.5479\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.0142 - acc: 0.6383 - val_loss: 1.3273 - val_acc: 0.5496\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 9s 223us/step - loss: 1.0090 - acc: 0.6404 - val_loss: 1.3228 - val_acc: 0.5522\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.0082 - acc: 0.6401 - val_loss: 1.3398 - val_acc: 0.5492\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.0019 - acc: 0.6431 - val_loss: 1.3467 - val_acc: 0.5531\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 0.9980 - acc: 0.6453 - val_loss: 1.3457 - val_acc: 0.5485\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.9947 - acc: 0.6462 - val_loss: 1.3433 - val_acc: 0.5548\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 0.9885 - acc: 0.6477 - val_loss: 1.3684 - val_acc: 0.5480\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.9845 - acc: 0.6500 - val_loss: 1.3556 - val_acc: 0.5493\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 0.9809 - acc: 0.6501 - val_loss: 1.3473 - val_acc: 0.5458\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 9s 224us/step - loss: 0.9758 - acc: 0.6516 - val_loss: 1.3719 - val_acc: 0.5501\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.9703 - acc: 0.6559 - val_loss: 1.3549 - val_acc: 0.5475\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 0.9618 - acc: 0.6560 - val_loss: 1.3910 - val_acc: 0.5463\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 0.9617 - acc: 0.6553 - val_loss: 1.3677 - val_acc: 0.5456\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.9596 - acc: 0.6588 - val_loss: 1.3793 - val_acc: 0.5498\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 0.9543 - acc: 0.6587 - val_loss: 1.3691 - val_acc: 0.5501\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 0.9472 - acc: 0.6613 - val_loss: 1.3805 - val_acc: 0.5457\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 0.9438 - acc: 0.6642 - val_loss: 1.3922 - val_acc: 0.5453\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 0.9373 - acc: 0.6655 - val_loss: 1.3983 - val_acc: 0.5429\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 0.9361 - acc: 0.6653 - val_loss: 1.3872 - val_acc: 0.5431\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 0.9284 - acc: 0.6684 - val_loss: 1.3948 - val_acc: 0.5455\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 0.9256 - acc: 0.6698 - val_loss: 1.3909 - val_acc: 0.5416\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 0.9181 - acc: 0.6723 - val_loss: 1.4076 - val_acc: 0.5446\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 0.9186 - acc: 0.6720 - val_loss: 1.4035 - val_acc: 0.5447\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.9124 - acc: 0.6717 - val_loss: 1.3906 - val_acc: 0.5481\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.9093 - acc: 0.6751 - val_loss: 1.4077 - val_acc: 0.5470\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 0.9027 - acc: 0.6776 - val_loss: 1.4329 - val_acc: 0.5442\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 0.8968 - acc: 0.6793 - val_loss: 1.4220 - val_acc: 0.5387\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.8945 - acc: 0.6802 - val_loss: 1.4268 - val_acc: 0.5411\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 0.8900 - acc: 0.6804 - val_loss: 1.4463 - val_acc: 0.5414\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 0.8849 - acc: 0.6821 - val_loss: 1.4518 - val_acc: 0.5413\n",
      "10000/10000 [==============================] - 3s 294us/step\n",
      "Validation loss: 1.4518084926903247\n",
      "Validation accuracy (NORMALIZED): 0.541300005659461\n",
      "================================================\n",
      "Split: 2\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 11s 270us/step - loss: 1.8475 - acc: 0.3281 - val_loss: 1.5276 - val_acc: 0.4552\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.5650 - acc: 0.4439 - val_loss: 1.4486 - val_acc: 0.4822\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.4920 - acc: 0.4743 - val_loss: 1.3988 - val_acc: 0.5012\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.4553 - acc: 0.4860 - val_loss: 1.3807 - val_acc: 0.5084\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.4211 - acc: 0.4949 - val_loss: 1.3751 - val_acc: 0.5123\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.4032 - acc: 0.5046 - val_loss: 1.3457 - val_acc: 0.5213\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.3881 - acc: 0.5111 - val_loss: 1.3414 - val_acc: 0.5244\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.3745 - acc: 0.5153 - val_loss: 1.3256 - val_acc: 0.5280\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.3602 - acc: 0.5212 - val_loss: 1.3204 - val_acc: 0.5311\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.3452 - acc: 0.5268 - val_loss: 1.3168 - val_acc: 0.5310\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.3360 - acc: 0.5282 - val_loss: 1.3089 - val_acc: 0.5354\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.3291 - acc: 0.5319 - val_loss: 1.3030 - val_acc: 0.5405\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.3215 - acc: 0.5352 - val_loss: 1.2997 - val_acc: 0.5409\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.3115 - acc: 0.5384 - val_loss: 1.2953 - val_acc: 0.5423\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.3021 - acc: 0.5423 - val_loss: 1.2924 - val_acc: 0.5371\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.2944 - acc: 0.5434 - val_loss: 1.2973 - val_acc: 0.5355\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.2848 - acc: 0.5482 - val_loss: 1.2933 - val_acc: 0.5406\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.2815 - acc: 0.5495 - val_loss: 1.2886 - val_acc: 0.5396\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.2756 - acc: 0.5521 - val_loss: 1.2803 - val_acc: 0.5450\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.2673 - acc: 0.5538 - val_loss: 1.2781 - val_acc: 0.5470\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.2637 - acc: 0.5563 - val_loss: 1.2839 - val_acc: 0.5439\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.2562 - acc: 0.5563 - val_loss: 1.2705 - val_acc: 0.5495\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.2509 - acc: 0.5592 - val_loss: 1.2740 - val_acc: 0.5477\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.2454 - acc: 0.5608 - val_loss: 1.2725 - val_acc: 0.5483\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.2363 - acc: 0.5630 - val_loss: 1.2766 - val_acc: 0.5444\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.2327 - acc: 0.5661 - val_loss: 1.2688 - val_acc: 0.5477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.2270 - acc: 0.5661 - val_loss: 1.2670 - val_acc: 0.5489\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.2203 - acc: 0.5684 - val_loss: 1.2748 - val_acc: 0.5465\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.2140 - acc: 0.5718 - val_loss: 1.2739 - val_acc: 0.5459\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.2060 - acc: 0.5753 - val_loss: 1.2687 - val_acc: 0.5494\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.2081 - acc: 0.5745 - val_loss: 1.2807 - val_acc: 0.5433\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.2009 - acc: 0.5746 - val_loss: 1.2633 - val_acc: 0.5492\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.1947 - acc: 0.5789 - val_loss: 1.2684 - val_acc: 0.5500\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.1888 - acc: 0.5805 - val_loss: 1.2691 - val_acc: 0.5495\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.1852 - acc: 0.5831 - val_loss: 1.2679 - val_acc: 0.5514\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.1822 - acc: 0.5815 - val_loss: 1.2773 - val_acc: 0.5442\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.1757 - acc: 0.5856 - val_loss: 1.2703 - val_acc: 0.5502\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.1709 - acc: 0.5875 - val_loss: 1.2653 - val_acc: 0.5524\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.1664 - acc: 0.5898 - val_loss: 1.2687 - val_acc: 0.5538\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.1582 - acc: 0.5914 - val_loss: 1.2796 - val_acc: 0.5484\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.1559 - acc: 0.5913 - val_loss: 1.2760 - val_acc: 0.5454\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.1515 - acc: 0.5914 - val_loss: 1.2794 - val_acc: 0.5462\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.1451 - acc: 0.5968 - val_loss: 1.2738 - val_acc: 0.5498\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.1425 - acc: 0.5984 - val_loss: 1.2717 - val_acc: 0.5491\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.1349 - acc: 0.5982 - val_loss: 1.2704 - val_acc: 0.5514\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.1320 - acc: 0.6001 - val_loss: 1.2697 - val_acc: 0.5521\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.1267 - acc: 0.6034 - val_loss: 1.2695 - val_acc: 0.5527\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.1233 - acc: 0.6025 - val_loss: 1.2718 - val_acc: 0.5556\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.1230 - acc: 0.6027 - val_loss: 1.2719 - val_acc: 0.5496\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.1115 - acc: 0.6073 - val_loss: 1.2725 - val_acc: 0.5514\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.1092 - acc: 0.6072 - val_loss: 1.2872 - val_acc: 0.5537\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.1058 - acc: 0.6087 - val_loss: 1.2755 - val_acc: 0.5529\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.1019 - acc: 0.6096 - val_loss: 1.2844 - val_acc: 0.5471\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.0977 - acc: 0.6134 - val_loss: 1.2715 - val_acc: 0.5502\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.0885 - acc: 0.6163 - val_loss: 1.2780 - val_acc: 0.5514\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.0860 - acc: 0.6160 - val_loss: 1.2827 - val_acc: 0.5496\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.0822 - acc: 0.6169 - val_loss: 1.2823 - val_acc: 0.5508\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.0802 - acc: 0.6203 - val_loss: 1.2838 - val_acc: 0.5491\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.0726 - acc: 0.6195 - val_loss: 1.3001 - val_acc: 0.5511\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.0678 - acc: 0.6205 - val_loss: 1.2913 - val_acc: 0.5500\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.0650 - acc: 0.6243 - val_loss: 1.2872 - val_acc: 0.5493\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.0588 - acc: 0.6255 - val_loss: 1.2881 - val_acc: 0.5502\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.0526 - acc: 0.6266 - val_loss: 1.2864 - val_acc: 0.5494\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.0492 - acc: 0.6288 - val_loss: 1.2985 - val_acc: 0.5442\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 1.0451 - acc: 0.6284 - val_loss: 1.3047 - val_acc: 0.5458\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.0432 - acc: 0.6291 - val_loss: 1.3008 - val_acc: 0.5511\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.0387 - acc: 0.6313 - val_loss: 1.2982 - val_acc: 0.5491\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.0334 - acc: 0.6337 - val_loss: 1.3250 - val_acc: 0.5488\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.0292 - acc: 0.6345 - val_loss: 1.3248 - val_acc: 0.5527\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.0221 - acc: 0.6386 - val_loss: 1.3178 - val_acc: 0.5491\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.0217 - acc: 0.6393 - val_loss: 1.3095 - val_acc: 0.5511\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.0146 - acc: 0.6396 - val_loss: 1.3073 - val_acc: 0.5500\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.0070 - acc: 0.6400 - val_loss: 1.3139 - val_acc: 0.5516\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.0043 - acc: 0.6429 - val_loss: 1.3292 - val_acc: 0.5469\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 0.9972 - acc: 0.6484 - val_loss: 1.3333 - val_acc: 0.5472\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 0.9965 - acc: 0.6473 - val_loss: 1.3305 - val_acc: 0.5508\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 0.9919 - acc: 0.6486 - val_loss: 1.3393 - val_acc: 0.5452\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.9880 - acc: 0.6513 - val_loss: 1.3409 - val_acc: 0.5482\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 0.9820 - acc: 0.6511 - val_loss: 1.3567 - val_acc: 0.5484\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 0.9743 - acc: 0.6548 - val_loss: 1.3482 - val_acc: 0.5445\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 0.9722 - acc: 0.6548 - val_loss: 1.3638 - val_acc: 0.5416\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.9677 - acc: 0.6570 - val_loss: 1.3438 - val_acc: 0.5470\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.9621 - acc: 0.6602 - val_loss: 1.3529 - val_acc: 0.5478\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 0.9575 - acc: 0.6589 - val_loss: 1.3417 - val_acc: 0.5479\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 9s 229us/step - loss: 0.9532 - acc: 0.6631 - val_loss: 1.3711 - val_acc: 0.5461\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 0.9471 - acc: 0.6628 - val_loss: 1.3556 - val_acc: 0.5494\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.9430 - acc: 0.6658 - val_loss: 1.3641 - val_acc: 0.5462\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 0.9362 - acc: 0.6667 - val_loss: 1.3677 - val_acc: 0.5455\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.9342 - acc: 0.6684 - val_loss: 1.3690 - val_acc: 0.5492\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 0.9262 - acc: 0.6711 - val_loss: 1.3625 - val_acc: 0.5453\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 0.9231 - acc: 0.6737 - val_loss: 1.3863 - val_acc: 0.5466\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 0.9196 - acc: 0.6734 - val_loss: 1.3805 - val_acc: 0.5443\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 0.9149 - acc: 0.6738 - val_loss: 1.4002 - val_acc: 0.5483\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 0.9120 - acc: 0.6748 - val_loss: 1.3912 - val_acc: 0.5417\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.9064 - acc: 0.6777 - val_loss: 1.3966 - val_acc: 0.5401\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.8988 - acc: 0.6795 - val_loss: 1.4124 - val_acc: 0.5338\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 0.8961 - acc: 0.6801 - val_loss: 1.4085 - val_acc: 0.5431\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 0.8931 - acc: 0.6823 - val_loss: 1.4108 - val_acc: 0.5421\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 0.8825 - acc: 0.6858 - val_loss: 1.4128 - val_acc: 0.5375\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 0.8838 - acc: 0.6855 - val_loss: 1.4320 - val_acc: 0.5394\n",
      "10000/10000 [==============================] - 3s 272us/step\n",
      "Validation loss: 1.4319536470770835\n",
      "Validation accuracy (NORMALIZED): 0.5394000061228872\n",
      "================================================\n",
      "Split: 3\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 11s 268us/step - loss: 1.8263 - acc: 0.3434 - val_loss: 1.5200 - val_acc: 0.4597\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.5510 - acc: 0.4464 - val_loss: 1.4496 - val_acc: 0.4847\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 1.4843 - acc: 0.4757 - val_loss: 1.4089 - val_acc: 0.4994\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 10s 253us/step - loss: 1.4418 - acc: 0.4877 - val_loss: 1.3805 - val_acc: 0.5063\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.4142 - acc: 0.5009 - val_loss: 1.3673 - val_acc: 0.5125\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.3925 - acc: 0.5083 - val_loss: 1.3643 - val_acc: 0.5130\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.3796 - acc: 0.5122 - val_loss: 1.3515 - val_acc: 0.5130\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.3622 - acc: 0.5191 - val_loss: 1.3420 - val_acc: 0.5217\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.3541 - acc: 0.5243 - val_loss: 1.3276 - val_acc: 0.5260\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.3400 - acc: 0.5274 - val_loss: 1.3221 - val_acc: 0.5298\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.3290 - acc: 0.5318 - val_loss: 1.3172 - val_acc: 0.5287\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.3179 - acc: 0.5345 - val_loss: 1.3240 - val_acc: 0.5261\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.3118 - acc: 0.5370 - val_loss: 1.3097 - val_acc: 0.5335\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.3023 - acc: 0.5403 - val_loss: 1.2990 - val_acc: 0.5348\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.2936 - acc: 0.5411 - val_loss: 1.2988 - val_acc: 0.5366\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.2865 - acc: 0.5462 - val_loss: 1.2963 - val_acc: 0.5368\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.2836 - acc: 0.5483 - val_loss: 1.2967 - val_acc: 0.5400\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.2706 - acc: 0.5507 - val_loss: 1.2927 - val_acc: 0.5403\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.2686 - acc: 0.5530 - val_loss: 1.2889 - val_acc: 0.5377\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.2606 - acc: 0.5544 - val_loss: 1.2855 - val_acc: 0.5402\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.2528 - acc: 0.5585 - val_loss: 1.2796 - val_acc: 0.5433\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.2465 - acc: 0.5583 - val_loss: 1.2873 - val_acc: 0.5443\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.2427 - acc: 0.5596 - val_loss: 1.2786 - val_acc: 0.5427\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.2356 - acc: 0.5633 - val_loss: 1.2786 - val_acc: 0.5439\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.2301 - acc: 0.5646 - val_loss: 1.2768 - val_acc: 0.5429\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.2266 - acc: 0.5639 - val_loss: 1.2840 - val_acc: 0.5433\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.2201 - acc: 0.5672 - val_loss: 1.2910 - val_acc: 0.5419\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.2122 - acc: 0.5708 - val_loss: 1.2821 - val_acc: 0.5426\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.2111 - acc: 0.5726 - val_loss: 1.2864 - val_acc: 0.5449\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.2072 - acc: 0.5723 - val_loss: 1.2768 - val_acc: 0.5475\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.1995 - acc: 0.5767 - val_loss: 1.2812 - val_acc: 0.5466\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.1929 - acc: 0.5772 - val_loss: 1.2908 - val_acc: 0.5418\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.1879 - acc: 0.5786 - val_loss: 1.2789 - val_acc: 0.5459\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.1842 - acc: 0.5799 - val_loss: 1.2805 - val_acc: 0.5489\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.1780 - acc: 0.5843 - val_loss: 1.2697 - val_acc: 0.5510\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.1728 - acc: 0.5841 - val_loss: 1.2770 - val_acc: 0.5507\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.1672 - acc: 0.5872 - val_loss: 1.2737 - val_acc: 0.5491\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.1656 - acc: 0.5867 - val_loss: 1.2835 - val_acc: 0.5429\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.1598 - acc: 0.5879 - val_loss: 1.2698 - val_acc: 0.5519\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.1532 - acc: 0.5921 - val_loss: 1.2728 - val_acc: 0.5518\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.1472 - acc: 0.5934 - val_loss: 1.2789 - val_acc: 0.5482\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.1434 - acc: 0.5952 - val_loss: 1.2873 - val_acc: 0.5505\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.1402 - acc: 0.5951 - val_loss: 1.2769 - val_acc: 0.5501\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 1.1341 - acc: 0.6002 - val_loss: 1.2927 - val_acc: 0.5472\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.1326 - acc: 0.5962 - val_loss: 1.2746 - val_acc: 0.5503\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.1276 - acc: 0.5999 - val_loss: 1.2779 - val_acc: 0.5514\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.1205 - acc: 0.6033 - val_loss: 1.2793 - val_acc: 0.5526\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.1203 - acc: 0.6014 - val_loss: 1.2798 - val_acc: 0.5498\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.1117 - acc: 0.6051 - val_loss: 1.2793 - val_acc: 0.5536\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.1084 - acc: 0.6066 - val_loss: 1.2826 - val_acc: 0.5515\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.1038 - acc: 0.6086 - val_loss: 1.2818 - val_acc: 0.5539\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.0971 - acc: 0.6090 - val_loss: 1.2866 - val_acc: 0.5489\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.0960 - acc: 0.6107 - val_loss: 1.2835 - val_acc: 0.5525\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.0875 - acc: 0.6146 - val_loss: 1.2932 - val_acc: 0.5488\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.0828 - acc: 0.6164 - val_loss: 1.2834 - val_acc: 0.5513\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.0797 - acc: 0.6169 - val_loss: 1.2829 - val_acc: 0.5483\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.0746 - acc: 0.6181 - val_loss: 1.2986 - val_acc: 0.5493\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.0718 - acc: 0.6183 - val_loss: 1.2883 - val_acc: 0.5507\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.0657 - acc: 0.6229 - val_loss: 1.2955 - val_acc: 0.5521\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.0644 - acc: 0.6220 - val_loss: 1.2914 - val_acc: 0.5501\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.0557 - acc: 0.6230 - val_loss: 1.2990 - val_acc: 0.5522\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.0495 - acc: 0.6251 - val_loss: 1.2963 - val_acc: 0.5488\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.0469 - acc: 0.6283 - val_loss: 1.2999 - val_acc: 0.5503\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.0431 - acc: 0.6287 - val_loss: 1.2946 - val_acc: 0.5454\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.0377 - acc: 0.6298 - val_loss: 1.3198 - val_acc: 0.5451\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.0303 - acc: 0.6323 - val_loss: 1.3077 - val_acc: 0.5490\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.0299 - acc: 0.6346 - val_loss: 1.3043 - val_acc: 0.5508\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.0236 - acc: 0.6364 - val_loss: 1.3182 - val_acc: 0.5455\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.0186 - acc: 0.6374 - val_loss: 1.3186 - val_acc: 0.5495\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.0146 - acc: 0.6371 - val_loss: 1.3059 - val_acc: 0.5482\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.0067 - acc: 0.6405 - val_loss: 1.3299 - val_acc: 0.5462\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.0059 - acc: 0.6421 - val_loss: 1.3191 - val_acc: 0.5504\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.0026 - acc: 0.6432 - val_loss: 1.3373 - val_acc: 0.5539\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 0.9929 - acc: 0.6456 - val_loss: 1.3408 - val_acc: 0.5449\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 0.9923 - acc: 0.6463 - val_loss: 1.3504 - val_acc: 0.5473\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 0.9865 - acc: 0.6494 - val_loss: 1.3331 - val_acc: 0.5464\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.9810 - acc: 0.6509 - val_loss: 1.3432 - val_acc: 0.5479\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 0.9744 - acc: 0.6542 - val_loss: 1.3352 - val_acc: 0.5468\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 0.9721 - acc: 0.6547 - val_loss: 1.3451 - val_acc: 0.5438\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 0.9678 - acc: 0.6544 - val_loss: 1.3329 - val_acc: 0.5463\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 0.9632 - acc: 0.6568 - val_loss: 1.3440 - val_acc: 0.5484\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 0.9574 - acc: 0.6589 - val_loss: 1.3482 - val_acc: 0.5464\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 0.9540 - acc: 0.6599 - val_loss: 1.3611 - val_acc: 0.5456\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.9474 - acc: 0.6627 - val_loss: 1.3635 - val_acc: 0.5429\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 0.9434 - acc: 0.6633 - val_loss: 1.3722 - val_acc: 0.5397\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 0.9385 - acc: 0.6651 - val_loss: 1.3597 - val_acc: 0.5423\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.9371 - acc: 0.6667 - val_loss: 1.3552 - val_acc: 0.5462\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 0.9279 - acc: 0.6666 - val_loss: 1.3733 - val_acc: 0.5441\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 0.9242 - acc: 0.6713 - val_loss: 1.3777 - val_acc: 0.5432\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 0.9193 - acc: 0.6703 - val_loss: 1.3914 - val_acc: 0.5441\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.9145 - acc: 0.6727 - val_loss: 1.3967 - val_acc: 0.5419\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.9110 - acc: 0.6749 - val_loss: 1.3963 - val_acc: 0.5455\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.9039 - acc: 0.6781 - val_loss: 1.4062 - val_acc: 0.5403\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.9020 - acc: 0.6797 - val_loss: 1.3943 - val_acc: 0.5388\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 10s 251us/step - loss: 0.8954 - acc: 0.6809 - val_loss: 1.4305 - val_acc: 0.5433\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 0.8909 - acc: 0.6820 - val_loss: 1.4046 - val_acc: 0.5389\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 0.8871 - acc: 0.6825 - val_loss: 1.4264 - val_acc: 0.5397\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.8845 - acc: 0.6857 - val_loss: 1.4147 - val_acc: 0.5402\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 0.8777 - acc: 0.6847 - val_loss: 1.4379 - val_acc: 0.5377\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 0.8711 - acc: 0.6884 - val_loss: 1.4502 - val_acc: 0.5356\n",
      "10000/10000 [==============================] - 3s 308us/step\n",
      "Validation loss: 1.4502276752442123\n",
      "Validation accuracy (NORMALIZED): 0.5356000067591667\n",
      "================================================\n",
      "Split: 4\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 11s 284us/step - loss: 1.8566 - acc: 0.3315 - val_loss: 1.5252 - val_acc: 0.4547\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.5518 - acc: 0.4507 - val_loss: 1.4502 - val_acc: 0.4806\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.4865 - acc: 0.4748 - val_loss: 1.4182 - val_acc: 0.4949\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.4469 - acc: 0.4854 - val_loss: 1.3929 - val_acc: 0.5003\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 10s 251us/step - loss: 1.4210 - acc: 0.4981 - val_loss: 1.3701 - val_acc: 0.5137\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.3996 - acc: 0.5055 - val_loss: 1.3690 - val_acc: 0.5111\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.3818 - acc: 0.5140 - val_loss: 1.3504 - val_acc: 0.5183\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.3640 - acc: 0.5178 - val_loss: 1.3405 - val_acc: 0.5194\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.3522 - acc: 0.5249 - val_loss: 1.3382 - val_acc: 0.5235\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.3397 - acc: 0.5292 - val_loss: 1.3299 - val_acc: 0.5248\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.3288 - acc: 0.5333 - val_loss: 1.3229 - val_acc: 0.5253\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.3194 - acc: 0.5350 - val_loss: 1.3124 - val_acc: 0.5322\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.3114 - acc: 0.5390 - val_loss: 1.3166 - val_acc: 0.5326\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.3039 - acc: 0.5405 - val_loss: 1.3139 - val_acc: 0.5313\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.2912 - acc: 0.5453 - val_loss: 1.3169 - val_acc: 0.5308\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.2877 - acc: 0.5482 - val_loss: 1.2996 - val_acc: 0.5362\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.2794 - acc: 0.5499 - val_loss: 1.3000 - val_acc: 0.5385\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.2710 - acc: 0.5508 - val_loss: 1.2962 - val_acc: 0.5376\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.2661 - acc: 0.5524 - val_loss: 1.2957 - val_acc: 0.5395\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.2597 - acc: 0.5549 - val_loss: 1.3014 - val_acc: 0.5369\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 1.2536 - acc: 0.5561 - val_loss: 1.2999 - val_acc: 0.5390\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 10s 256us/step - loss: 1.2513 - acc: 0.5593 - val_loss: 1.2876 - val_acc: 0.5423\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.2414 - acc: 0.5605 - val_loss: 1.2835 - val_acc: 0.5440\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.2362 - acc: 0.5625 - val_loss: 1.2910 - val_acc: 0.5446\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.2316 - acc: 0.5655 - val_loss: 1.2947 - val_acc: 0.5400\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 10s 260us/step - loss: 1.2256 - acc: 0.5667 - val_loss: 1.2883 - val_acc: 0.5443\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.2201 - acc: 0.5723 - val_loss: 1.2822 - val_acc: 0.5436\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.2139 - acc: 0.5713 - val_loss: 1.2872 - val_acc: 0.5434\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.2106 - acc: 0.5711 - val_loss: 1.2929 - val_acc: 0.5376\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 1.2022 - acc: 0.5754 - val_loss: 1.2828 - val_acc: 0.5434\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.1992 - acc: 0.5741 - val_loss: 1.2811 - val_acc: 0.5436\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 10s 251us/step - loss: 1.1930 - acc: 0.5774 - val_loss: 1.2808 - val_acc: 0.5449\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.1887 - acc: 0.5795 - val_loss: 1.2846 - val_acc: 0.5460\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.1876 - acc: 0.5780 - val_loss: 1.2818 - val_acc: 0.5457\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.1792 - acc: 0.5827 - val_loss: 1.2811 - val_acc: 0.5419\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.1741 - acc: 0.5834 - val_loss: 1.2800 - val_acc: 0.5477\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.1695 - acc: 0.5880 - val_loss: 1.2812 - val_acc: 0.5476\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.1663 - acc: 0.5876 - val_loss: 1.2858 - val_acc: 0.5460\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.1609 - acc: 0.5894 - val_loss: 1.2764 - val_acc: 0.5436\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 1.1569 - acc: 0.5925 - val_loss: 1.2810 - val_acc: 0.5461\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 10s 261us/step - loss: 1.1511 - acc: 0.5948 - val_loss: 1.2799 - val_acc: 0.5454\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 11s 266us/step - loss: 1.1510 - acc: 0.5941 - val_loss: 1.2760 - val_acc: 0.5461\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 10s 257us/step - loss: 1.1417 - acc: 0.5979 - val_loss: 1.2859 - val_acc: 0.5475\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 1.1386 - acc: 0.5972 - val_loss: 1.2830 - val_acc: 0.5469\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 1.1352 - acc: 0.5979 - val_loss: 1.2902 - val_acc: 0.5475\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.1307 - acc: 0.6001 - val_loss: 1.2811 - val_acc: 0.5472\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.1240 - acc: 0.6019 - val_loss: 1.2811 - val_acc: 0.5456\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.1199 - acc: 0.6015 - val_loss: 1.2886 - val_acc: 0.5485\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.1166 - acc: 0.6042 - val_loss: 1.2899 - val_acc: 0.5460\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.1116 - acc: 0.6042 - val_loss: 1.2871 - val_acc: 0.5504\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.1048 - acc: 0.6079 - val_loss: 1.2820 - val_acc: 0.5479\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.1028 - acc: 0.6104 - val_loss: 1.2901 - val_acc: 0.5463\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.0983 - acc: 0.6092 - val_loss: 1.2870 - val_acc: 0.5497\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.0936 - acc: 0.6129 - val_loss: 1.3150 - val_acc: 0.5456\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.0881 - acc: 0.6135 - val_loss: 1.2857 - val_acc: 0.5475\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.0843 - acc: 0.6157 - val_loss: 1.2968 - val_acc: 0.5465\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.0837 - acc: 0.6124 - val_loss: 1.3037 - val_acc: 0.5469\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 10s 254us/step - loss: 1.0788 - acc: 0.6172 - val_loss: 1.3095 - val_acc: 0.5435\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 10s 256us/step - loss: 1.0725 - acc: 0.6192 - val_loss: 1.2934 - val_acc: 0.5452\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.0687 - acc: 0.6216 - val_loss: 1.2952 - val_acc: 0.5455\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.0625 - acc: 0.6229 - val_loss: 1.2959 - val_acc: 0.5489\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.0603 - acc: 0.6241 - val_loss: 1.2954 - val_acc: 0.5486\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.0558 - acc: 0.6247 - val_loss: 1.2952 - val_acc: 0.5478\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.0487 - acc: 0.6287 - val_loss: 1.3117 - val_acc: 0.5461\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.0448 - acc: 0.6295 - val_loss: 1.3051 - val_acc: 0.5454\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.0418 - acc: 0.6307 - val_loss: 1.3159 - val_acc: 0.5445\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.0380 - acc: 0.6312 - val_loss: 1.3089 - val_acc: 0.5475\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.0353 - acc: 0.6330 - val_loss: 1.3213 - val_acc: 0.5461\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.0291 - acc: 0.6348 - val_loss: 1.3149 - val_acc: 0.5446\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.0217 - acc: 0.6370 - val_loss: 1.3440 - val_acc: 0.5342\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.0179 - acc: 0.6393 - val_loss: 1.3241 - val_acc: 0.5436\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.0157 - acc: 0.6384 - val_loss: 1.3315 - val_acc: 0.5451\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.0100 - acc: 0.6399 - val_loss: 1.3302 - val_acc: 0.5453\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.0068 - acc: 0.6431 - val_loss: 1.3396 - val_acc: 0.5443\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 0.9986 - acc: 0.6450 - val_loss: 1.3384 - val_acc: 0.5413\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.9953 - acc: 0.6476 - val_loss: 1.3309 - val_acc: 0.5421\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 0.9933 - acc: 0.6490 - val_loss: 1.3535 - val_acc: 0.5461\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.9880 - acc: 0.6499 - val_loss: 1.3528 - val_acc: 0.5400\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 0.9853 - acc: 0.6504 - val_loss: 1.3301 - val_acc: 0.5455\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 0.9815 - acc: 0.6528 - val_loss: 1.3363 - val_acc: 0.5424\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.9758 - acc: 0.6534 - val_loss: 1.3480 - val_acc: 0.5416\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.9740 - acc: 0.6545 - val_loss: 1.3470 - val_acc: 0.5395\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 11s 266us/step - loss: 0.9663 - acc: 0.6581 - val_loss: 1.3464 - val_acc: 0.5408\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 10s 258us/step - loss: 0.9606 - acc: 0.6579 - val_loss: 1.3743 - val_acc: 0.5417\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 11s 268us/step - loss: 0.9591 - acc: 0.6586 - val_loss: 1.3802 - val_acc: 0.5380\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 0.9535 - acc: 0.6608 - val_loss: 1.3656 - val_acc: 0.5400\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 11s 268us/step - loss: 0.9517 - acc: 0.6633 - val_loss: 1.3639 - val_acc: 0.5420\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 10s 258us/step - loss: 0.9444 - acc: 0.6644 - val_loss: 1.3800 - val_acc: 0.5401\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 10s 256us/step - loss: 0.9423 - acc: 0.6653 - val_loss: 1.3795 - val_acc: 0.5435\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 10s 254us/step - loss: 0.9337 - acc: 0.6656 - val_loss: 1.3952 - val_acc: 0.5363\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 11s 268us/step - loss: 0.9313 - acc: 0.6709 - val_loss: 1.3854 - val_acc: 0.5417\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 10s 255us/step - loss: 0.9264 - acc: 0.6714 - val_loss: 1.3763 - val_acc: 0.5416\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 10s 253us/step - loss: 0.9247 - acc: 0.6709 - val_loss: 1.3816 - val_acc: 0.5417\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 10s 251us/step - loss: 0.9159 - acc: 0.6739 - val_loss: 1.3767 - val_acc: 0.5383\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 10s 260us/step - loss: 0.9148 - acc: 0.6742 - val_loss: 1.3879 - val_acc: 0.5370\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 10s 259us/step - loss: 0.9095 - acc: 0.6766 - val_loss: 1.4014 - val_acc: 0.5369\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 10s 257us/step - loss: 0.9045 - acc: 0.6774 - val_loss: 1.4310 - val_acc: 0.5377\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.9024 - acc: 0.6781 - val_loss: 1.4254 - val_acc: 0.5379\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 0.8958 - acc: 0.6813 - val_loss: 1.4253 - val_acc: 0.5419\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 0.8947 - acc: 0.6794 - val_loss: 1.4467 - val_acc: 0.5355\n",
      "10000/10000 [==============================] - 3s 308us/step\n",
      "Validation loss: 1.44670917083323\n",
      "Validation accuracy (NORMALIZED): 0.5355000059753656\n",
      "[[1.4240833519101144, 0.5449000060409307], [1.4518084926903247, 0.541300005659461], [1.4319536470770835, 0.5394000061228872], [1.4502276752442123, 0.5356000067591667], [1.44670917083323, 0.5355000059753656]]\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Training model and Evaluation\n",
    "#=====================================\n",
    "\n",
    "y_train_categorical = to_categorical(y_train, num_classes=n_classes)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=n_classes)\n",
    "\n",
    "scores = []\n",
    "for i in range(folds):\n",
    "    #--- Loading model\n",
    "    model = get_squeezenet_ft2()    \n",
    "    \n",
    "    #--- Evaluating the model for split i\n",
    "    print(\"================================================\")\n",
    "    print(\"Split: \"+str(i))\n",
    "    print(\"Number of Epochs: \"+str(n_epochs))\n",
    "    print(\"Train shape:\",X_train[i].shape)\n",
    "    print(\"Train batch size: \"+str(train_batch_size))\n",
    "    print(\"Val batch size: \"+str(val_batch_size))\n",
    "    print(\"================================================\")\n",
    "    \n",
    "    # Training without data augmentation\n",
    "    model.fit(X_train[i],y_train_categorical[i], batch_size=train_batch_size,\n",
    "              epochs=n_epochs, \n",
    "              validation_data=(X_val[i],y_val_categorical[i]),              \n",
    "              verbose=1)\n",
    "    \n",
    "    #--- Evaluating the model for split i\n",
    "    score = model.evaluate(x=X_val[i], y=y_val_categorical[i], batch_size=val_batch_size, verbose=1)\n",
    "    scores.append(score)\n",
    "    print('Validation loss:', score[0])\n",
    "    print('Validation accuracy (NORMALIZED):', score[1])\n",
    "    \n",
    "#--- Showing scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation loss: 1.440956467550993\n",
      "Mean Validation accuracy (NORMALIZED): 0.5393400061115623\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Evaluate on validation\n",
    "#=====================================\n",
    "\n",
    "#--- The evaluation of the model \n",
    "np_aux = np.array(scores).mean(axis=0)\n",
    "\n",
    "print('Mean Validation loss:', np_aux[0])\n",
    "print('Mean Validation accuracy (NORMALIZED):', np_aux[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "# Tensorboard\n",
    "\n",
    "Tensorboard is a visualization tool for Tensorflow. Among other things, it allows us to monitor the progress of our training, plot metrics per epochs, visualize the architecture's schematics. \n",
    "\n",
    "Just like for Early Stopping, we will use the [Tensorboard callback](https://keras.io/callbacks/#tensorboard) to log the information about our training. An example of usage, would be:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Just an example, DON'T RUN! \n",
    "### You will need to change <<LOG_DIR>>\n",
    "import keras.callbacks as callbacks\n",
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./<<LOG_DIR>>\")\n",
    "model.fit(..., callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your training progresses, Keras will log the metrics (e.g., loss, accuracy) to `<<LOG_DIR>>` (**make sure `<<LOG_DIR>>` is a valid directory)**. On your terminal, you will need to run Tensorboard, assign a port and access it via browser (just like jupyter).\n",
    "\n",
    "#### ----> MAKE SURE YOU USE A DIFFERENT PORT FOR JUPYTER AND TENSORBOARD <----\n",
    "\n",
    "### Docker\n",
    "For those using docker, open a new terminal and create a new container (using the same image) running Tensorboard:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ docker run -it -p <<port_host>>:<<port_container>>\n",
    "            --volume=<<LOG_DIR>>:<<LOG_DIR>>\n",
    "            --name=<<container_name>> <<docker_image>> \n",
    "            tensorboard --logdir=<<LOG_DIR>> --port=<<port_container>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ docker run -it -p 8887:8887\n",
    "            --volume=/your/path/ml2018/:/ml2018\n",
    "            --name=mdc_container_tensorboard mdc-keras:cpu\n",
    "            tensorboard --logdir=/ml2018/logs --port=8887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After starting Tensorboard, access it via browser on `http://localhost:<<port_container>>`.\n",
    "\n",
    "### Anaconda\n",
    "$ tensorboard --logdir=<<LOG_DIR>> --port=<<port>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After starting Tensorboard, access it via browser on `http://localhost:<<port>>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "\n",
    "# Fine-tuning all layers\n",
    "\n",
    "What if we fine-tune all layers of SqueezeNet?\n",
    "<img src=\"unfrozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Compiling model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 10)     5130        drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 10)     0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_26 (Gl (None, 10)           0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 10)           0           global_average_pooling2d_26[0][0]\n",
      "==================================================================================================\n",
      "Total params: 727,626\n",
      "Trainable params: 727,626\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_squeezenet_ft3():\n",
    "    squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "    for layer in squeezeNetModel.layers:\n",
    "        layer.trainable = True       #by default they are all trainable, but just for clarification\n",
    "\n",
    "    #=====================================\n",
    "    # Add new classification layers\n",
    "    #=====================================\n",
    "\n",
    "    #--- Removing layers until drop 9\n",
    "    squeezeNetModel.layers.pop() #Convolution2D\n",
    "    squeezeNetModel.layers.pop() #Activation ReLU\n",
    "    squeezeNetModel.layers.pop() #Global Avg Pool\n",
    "    squeezeNetModel.layers.pop() #Activation Softmax\n",
    "\n",
    "    #--- Adding classification layer for 10 classes\n",
    "    out = Convolution2D(n_classes, (1, 1), padding='valid', name='conv10')(squeezeNetModel.layers[-1].output)\n",
    "    out = Activation('relu', name='relu_conv10')(out)\n",
    "\n",
    "    out = GlobalAveragePooling2D()(out)\n",
    "    out = Activation('softmax', name='loss')(out)\n",
    "\n",
    "    #=====================================\n",
    "    # New Model\n",
    "    #=====================================\n",
    "    model = Model(squeezeNetModel.inputs, out, name='squeezenet_new')\n",
    "    opt = optimizer=optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#SGD(lr=learning_rate)\n",
    "    print(\"--- Compiling model\")\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_squeezenet_ft3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542669991.6610415\n",
      "--- Start training\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 0\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 20s 501us/step - loss: 1.4881 - acc: 0.4816 - val_loss: 1.0885 - val_acc: 0.6225\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 19s 466us/step - loss: 1.0394 - acc: 0.6466 - val_loss: 0.9641 - val_acc: 0.6703\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 19s 463us/step - loss: 0.9073 - acc: 0.6976 - val_loss: 0.8898 - val_acc: 0.6986\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.8210 - acc: 0.7279 - val_loss: 0.8243 - val_acc: 0.7176\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 19s 464us/step - loss: 0.7565 - acc: 0.7474 - val_loss: 0.7892 - val_acc: 0.7306\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 18s 457us/step - loss: 0.7048 - acc: 0.7652 - val_loss: 0.8129 - val_acc: 0.7231\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 19s 467us/step - loss: 0.6514 - acc: 0.7826 - val_loss: 0.7810 - val_acc: 0.7426\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 19s 466us/step - loss: 0.6117 - acc: 0.7971 - val_loss: 0.7607 - val_acc: 0.7469\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 19s 464us/step - loss: 0.5765 - acc: 0.8080 - val_loss: 0.7604 - val_acc: 0.7410\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 18s 454us/step - loss: 0.5371 - acc: 0.8198 - val_loss: 0.7710 - val_acc: 0.7439\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 19s 478us/step - loss: 0.5068 - acc: 0.8335 - val_loss: 0.7869 - val_acc: 0.7460\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 19s 464us/step - loss: 0.4748 - acc: 0.8428 - val_loss: 0.7649 - val_acc: 0.7536\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 19s 463us/step - loss: 0.4418 - acc: 0.8532 - val_loss: 0.7686 - val_acc: 0.7565\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 18s 462us/step - loss: 0.4186 - acc: 0.8612 - val_loss: 0.7825 - val_acc: 0.7611\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 19s 466us/step - loss: 0.3916 - acc: 0.8699 - val_loss: 0.8239 - val_acc: 0.7567\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 19s 463us/step - loss: 0.3646 - acc: 0.8801 - val_loss: 0.8447 - val_acc: 0.7584\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 19s 472us/step - loss: 0.3454 - acc: 0.8869 - val_loss: 0.8330 - val_acc: 0.7578\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 19s 464us/step - loss: 0.3230 - acc: 0.8946 - val_loss: 0.8664 - val_acc: 0.7589\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 19s 468us/step - loss: 0.3069 - acc: 0.8983 - val_loss: 0.9117 - val_acc: 0.7522\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 19s 468us/step - loss: 0.2853 - acc: 0.9060 - val_loss: 0.9912 - val_acc: 0.7488\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 19s 472us/step - loss: 0.2677 - acc: 0.9124 - val_loss: 0.9200 - val_acc: 0.7593\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 19s 474us/step - loss: 0.2550 - acc: 0.9162 - val_loss: 0.9555 - val_acc: 0.7592\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.2393 - acc: 0.9209 - val_loss: 0.9563 - val_acc: 0.7657\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.2259 - acc: 0.9264 - val_loss: 0.9957 - val_acc: 0.7632\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.2131 - acc: 0.9305 - val_loss: 1.0869 - val_acc: 0.7540\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.2055 - acc: 0.9337 - val_loss: 1.0362 - val_acc: 0.7637\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.1942 - acc: 0.9358 - val_loss: 1.1125 - val_acc: 0.7507\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.1856 - acc: 0.9398 - val_loss: 1.0949 - val_acc: 0.7623\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.1707 - acc: 0.9434 - val_loss: 1.1370 - val_acc: 0.7601\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.1626 - acc: 0.9469 - val_loss: 1.1569 - val_acc: 0.7563\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.1587 - acc: 0.9492 - val_loss: 1.1388 - val_acc: 0.7598\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.1523 - acc: 0.9515 - val_loss: 1.1907 - val_acc: 0.7621\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.1409 - acc: 0.9552 - val_loss: 1.2010 - val_acc: 0.7589\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.1340 - acc: 0.9563 - val_loss: 1.2661 - val_acc: 0.7581\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.1324 - acc: 0.9576 - val_loss: 1.2053 - val_acc: 0.7630\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.1228 - acc: 0.9605 - val_loss: 1.2850 - val_acc: 0.7528\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.1270 - acc: 0.9597 - val_loss: 1.2990 - val_acc: 0.7472\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.1193 - acc: 0.9621 - val_loss: 1.2436 - val_acc: 0.7620\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.1071 - acc: 0.9662 - val_loss: 1.2812 - val_acc: 0.7489\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 18s 454us/step - loss: 0.1106 - acc: 0.9650 - val_loss: 1.2685 - val_acc: 0.7565\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.1043 - acc: 0.9679 - val_loss: 1.2813 - val_acc: 0.7573\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0976 - acc: 0.9697 - val_loss: 1.3400 - val_acc: 0.7584\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.1008 - acc: 0.9689 - val_loss: 1.3782 - val_acc: 0.7571\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.0891 - acc: 0.9722 - val_loss: 1.3200 - val_acc: 0.7596\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0885 - acc: 0.9727 - val_loss: 1.3854 - val_acc: 0.7569\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0922 - acc: 0.9712 - val_loss: 1.3381 - val_acc: 0.7591\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0826 - acc: 0.9744 - val_loss: 1.4342 - val_acc: 0.7554\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.0819 - acc: 0.9743 - val_loss: 1.3872 - val_acc: 0.7555\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0808 - acc: 0.9752 - val_loss: 1.4299 - val_acc: 0.7461\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0775 - acc: 0.9763 - val_loss: 1.4785 - val_acc: 0.7600\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0764 - acc: 0.9771 - val_loss: 1.4411 - val_acc: 0.7611\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0760 - acc: 0.9765 - val_loss: 1.6129 - val_acc: 0.7423\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0684 - acc: 0.9790 - val_loss: 1.4998 - val_acc: 0.7560\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.0700 - acc: 0.9785 - val_loss: 1.5494 - val_acc: 0.7595\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0701 - acc: 0.9780 - val_loss: 1.4499 - val_acc: 0.7550\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.0638 - acc: 0.9803 - val_loss: 1.4713 - val_acc: 0.7582\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0651 - acc: 0.9800 - val_loss: 1.4867 - val_acc: 0.7589\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0665 - acc: 0.9797 - val_loss: 1.4441 - val_acc: 0.7593\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.0623 - acc: 0.9811 - val_loss: 1.4963 - val_acc: 0.7539\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0636 - acc: 0.9806 - val_loss: 1.6365 - val_acc: 0.7447\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0569 - acc: 0.9826 - val_loss: 1.5279 - val_acc: 0.7581\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.0632 - acc: 0.9802 - val_loss: 1.5777 - val_acc: 0.7488\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0552 - acc: 0.9826 - val_loss: 1.5988 - val_acc: 0.7560\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0590 - acc: 0.9817 - val_loss: 1.5510 - val_acc: 0.7569\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 17s 423us/step - loss: 0.0575 - acc: 0.9824 - val_loss: 1.6397 - val_acc: 0.7491\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.0558 - acc: 0.9828 - val_loss: 1.5977 - val_acc: 0.7514\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 16s 412us/step - loss: 0.0535 - acc: 0.9836 - val_loss: 1.6217 - val_acc: 0.7575\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 16s 410us/step - loss: 0.0572 - acc: 0.9831 - val_loss: 1.5168 - val_acc: 0.7570\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 16s 411us/step - loss: 0.0491 - acc: 0.9848 - val_loss: 1.4878 - val_acc: 0.7558\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 16s 412us/step - loss: 0.0499 - acc: 0.9848 - val_loss: 1.5804 - val_acc: 0.7547\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.0537 - acc: 0.9838 - val_loss: 1.6134 - val_acc: 0.7558\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.0501 - acc: 0.9841 - val_loss: 1.6100 - val_acc: 0.7620\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 16s 411us/step - loss: 0.0491 - acc: 0.9843 - val_loss: 1.6876 - val_acc: 0.7558\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.0443 - acc: 0.9859 - val_loss: 1.6090 - val_acc: 0.7606\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.0482 - acc: 0.9855 - val_loss: 1.6460 - val_acc: 0.7619\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 16s 412us/step - loss: 0.0519 - acc: 0.9849 - val_loss: 1.5686 - val_acc: 0.7593\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 16s 409us/step - loss: 0.0457 - acc: 0.9856 - val_loss: 1.6196 - val_acc: 0.7581\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.0462 - acc: 0.9855 - val_loss: 1.6381 - val_acc: 0.7571\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.0444 - acc: 0.9869 - val_loss: 1.6265 - val_acc: 0.7600\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.0461 - acc: 0.9852 - val_loss: 1.6935 - val_acc: 0.7576\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 16s 410us/step - loss: 0.0437 - acc: 0.9866 - val_loss: 1.6477 - val_acc: 0.7561\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.0449 - acc: 0.9867 - val_loss: 1.5567 - val_acc: 0.7632\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.0421 - acc: 0.9870 - val_loss: 1.6339 - val_acc: 0.7611\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.0401 - acc: 0.9879 - val_loss: 1.6434 - val_acc: 0.7561\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.0418 - acc: 0.9876 - val_loss: 1.5291 - val_acc: 0.7591\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.0415 - acc: 0.9875 - val_loss: 1.6643 - val_acc: 0.7612\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 16s 412us/step - loss: 0.0402 - acc: 0.9873 - val_loss: 1.7294 - val_acc: 0.7581\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 16s 411us/step - loss: 0.0462 - acc: 0.9858 - val_loss: 1.5415 - val_acc: 0.7572\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.0353 - acc: 0.9889 - val_loss: 1.8705 - val_acc: 0.7449\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.0409 - acc: 0.9874 - val_loss: 1.7058 - val_acc: 0.7587\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 16s 411us/step - loss: 0.0392 - acc: 0.9875 - val_loss: 1.6862 - val_acc: 0.7476\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 16s 412us/step - loss: 0.0380 - acc: 0.9886 - val_loss: 1.8131 - val_acc: 0.7461\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.0377 - acc: 0.9886 - val_loss: 1.7583 - val_acc: 0.7618\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.0411 - acc: 0.9875 - val_loss: 1.5986 - val_acc: 0.7591\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 16s 412us/step - loss: 0.0308 - acc: 0.9908 - val_loss: 1.9414 - val_acc: 0.7482\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.0415 - acc: 0.9867 - val_loss: 1.7614 - val_acc: 0.7518\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.0400 - acc: 0.9881 - val_loss: 1.5393 - val_acc: 0.7579\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.0330 - acc: 0.9898 - val_loss: 1.7565 - val_acc: 0.7530\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.0341 - acc: 0.9894 - val_loss: 1.7759 - val_acc: 0.7566\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.0361 - acc: 0.9887 - val_loss: 1.8141 - val_acc: 0.7615\n",
      "10000/10000 [==============================] - 3s 293us/step\n",
      "Validation loss: 1.814102641878854\n",
      "Validation accuracy (NORMALIZED): 0.7614999990612269\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 1\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 1.4871 - acc: 0.4886 - val_loss: 1.1396 - val_acc: 0.6128\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 1.0684 - acc: 0.6437 - val_loss: 0.9562 - val_acc: 0.6721\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 17s 429us/step - loss: 0.9205 - acc: 0.6940 - val_loss: 0.8914 - val_acc: 0.6964\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.8344 - acc: 0.7229 - val_loss: 0.8446 - val_acc: 0.7135\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.7623 - acc: 0.7471 - val_loss: 0.8628 - val_acc: 0.7107\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.7111 - acc: 0.7660 - val_loss: 0.8107 - val_acc: 0.7304\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.6650 - acc: 0.7810 - val_loss: 0.7790 - val_acc: 0.7431\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.6207 - acc: 0.7954 - val_loss: 0.7857 - val_acc: 0.7434\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.5814 - acc: 0.8093 - val_loss: 0.7770 - val_acc: 0.7424\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 17s 423us/step - loss: 0.5469 - acc: 0.8190 - val_loss: 0.7788 - val_acc: 0.7501\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.5112 - acc: 0.8330 - val_loss: 0.7512 - val_acc: 0.7553\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.4812 - acc: 0.8432 - val_loss: 0.7868 - val_acc: 0.7524\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.4504 - acc: 0.8540 - val_loss: 0.8121 - val_acc: 0.7481\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 17s 431us/step - loss: 0.4266 - acc: 0.8611 - val_loss: 0.8292 - val_acc: 0.7527\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 17s 424us/step - loss: 0.3978 - acc: 0.8702 - val_loss: 0.8471 - val_acc: 0.7471\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 17s 424us/step - loss: 0.3722 - acc: 0.8788 - val_loss: 0.9158 - val_acc: 0.7483\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.3502 - acc: 0.8865 - val_loss: 0.8777 - val_acc: 0.7553\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.3285 - acc: 0.8937 - val_loss: 0.8992 - val_acc: 0.7536\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 17s 424us/step - loss: 0.3080 - acc: 0.9012 - val_loss: 0.8853 - val_acc: 0.7526\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.2871 - acc: 0.9073 - val_loss: 0.9126 - val_acc: 0.7509\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.2720 - acc: 0.9125 - val_loss: 0.9347 - val_acc: 0.7552\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.2552 - acc: 0.9180 - val_loss: 1.0098 - val_acc: 0.7518\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.2396 - acc: 0.9234 - val_loss: 1.0193 - val_acc: 0.7459\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 17s 429us/step - loss: 0.2243 - acc: 0.9284 - val_loss: 1.0317 - val_acc: 0.7524\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.2172 - acc: 0.9327 - val_loss: 1.0112 - val_acc: 0.7527\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.2033 - acc: 0.9365 - val_loss: 1.0932 - val_acc: 0.7511\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.1857 - acc: 0.9416 - val_loss: 1.0816 - val_acc: 0.7569\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.1781 - acc: 0.9447 - val_loss: 1.1605 - val_acc: 0.7491\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.1722 - acc: 0.9454 - val_loss: 1.1491 - val_acc: 0.7514\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.1684 - acc: 0.9467 - val_loss: 1.1749 - val_acc: 0.7514\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.1502 - acc: 0.9537 - val_loss: 1.1502 - val_acc: 0.7546\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.1454 - acc: 0.9560 - val_loss: 1.2261 - val_acc: 0.7499\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.1394 - acc: 0.9577 - val_loss: 1.2722 - val_acc: 0.7494\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.1295 - acc: 0.9609 - val_loss: 1.2949 - val_acc: 0.7518\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.1318 - acc: 0.9586 - val_loss: 1.2486 - val_acc: 0.7505\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.1225 - acc: 0.9630 - val_loss: 1.3317 - val_acc: 0.7484\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.1183 - acc: 0.9645 - val_loss: 1.2531 - val_acc: 0.7510\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.1146 - acc: 0.9647 - val_loss: 1.2747 - val_acc: 0.7508\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.1072 - acc: 0.9667 - val_loss: 1.3986 - val_acc: 0.7523\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.1111 - acc: 0.9661 - val_loss: 1.3408 - val_acc: 0.7438\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.1004 - acc: 0.9703 - val_loss: 1.3740 - val_acc: 0.7546\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0959 - acc: 0.9708 - val_loss: 1.3557 - val_acc: 0.7497\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0957 - acc: 0.9712 - val_loss: 1.3758 - val_acc: 0.7500\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0959 - acc: 0.9716 - val_loss: 1.4094 - val_acc: 0.7431\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.0928 - acc: 0.9728 - val_loss: 1.2905 - val_acc: 0.7489\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0836 - acc: 0.9754 - val_loss: 1.3839 - val_acc: 0.7503\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0848 - acc: 0.9745 - val_loss: 1.4130 - val_acc: 0.7482\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0873 - acc: 0.9739 - val_loss: 1.4107 - val_acc: 0.7568\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 17s 429us/step - loss: 0.0796 - acc: 0.9759 - val_loss: 1.4137 - val_acc: 0.7521\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 17s 430us/step - loss: 0.0763 - acc: 0.9774 - val_loss: 1.4715 - val_acc: 0.7508\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0823 - acc: 0.9758 - val_loss: 1.4539 - val_acc: 0.7476\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0717 - acc: 0.9783 - val_loss: 1.4384 - val_acc: 0.7536\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0757 - acc: 0.9775 - val_loss: 1.4661 - val_acc: 0.7444\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 17s 429us/step - loss: 0.0723 - acc: 0.9779 - val_loss: 1.4631 - val_acc: 0.7480\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 17s 430us/step - loss: 0.0676 - acc: 0.9799 - val_loss: 1.6460 - val_acc: 0.7411\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.0685 - acc: 0.9796 - val_loss: 1.4245 - val_acc: 0.7568\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 17s 429us/step - loss: 0.0631 - acc: 0.9811 - val_loss: 1.5275 - val_acc: 0.7525\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0650 - acc: 0.9805 - val_loss: 1.5599 - val_acc: 0.7579\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0634 - acc: 0.9812 - val_loss: 1.4888 - val_acc: 0.7518\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 17s 429us/step - loss: 0.0606 - acc: 0.9818 - val_loss: 1.6337 - val_acc: 0.7497\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0625 - acc: 0.9814 - val_loss: 1.6460 - val_acc: 0.7482\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 17s 430us/step - loss: 0.0634 - acc: 0.9811 - val_loss: 1.5742 - val_acc: 0.7540\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 17s 429us/step - loss: 0.0533 - acc: 0.9836 - val_loss: 1.6182 - val_acc: 0.7540\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0627 - acc: 0.9814 - val_loss: 1.5029 - val_acc: 0.7577\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.0567 - acc: 0.9834 - val_loss: 1.6339 - val_acc: 0.7423\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0549 - acc: 0.9823 - val_loss: 1.6971 - val_acc: 0.7484\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0584 - acc: 0.9818 - val_loss: 1.6076 - val_acc: 0.7436\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.0479 - acc: 0.9857 - val_loss: 1.7043 - val_acc: 0.7432\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.0552 - acc: 0.9838 - val_loss: 1.5217 - val_acc: 0.7515\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 17s 424us/step - loss: 0.0506 - acc: 0.9844 - val_loss: 1.7048 - val_acc: 0.7505\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 17s 422us/step - loss: 0.0510 - acc: 0.9851 - val_loss: 1.6384 - val_acc: 0.7520\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 17s 424us/step - loss: 0.0530 - acc: 0.9838 - val_loss: 1.6168 - val_acc: 0.7525\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 17s 424us/step - loss: 0.0463 - acc: 0.9857 - val_loss: 1.7073 - val_acc: 0.7492\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.0500 - acc: 0.9851 - val_loss: 1.6719 - val_acc: 0.7442\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 17s 423us/step - loss: 0.0532 - acc: 0.9835 - val_loss: 1.6558 - val_acc: 0.7510\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0490 - acc: 0.9850 - val_loss: 1.5603 - val_acc: 0.7427\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0434 - acc: 0.9870 - val_loss: 1.7433 - val_acc: 0.7560\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 17s 424us/step - loss: 0.0507 - acc: 0.9848 - val_loss: 1.5195 - val_acc: 0.7554\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.0442 - acc: 0.9874 - val_loss: 1.6973 - val_acc: 0.7498\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 17s 429us/step - loss: 0.0448 - acc: 0.9872 - val_loss: 1.6626 - val_acc: 0.7425\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.0437 - acc: 0.9870 - val_loss: 1.6180 - val_acc: 0.7513\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 17s 429us/step - loss: 0.0477 - acc: 0.9849 - val_loss: 1.6761 - val_acc: 0.7536\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.0436 - acc: 0.9872 - val_loss: 1.6570 - val_acc: 0.7525\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0386 - acc: 0.9882 - val_loss: 1.6826 - val_acc: 0.7479\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0472 - acc: 0.9859 - val_loss: 1.5890 - val_acc: 0.7565\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.0419 - acc: 0.9877 - val_loss: 1.6627 - val_acc: 0.7463\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0438 - acc: 0.9866 - val_loss: 1.7117 - val_acc: 0.7521\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.0407 - acc: 0.9875 - val_loss: 1.7269 - val_acc: 0.7491\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0415 - acc: 0.9871 - val_loss: 1.6853 - val_acc: 0.7522\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.0432 - acc: 0.9870 - val_loss: 1.7069 - val_acc: 0.7543\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0382 - acc: 0.9888 - val_loss: 1.7874 - val_acc: 0.7544\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0415 - acc: 0.9869 - val_loss: 1.7570 - val_acc: 0.7559\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.0374 - acc: 0.9881 - val_loss: 1.7037 - val_acc: 0.7522\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.0374 - acc: 0.9887 - val_loss: 1.7172 - val_acc: 0.7500\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.0378 - acc: 0.9883 - val_loss: 1.8294 - val_acc: 0.7491\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0395 - acc: 0.9880 - val_loss: 1.7263 - val_acc: 0.7469\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0336 - acc: 0.9894 - val_loss: 1.7331 - val_acc: 0.7524\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 17s 431us/step - loss: 0.0375 - acc: 0.9879 - val_loss: 1.8622 - val_acc: 0.7468\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.0403 - acc: 0.9877 - val_loss: 1.7524 - val_acc: 0.7572\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0350 - acc: 0.9892 - val_loss: 1.7686 - val_acc: 0.7536\n",
      "10000/10000 [==============================] - 3s 307us/step\n",
      "Validation loss: 1.768568186593432\n",
      "Validation accuracy (NORMALIZED): 0.7535999999195337\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 2\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 19s 474us/step - loss: 1.5112 - acc: 0.4714 - val_loss: 1.0864 - val_acc: 0.6205\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 1.0653 - acc: 0.6402 - val_loss: 0.9308 - val_acc: 0.6820\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.9246 - acc: 0.6912 - val_loss: 0.8747 - val_acc: 0.7081\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.8396 - acc: 0.7208 - val_loss: 0.8197 - val_acc: 0.7217\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.7708 - acc: 0.7435 - val_loss: 0.8351 - val_acc: 0.7261\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.7222 - acc: 0.7601 - val_loss: 0.7903 - val_acc: 0.7329\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.6718 - acc: 0.7743 - val_loss: 0.7594 - val_acc: 0.7461\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.6327 - acc: 0.7891 - val_loss: 0.7753 - val_acc: 0.7420\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.5946 - acc: 0.8023 - val_loss: 0.7955 - val_acc: 0.7374\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.5623 - acc: 0.8122 - val_loss: 0.8074 - val_acc: 0.7472\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.5292 - acc: 0.8232 - val_loss: 0.7988 - val_acc: 0.7453\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.4972 - acc: 0.8367 - val_loss: 0.7586 - val_acc: 0.7535\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.4656 - acc: 0.8449 - val_loss: 0.7660 - val_acc: 0.7554\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.4395 - acc: 0.8556 - val_loss: 0.8177 - val_acc: 0.7563\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.4111 - acc: 0.8654 - val_loss: 0.8144 - val_acc: 0.7553\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.3918 - acc: 0.8709 - val_loss: 0.8241 - val_acc: 0.7559\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.3623 - acc: 0.8812 - val_loss: 0.8328 - val_acc: 0.7510\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.3521 - acc: 0.8848 - val_loss: 0.8825 - val_acc: 0.7561\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.3239 - acc: 0.8937 - val_loss: 0.8572 - val_acc: 0.7599\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.3002 - acc: 0.9025 - val_loss: 0.8881 - val_acc: 0.7589\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.2825 - acc: 0.9088 - val_loss: 0.9485 - val_acc: 0.7590\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.2675 - acc: 0.9129 - val_loss: 0.9422 - val_acc: 0.7582\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.2494 - acc: 0.9185 - val_loss: 1.0555 - val_acc: 0.7537\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.2416 - acc: 0.9219 - val_loss: 1.0286 - val_acc: 0.7512\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.2189 - acc: 0.9312 - val_loss: 1.0234 - val_acc: 0.7497\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 17s 436us/step - loss: 0.2103 - acc: 0.9326 - val_loss: 1.0802 - val_acc: 0.7554\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1967 - acc: 0.9365 - val_loss: 1.0882 - val_acc: 0.7560\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1867 - acc: 0.9416 - val_loss: 1.0868 - val_acc: 0.7574\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1788 - acc: 0.9431 - val_loss: 1.1344 - val_acc: 0.7520\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.1707 - acc: 0.9463 - val_loss: 1.1954 - val_acc: 0.7469\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.1653 - acc: 0.9464 - val_loss: 1.2080 - val_acc: 0.7434\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.1495 - acc: 0.9534 - val_loss: 1.2025 - val_acc: 0.7512\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1460 - acc: 0.9553 - val_loss: 1.1968 - val_acc: 0.7456\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.1388 - acc: 0.9561 - val_loss: 1.2953 - val_acc: 0.7471\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1329 - acc: 0.9594 - val_loss: 1.2235 - val_acc: 0.7541\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.1227 - acc: 0.9625 - val_loss: 1.2606 - val_acc: 0.7575\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1213 - acc: 0.9637 - val_loss: 1.2569 - val_acc: 0.7540\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.1137 - acc: 0.9657 - val_loss: 1.3104 - val_acc: 0.7540\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.1084 - acc: 0.9677 - val_loss: 1.3233 - val_acc: 0.7530\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.1118 - acc: 0.9653 - val_loss: 1.3123 - val_acc: 0.7435\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.1067 - acc: 0.9674 - val_loss: 1.3194 - val_acc: 0.7559\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.1011 - acc: 0.9691 - val_loss: 1.2955 - val_acc: 0.7521\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0922 - acc: 0.9716 - val_loss: 1.5141 - val_acc: 0.7444\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0965 - acc: 0.9706 - val_loss: 1.3600 - val_acc: 0.7524\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0890 - acc: 0.9731 - val_loss: 1.4278 - val_acc: 0.7495\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0916 - acc: 0.9720 - val_loss: 1.3752 - val_acc: 0.7499\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0829 - acc: 0.9750 - val_loss: 1.5428 - val_acc: 0.7326\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0815 - acc: 0.9745 - val_loss: 1.4875 - val_acc: 0.7543\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0809 - acc: 0.9757 - val_loss: 1.4513 - val_acc: 0.7509\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0811 - acc: 0.9748 - val_loss: 1.4537 - val_acc: 0.7523\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0792 - acc: 0.9756 - val_loss: 1.4289 - val_acc: 0.7536\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0709 - acc: 0.9784 - val_loss: 1.5303 - val_acc: 0.7429\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0750 - acc: 0.9770 - val_loss: 1.4641 - val_acc: 0.7423\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0649 - acc: 0.9808 - val_loss: 1.6113 - val_acc: 0.7514\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0748 - acc: 0.9772 - val_loss: 1.4906 - val_acc: 0.7517\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0686 - acc: 0.9795 - val_loss: 1.4935 - val_acc: 0.7412\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0711 - acc: 0.9787 - val_loss: 1.4750 - val_acc: 0.7495\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0605 - acc: 0.9818 - val_loss: 1.5365 - val_acc: 0.7539\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0634 - acc: 0.9813 - val_loss: 1.4698 - val_acc: 0.7538\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0638 - acc: 0.9803 - val_loss: 1.5861 - val_acc: 0.7462\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0561 - acc: 0.9824 - val_loss: 1.5890 - val_acc: 0.7471\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0612 - acc: 0.9818 - val_loss: 1.5541 - val_acc: 0.7448\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0645 - acc: 0.9801 - val_loss: 1.4954 - val_acc: 0.7555\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0582 - acc: 0.9823 - val_loss: 1.4831 - val_acc: 0.7545\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0547 - acc: 0.9833 - val_loss: 1.6602 - val_acc: 0.7441\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0578 - acc: 0.9827 - val_loss: 1.5040 - val_acc: 0.7546\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0542 - acc: 0.9830 - val_loss: 1.5766 - val_acc: 0.7515\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0546 - acc: 0.9827 - val_loss: 1.6201 - val_acc: 0.7503\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0531 - acc: 0.9839 - val_loss: 1.7237 - val_acc: 0.7463\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0543 - acc: 0.9833 - val_loss: 1.6660 - val_acc: 0.7517\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0537 - acc: 0.9832 - val_loss: 1.6514 - val_acc: 0.7530\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0532 - acc: 0.9838 - val_loss: 1.5628 - val_acc: 0.7591\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0480 - acc: 0.9851 - val_loss: 1.7200 - val_acc: 0.7459\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0472 - acc: 0.9856 - val_loss: 1.6347 - val_acc: 0.7543\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0488 - acc: 0.9850 - val_loss: 1.7623 - val_acc: 0.7445\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0534 - acc: 0.9843 - val_loss: 1.5891 - val_acc: 0.7522\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0456 - acc: 0.9862 - val_loss: 1.7184 - val_acc: 0.7486\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0525 - acc: 0.9842 - val_loss: 1.6172 - val_acc: 0.7517\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.0475 - acc: 0.9852 - val_loss: 1.6146 - val_acc: 0.7505\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0470 - acc: 0.9861 - val_loss: 1.6112 - val_acc: 0.7563\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0425 - acc: 0.9868 - val_loss: 1.6126 - val_acc: 0.7543\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0459 - acc: 0.9861 - val_loss: 1.7139 - val_acc: 0.7442\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 17s 437us/step - loss: 0.0453 - acc: 0.9860 - val_loss: 1.6442 - val_acc: 0.7556\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 17s 437us/step - loss: 0.0450 - acc: 0.9859 - val_loss: 1.6879 - val_acc: 0.7551\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.0429 - acc: 0.9870 - val_loss: 1.7018 - val_acc: 0.7517\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0441 - acc: 0.9866 - val_loss: 1.6351 - val_acc: 0.7509\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0399 - acc: 0.9884 - val_loss: 1.7490 - val_acc: 0.7442\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 17s 437us/step - loss: 0.0443 - acc: 0.9866 - val_loss: 1.6453 - val_acc: 0.7539\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0382 - acc: 0.9886 - val_loss: 1.7684 - val_acc: 0.7555\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0428 - acc: 0.9866 - val_loss: 1.7009 - val_acc: 0.7517\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 17s 437us/step - loss: 0.0429 - acc: 0.9865 - val_loss: 1.6636 - val_acc: 0.7432\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0372 - acc: 0.9885 - val_loss: 1.7925 - val_acc: 0.7528\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0399 - acc: 0.9879 - val_loss: 1.6796 - val_acc: 0.7570\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0384 - acc: 0.9882 - val_loss: 1.7668 - val_acc: 0.7537\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0395 - acc: 0.9883 - val_loss: 1.8688 - val_acc: 0.7479\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0415 - acc: 0.9876 - val_loss: 1.6533 - val_acc: 0.7537\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0386 - acc: 0.9880 - val_loss: 1.6945 - val_acc: 0.7534\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0380 - acc: 0.9882 - val_loss: 1.6999 - val_acc: 0.7520\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0392 - acc: 0.9885 - val_loss: 1.7144 - val_acc: 0.7489\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0386 - acc: 0.9880 - val_loss: 1.7498 - val_acc: 0.7568\n",
      "10000/10000 [==============================] - 3s 324us/step\n",
      "Validation loss: 1.749821595011129\n",
      "Validation accuracy (NORMALIZED): 0.7567999993860721\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 3\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 19s 478us/step - loss: 1.5035 - acc: 0.4791 - val_loss: 1.0701 - val_acc: 0.6282\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 1.0585 - acc: 0.6463 - val_loss: 0.9448 - val_acc: 0.6778\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.9231 - acc: 0.6940 - val_loss: 0.8725 - val_acc: 0.7013\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.8357 - acc: 0.7230 - val_loss: 0.8361 - val_acc: 0.7113\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.7657 - acc: 0.7478 - val_loss: 0.7981 - val_acc: 0.7245\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.7143 - acc: 0.7628 - val_loss: 0.7655 - val_acc: 0.7361\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.6656 - acc: 0.7804 - val_loss: 0.7865 - val_acc: 0.7321\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.6229 - acc: 0.7954 - val_loss: 0.7855 - val_acc: 0.7309\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.5821 - acc: 0.8084 - val_loss: 0.7504 - val_acc: 0.7458\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.5463 - acc: 0.8212 - val_loss: 0.7612 - val_acc: 0.7467\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.5172 - acc: 0.8296 - val_loss: 0.7872 - val_acc: 0.7479\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.4867 - acc: 0.8411 - val_loss: 0.7983 - val_acc: 0.7451\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.4529 - acc: 0.8522 - val_loss: 0.7846 - val_acc: 0.7578\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.4236 - acc: 0.8611 - val_loss: 0.8455 - val_acc: 0.7439\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.4031 - acc: 0.8689 - val_loss: 0.8221 - val_acc: 0.7502\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.3761 - acc: 0.8774 - val_loss: 0.8259 - val_acc: 0.7565\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.3521 - acc: 0.8833 - val_loss: 0.8248 - val_acc: 0.7611\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.3257 - acc: 0.8949 - val_loss: 0.9090 - val_acc: 0.7536\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.3129 - acc: 0.8977 - val_loss: 0.9036 - val_acc: 0.7477\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.2886 - acc: 0.9063 - val_loss: 0.9034 - val_acc: 0.7522\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.2729 - acc: 0.9124 - val_loss: 0.9160 - val_acc: 0.7592\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.2555 - acc: 0.9178 - val_loss: 0.9548 - val_acc: 0.7609\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.2373 - acc: 0.9239 - val_loss: 0.9833 - val_acc: 0.7562\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.2230 - acc: 0.9303 - val_loss: 1.0486 - val_acc: 0.7519\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.2136 - acc: 0.9325 - val_loss: 1.0629 - val_acc: 0.7563\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.1992 - acc: 0.9377 - val_loss: 1.0559 - val_acc: 0.7556\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.1904 - acc: 0.9389 - val_loss: 1.1278 - val_acc: 0.7479\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.1823 - acc: 0.9434 - val_loss: 1.1390 - val_acc: 0.7423\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.1727 - acc: 0.9461 - val_loss: 1.1411 - val_acc: 0.7507\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.1575 - acc: 0.9510 - val_loss: 1.1931 - val_acc: 0.7526\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.1497 - acc: 0.9545 - val_loss: 1.2191 - val_acc: 0.7477\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.1489 - acc: 0.9535 - val_loss: 1.1965 - val_acc: 0.7518\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.1322 - acc: 0.9608 - val_loss: 1.2608 - val_acc: 0.7564\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.1436 - acc: 0.9564 - val_loss: 1.2556 - val_acc: 0.7499\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.1272 - acc: 0.9615 - val_loss: 1.2676 - val_acc: 0.7541\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.1243 - acc: 0.9630 - val_loss: 1.2429 - val_acc: 0.7535\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.1241 - acc: 0.9614 - val_loss: 1.2491 - val_acc: 0.7543\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.1096 - acc: 0.9670 - val_loss: 1.3186 - val_acc: 0.7516\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.1120 - acc: 0.9658 - val_loss: 1.3456 - val_acc: 0.7509\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.1042 - acc: 0.9689 - val_loss: 1.3358 - val_acc: 0.7581\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.1014 - acc: 0.9692 - val_loss: 1.3723 - val_acc: 0.7526\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.1040 - acc: 0.9681 - val_loss: 1.3997 - val_acc: 0.7477\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0919 - acc: 0.9721 - val_loss: 1.3783 - val_acc: 0.7551\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0921 - acc: 0.9727 - val_loss: 1.4055 - val_acc: 0.7556\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.0967 - acc: 0.9700 - val_loss: 1.3492 - val_acc: 0.7516\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0806 - acc: 0.9765 - val_loss: 1.4789 - val_acc: 0.7476\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0869 - acc: 0.9740 - val_loss: 1.4454 - val_acc: 0.7524\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.0849 - acc: 0.9741 - val_loss: 1.4736 - val_acc: 0.7527\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.0842 - acc: 0.9745 - val_loss: 1.4613 - val_acc: 0.7468\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0714 - acc: 0.9787 - val_loss: 1.4816 - val_acc: 0.7542\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.0824 - acc: 0.9748 - val_loss: 1.5672 - val_acc: 0.7473\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.0772 - acc: 0.9769 - val_loss: 1.3679 - val_acc: 0.7599\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0715 - acc: 0.9787 - val_loss: 1.5518 - val_acc: 0.7491\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.0733 - acc: 0.9786 - val_loss: 1.4635 - val_acc: 0.7537\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0718 - acc: 0.9787 - val_loss: 1.4766 - val_acc: 0.7564\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.0676 - acc: 0.9795 - val_loss: 1.5230 - val_acc: 0.7504\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.0647 - acc: 0.9806 - val_loss: 1.5823 - val_acc: 0.7437\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.0657 - acc: 0.9799 - val_loss: 1.5626 - val_acc: 0.7614\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.0640 - acc: 0.9814 - val_loss: 1.5346 - val_acc: 0.7520\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.0589 - acc: 0.9821 - val_loss: 1.5196 - val_acc: 0.7553\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.0667 - acc: 0.9800 - val_loss: 1.5004 - val_acc: 0.7511\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.0601 - acc: 0.9818 - val_loss: 1.5934 - val_acc: 0.7555\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.0610 - acc: 0.9817 - val_loss: 1.5611 - val_acc: 0.7486\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0540 - acc: 0.9840 - val_loss: 1.5083 - val_acc: 0.7480\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0554 - acc: 0.9830 - val_loss: 1.5918 - val_acc: 0.7514\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.0631 - acc: 0.9804 - val_loss: 1.6390 - val_acc: 0.7535\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0522 - acc: 0.9840 - val_loss: 1.5744 - val_acc: 0.7530\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0540 - acc: 0.9836 - val_loss: 1.5778 - val_acc: 0.7591\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0540 - acc: 0.9834 - val_loss: 1.6214 - val_acc: 0.7531\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0514 - acc: 0.9840 - val_loss: 1.6126 - val_acc: 0.7558\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.0535 - acc: 0.9836 - val_loss: 1.5776 - val_acc: 0.7543\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0469 - acc: 0.9859 - val_loss: 1.6462 - val_acc: 0.7493\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0476 - acc: 0.9859 - val_loss: 1.6679 - val_acc: 0.7585\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0517 - acc: 0.9835 - val_loss: 1.6847 - val_acc: 0.7439\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0495 - acc: 0.9855 - val_loss: 1.6278 - val_acc: 0.7508\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0470 - acc: 0.9859 - val_loss: 1.6381 - val_acc: 0.7476\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0480 - acc: 0.9850 - val_loss: 1.6920 - val_acc: 0.7380\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0461 - acc: 0.9866 - val_loss: 1.5897 - val_acc: 0.7598\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0442 - acc: 0.9859 - val_loss: 1.7043 - val_acc: 0.7499\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0482 - acc: 0.9853 - val_loss: 1.6940 - val_acc: 0.7556\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0412 - acc: 0.9874 - val_loss: 1.6698 - val_acc: 0.7583\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0416 - acc: 0.9873 - val_loss: 1.7267 - val_acc: 0.7530\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0556 - acc: 0.9829 - val_loss: 1.6407 - val_acc: 0.7581\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0390 - acc: 0.9878 - val_loss: 1.7550 - val_acc: 0.7504\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0430 - acc: 0.9870 - val_loss: 1.7574 - val_acc: 0.7503\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.0438 - acc: 0.9867 - val_loss: 1.6340 - val_acc: 0.7527\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0466 - acc: 0.9859 - val_loss: 1.4992 - val_acc: 0.7511\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0412 - acc: 0.9873 - val_loss: 1.6346 - val_acc: 0.7569\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0362 - acc: 0.9887 - val_loss: 1.7723 - val_acc: 0.7533\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0427 - acc: 0.9863 - val_loss: 1.7470 - val_acc: 0.7511\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0384 - acc: 0.9882 - val_loss: 1.7208 - val_acc: 0.7593\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0383 - acc: 0.9885 - val_loss: 1.7844 - val_acc: 0.7529\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0409 - acc: 0.9875 - val_loss: 1.8149 - val_acc: 0.7508\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0397 - acc: 0.9878 - val_loss: 1.7378 - val_acc: 0.7548\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0407 - acc: 0.9872 - val_loss: 1.7216 - val_acc: 0.7560\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.0366 - acc: 0.9889 - val_loss: 1.7319 - val_acc: 0.7545\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.0367 - acc: 0.9887 - val_loss: 1.7776 - val_acc: 0.7541\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0348 - acc: 0.9891 - val_loss: 1.7547 - val_acc: 0.7541\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0369 - acc: 0.9889 - val_loss: 1.8341 - val_acc: 0.7543\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.0391 - acc: 0.9877 - val_loss: 1.6876 - val_acc: 0.7591\n",
      "10000/10000 [==============================] - 3s 337us/step\n",
      "Validation loss: 1.6875655769891673\n",
      "Validation accuracy (NORMALIZED): 0.759099999666214\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 4\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 20s 498us/step - loss: 1.5006 - acc: 0.4775 - val_loss: 1.0892 - val_acc: 0.6243\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 1.0717 - acc: 0.6410 - val_loss: 0.9603 - val_acc: 0.6696\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.9319 - acc: 0.6885 - val_loss: 0.8849 - val_acc: 0.7006\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.8466 - acc: 0.7189 - val_loss: 0.8213 - val_acc: 0.7243\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.7791 - acc: 0.7425 - val_loss: 0.8447 - val_acc: 0.7191\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.7207 - acc: 0.7603 - val_loss: 0.8118 - val_acc: 0.7304\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.6739 - acc: 0.7756 - val_loss: 0.7601 - val_acc: 0.7429\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.6334 - acc: 0.7891 - val_loss: 0.7582 - val_acc: 0.7475\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.5940 - acc: 0.8021 - val_loss: 0.7645 - val_acc: 0.7429\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.5547 - acc: 0.8163 - val_loss: 0.7573 - val_acc: 0.7514\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.5241 - acc: 0.8242 - val_loss: 0.7911 - val_acc: 0.7506\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.4933 - acc: 0.8360 - val_loss: 0.7669 - val_acc: 0.7558\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.4635 - acc: 0.8467 - val_loss: 0.7858 - val_acc: 0.7544\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.4396 - acc: 0.8551 - val_loss: 0.8024 - val_acc: 0.7555\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.4054 - acc: 0.8646 - val_loss: 0.8058 - val_acc: 0.7544\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.3840 - acc: 0.8733 - val_loss: 0.8102 - val_acc: 0.7569\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 18s 462us/step - loss: 0.3638 - acc: 0.8800 - val_loss: 0.8252 - val_acc: 0.7613\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 18s 462us/step - loss: 0.3367 - acc: 0.8896 - val_loss: 0.8471 - val_acc: 0.7579\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.3181 - acc: 0.8957 - val_loss: 0.8802 - val_acc: 0.7562\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.2963 - acc: 0.9032 - val_loss: 0.9295 - val_acc: 0.7607\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.2790 - acc: 0.9086 - val_loss: 0.9598 - val_acc: 0.7528\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.2649 - acc: 0.9136 - val_loss: 0.9887 - val_acc: 0.7587\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.2444 - acc: 0.9213 - val_loss: 0.9700 - val_acc: 0.7543\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.2348 - acc: 0.9233 - val_loss: 0.9984 - val_acc: 0.7531\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.2186 - acc: 0.9281 - val_loss: 1.0718 - val_acc: 0.7519\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.2096 - acc: 0.9330 - val_loss: 1.0971 - val_acc: 0.7539\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.2002 - acc: 0.9355 - val_loss: 1.0908 - val_acc: 0.7543\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.1929 - acc: 0.9374 - val_loss: 1.0883 - val_acc: 0.7510\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.1768 - acc: 0.9431 - val_loss: 1.1363 - val_acc: 0.7540\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.1666 - acc: 0.9461 - val_loss: 1.1398 - val_acc: 0.7505\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.1600 - acc: 0.9492 - val_loss: 1.2377 - val_acc: 0.7538\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.1611 - acc: 0.9475 - val_loss: 1.1825 - val_acc: 0.7528\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.1462 - acc: 0.9546 - val_loss: 1.2195 - val_acc: 0.7508\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 18s 462us/step - loss: 0.1410 - acc: 0.9544 - val_loss: 1.2286 - val_acc: 0.7498\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.1357 - acc: 0.9577 - val_loss: 1.2717 - val_acc: 0.7486\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.1282 - acc: 0.9594 - val_loss: 1.3270 - val_acc: 0.7527\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.1213 - acc: 0.9626 - val_loss: 1.2415 - val_acc: 0.7532\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.1155 - acc: 0.9648 - val_loss: 1.3316 - val_acc: 0.7476\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.1197 - acc: 0.9625 - val_loss: 1.3235 - val_acc: 0.7480\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.1070 - acc: 0.9670 - val_loss: 1.3427 - val_acc: 0.7536\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.1049 - acc: 0.9673 - val_loss: 1.3816 - val_acc: 0.7524\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.1018 - acc: 0.9691 - val_loss: 1.3188 - val_acc: 0.7449\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 19s 463us/step - loss: 0.0997 - acc: 0.9699 - val_loss: 1.3337 - val_acc: 0.7534\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0917 - acc: 0.9716 - val_loss: 1.4199 - val_acc: 0.7534\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0937 - acc: 0.9715 - val_loss: 1.3925 - val_acc: 0.7548\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.0886 - acc: 0.9733 - val_loss: 1.3354 - val_acc: 0.7509\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.0843 - acc: 0.9740 - val_loss: 1.4004 - val_acc: 0.7489\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.0858 - acc: 0.9743 - val_loss: 1.4610 - val_acc: 0.7551\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0809 - acc: 0.9755 - val_loss: 1.4471 - val_acc: 0.7440\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0742 - acc: 0.9779 - val_loss: 1.4671 - val_acc: 0.7540\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 18s 457us/step - loss: 0.0739 - acc: 0.9785 - val_loss: 1.4567 - val_acc: 0.7512\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.0811 - acc: 0.9752 - val_loss: 1.5719 - val_acc: 0.7448\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.0736 - acc: 0.9773 - val_loss: 1.5368 - val_acc: 0.7459\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 18s 457us/step - loss: 0.0694 - acc: 0.9790 - val_loss: 1.5274 - val_acc: 0.7512\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.0734 - acc: 0.9775 - val_loss: 1.5252 - val_acc: 0.7516\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 18s 457us/step - loss: 0.0705 - acc: 0.9788 - val_loss: 1.5193 - val_acc: 0.7489\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.0644 - acc: 0.9811 - val_loss: 1.6074 - val_acc: 0.7489\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.0611 - acc: 0.9816 - val_loss: 1.5233 - val_acc: 0.7528\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 18s 457us/step - loss: 0.0695 - acc: 0.9788 - val_loss: 1.5680 - val_acc: 0.7491\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 18s 457us/step - loss: 0.0597 - acc: 0.9823 - val_loss: 1.5363 - val_acc: 0.7518\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.0632 - acc: 0.9812 - val_loss: 1.5470 - val_acc: 0.7483\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.0616 - acc: 0.9812 - val_loss: 1.5916 - val_acc: 0.7446\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0580 - acc: 0.9822 - val_loss: 1.5971 - val_acc: 0.7459\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 18s 457us/step - loss: 0.0610 - acc: 0.9813 - val_loss: 1.6162 - val_acc: 0.7465\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0586 - acc: 0.9826 - val_loss: 1.5381 - val_acc: 0.7518\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0498 - acc: 0.9854 - val_loss: 1.6344 - val_acc: 0.7534\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0618 - acc: 0.9805 - val_loss: 1.6025 - val_acc: 0.7484\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0508 - acc: 0.9847 - val_loss: 1.6508 - val_acc: 0.7535\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0521 - acc: 0.9840 - val_loss: 1.8175 - val_acc: 0.7389\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0564 - acc: 0.9819 - val_loss: 1.5945 - val_acc: 0.7510\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.0499 - acc: 0.9851 - val_loss: 1.7031 - val_acc: 0.7510\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0560 - acc: 0.9836 - val_loss: 1.5961 - val_acc: 0.7445\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0470 - acc: 0.9857 - val_loss: 1.6126 - val_acc: 0.7517\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0523 - acc: 0.9839 - val_loss: 1.6551 - val_acc: 0.7484\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0461 - acc: 0.9865 - val_loss: 1.6085 - val_acc: 0.7521\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0530 - acc: 0.9839 - val_loss: 1.6082 - val_acc: 0.7573\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.0480 - acc: 0.9852 - val_loss: 1.6750 - val_acc: 0.7543\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.0456 - acc: 0.9858 - val_loss: 1.6248 - val_acc: 0.7515\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.0491 - acc: 0.9847 - val_loss: 1.6639 - val_acc: 0.7529\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0398 - acc: 0.9883 - val_loss: 1.6637 - val_acc: 0.7525\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0467 - acc: 0.9856 - val_loss: 1.6710 - val_acc: 0.7560\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0455 - acc: 0.9850 - val_loss: 1.7779 - val_acc: 0.7415\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.0421 - acc: 0.9872 - val_loss: 1.6842 - val_acc: 0.7567\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0384 - acc: 0.9876 - val_loss: 1.7722 - val_acc: 0.7475\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0495 - acc: 0.9841 - val_loss: 1.6957 - val_acc: 0.7546\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0405 - acc: 0.9873 - val_loss: 1.6590 - val_acc: 0.7493\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0407 - acc: 0.9876 - val_loss: 1.8270 - val_acc: 0.7503\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0394 - acc: 0.9879 - val_loss: 1.6891 - val_acc: 0.7517\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0432 - acc: 0.9863 - val_loss: 1.7137 - val_acc: 0.7548\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0370 - acc: 0.9887 - val_loss: 1.8173 - val_acc: 0.7426\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0456 - acc: 0.9858 - val_loss: 1.8017 - val_acc: 0.7492\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0440 - acc: 0.9862 - val_loss: 1.6530 - val_acc: 0.7539\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 19s 465us/step - loss: 0.0349 - acc: 0.9893 - val_loss: 1.8377 - val_acc: 0.7600\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0401 - acc: 0.9877 - val_loss: 1.7651 - val_acc: 0.7580\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0382 - acc: 0.9877 - val_loss: 1.7149 - val_acc: 0.7464\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0356 - acc: 0.9889 - val_loss: 1.7216 - val_acc: 0.7547\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 18s 462us/step - loss: 0.0365 - acc: 0.9882 - val_loss: 1.7977 - val_acc: 0.7536\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0386 - acc: 0.9880 - val_loss: 1.6839 - val_acc: 0.7473\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 19s 465us/step - loss: 0.0356 - acc: 0.9886 - val_loss: 1.7400 - val_acc: 0.7545\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.0359 - acc: 0.9885 - val_loss: 1.8812 - val_acc: 0.7534\n",
      "10000/10000 [==============================] - 4s 352us/step\n",
      "Validation loss: 1.8812175272491583\n",
      "Validation accuracy (NORMALIZED): 0.7533999991342425\n",
      "[[1.814102641878854, 0.7614999990612269], [1.768568186593432, 0.7535999999195337], [1.749821595011129, 0.7567999993860721], [1.6875655769891673, 0.759099999666214], [1.8812175272491583, 0.7533999991342425]]\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "#=====================================\n",
    "# Tensorboard callback\n",
    "#=====================================\n",
    "\n",
    "print(\"--- Preparing tensorboard\")\n",
    "log_dir = \"logs/{}\".format(time())\n",
    "print(\"Log Dir: \", log_dir)\n",
    "tbCallBack = TensorBoard(log_dir=log_dir, write_graph=True)\n",
    "\n",
    "#=====================================\n",
    "# Training model and Evaluation\n",
    "#=====================================\n",
    "print(\"--- Start training\")\n",
    "y_train_categorical = to_categorical(y_train, num_classes=n_classes)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=n_classes)\n",
    "scores = []\n",
    "\n",
    "for i in range(folds):\n",
    "    #--- Loading model\n",
    "    model = get_squeezenet_ft3()\n",
    "    \n",
    "    #--- Evaluating the model for split i\n",
    "    print(\"================================================\")\n",
    "    print(\"Split: \"+str(i))\n",
    "    print(\"Number of Epochs: \"+str(n_epochs))\n",
    "    print(\"Train shape:\",X_train[i].shape)\n",
    "    print(\"Train batch size: \"+str(train_batch_size))\n",
    "    print(\"Val batch size: \"+str(val_batch_size))\n",
    "    #print(\"Optimizer:\", opt)\n",
    "    print(\"================================================\")\n",
    "          \n",
    "    #--- Training without data augmentation\n",
    "    model.fit(X_train[i],y_train_categorical[i], batch_size=train_batch_size,\n",
    "              epochs=n_epochs, \n",
    "              validation_data=(X_val[i],y_val_categorical[i]),              \n",
    "              verbose=1,\n",
    "              callbacks=[tbCallBack])\n",
    "          \n",
    "    #--- Evaluating the model for split i\n",
    "    score = model.evaluate(x=X_val[i], y=y_val_categorical[i], batch_size=val_batch_size, verbose=1)\n",
    "    scores.append(score)\n",
    "    print('Validation loss:', score[0])\n",
    "    print('Validation accuracy (NORMALIZED):', score[1])\n",
    "    \n",
    "#--- Showing scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation loss: 1.780255105544348\n",
      "Mean Validation accuracy (NORMALIZED): 0.7568799994334579\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Evaluate on validation\n",
    "#=====================================\n",
    "\n",
    "#--- The evaluation of the model \n",
    "np_aux = np.array(scores).mean(axis=0)\n",
    "\n",
    "print('Mean Validation loss:', np_aux[0])\n",
    "print('Mean Validation accuracy (NORMALIZED):', np_aux[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your best model on test\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "Now that we are working on more complex tasks and our trainings are starting to take more time it is usually a good idea to save the trained model from time to time. [Keras has a lot of ways of saving and loading the model](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model), but in this exercise we will use the simplest of them all: `model.save()`. It saves the architecture, the weights, the choice of loss function/optimizer/metrics and even the current state of the training, so you can resume your training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The better model obtained was when retraining the whole network \n",
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a model\n",
    "Once we have our model trained, we can load it using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 650us/step\n",
      "Test loss: 1.89428568550757\n",
      "Test accuracy (NORMALIZED): 0.7488999999463558\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "del model  # Will delete model, only to check if load_model is working\n",
    "\n",
    "y_test_categorical = to_categorical(y_test, num_classes=n_classes)\n",
    "\n",
    "# returns a compiled model identical to the previous one\n",
    "model = load_model('my_model.h5')\n",
    "\n",
    "score = model.evaluate(x=X_test, y=y_test_categorical, batch_size=val_batch_size, verbose=1)    \n",
    "# evaluate test set again... should give us the same result\n",
    "# ...\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy (NORMALIZED):', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
