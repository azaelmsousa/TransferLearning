{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorflow version: 1.12.0-rc0\n",
    "scikit-learn version: 0.17\n",
    "keras version: 2.2.4\n",
    "tensorboard version: 1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "In this assignment, we will use the weights of a network pre-trained in a particular problem as starting point to train our CNN to a different problem. As training a network from scratch is time-consuming and demands a lot of data, this is a frequent strategy, specially if both datasets (the one used for pre-training and the target) shares similar structures/elements/concepts. \n",
    "\n",
    "This is specially true when working with images. Most filters learned in initial convolutional layers will detect low-level elements, such as borders, corners and color blobs, which are common to most problems in the image domain. \n",
    "\n",
    "In this notebook, we will load the SqueezeNet architecture trained in the ImageNet dataset and fine-tune it to CIFAR-10.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.5/dist-packages (2.2.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (3.13)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.0.6)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.0.5)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.1.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (2.8.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.15.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.20.0.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import keras\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "if (sklearn.__version__ == '0.20.0'):\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "else:\n",
    "    from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "#======================================\n",
    "# Global definitions\n",
    "#======================================\n",
    "n_epochs         = 100\n",
    "learning_rate    = 1e-4\n",
    "n_classes        = 10\n",
    "train_batch_size = 384\n",
    "val_batch_size   = 128\n",
    "    \n",
    "#Utility to plot\n",
    "def plotImages(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "        \n",
    "        \n",
    "def plotImage(img):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.imshow(np.uint8(img), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SqueezeNet definition\n",
    "These methods define our architecture and load the weights obtained using ImageNet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Module Definition\n",
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "#SqueezeNet model definition\n",
    "def SqueezeNet(input_shape):\n",
    "    img_input = Input(shape=input_shape) #placeholder\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(1000, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    # Download and load ImageNet weights\n",
    "    model.load_weights('./squeezenet_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The class are **airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val data. X:  (50000, 32, 32, 3) , Y:  (50000, 1)\n",
      "Test data. X:  (10000, 32, 32, 3) , Y:  (10000, 1)\n",
      "--- Splitting data into train and val\n",
      "Train data. X: (5, 40000, 32, 32, 3) Y: (5, 40000, 1)\n",
      "Val data. X: (5, 10000, 32, 32, 3) Y: (5, 10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "(trainVal_data, trainVal_label), (X_test, y_test) = cifar10.load_data()\n",
    "print(\"Train/Val data. X: \", trainVal_data.shape, \", Y: \", trainVal_label.shape)\n",
    "print(\"Test data. X: \", X_test.shape, \", Y: \", y_test.shape)\n",
    "\n",
    "# Normalizing the data\n",
    "trainVal_data = (trainVal_data / 127.5) - 1.\n",
    "X_test = (X_test  / 127.5) - 1.\n",
    "\n",
    "#=====================================\n",
    "# Prepare the data\n",
    "#=====================================\n",
    "\n",
    "#--- Dividing the data into training and validation\n",
    "folds = 5\n",
    "if (sklearn.__version__ == '0.20.0'):\n",
    "    sss = StratifiedShuffleSplit(folds, test_size=0.2, random_state=42)\n",
    "    sss = sss.split(trainVal_data,trainVal_label)\n",
    "else:\n",
    "    sss = StratifiedShuffleSplit(trainVal_label, folds, test_size=0.2, random_state=42)\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "for train_index, val_index in sss:\n",
    "    X_train.append(trainVal_data[train_index])\n",
    "    X_val.append(trainVal_data[val_index])\n",
    "    y_train.append(trainVal_label[train_index])\n",
    "    y_val.append(trainVal_label[val_index])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "    \n",
    "print(\"--- Splitting data into train and val\")\n",
    "print(\"Train data. X:\",X_train.shape,\"Y:\",y_train.shape)\n",
    "print(\"Val data. X:\",X_val.shape,\"Y:\",y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cheking if the splits are balanced\n",
    "for i in range(folds):\n",
    "    hist = np.histogram(np.squeeze(y_train[i]))[0]\n",
    "    print(hist)    \n",
    "    plt.bar(hist,np.amax(hist),alpha=0.5)\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## SqueezeNet with frozen layers\n",
    "Our initial attempt will be to remove SqueezeNet's top layers --- responsible for the classification into ImageNet classes --- and train a new set of layers to our CIFAR-10 classes. We will also freeze the layers before `drop9`. Our architecture will be like this:\n",
    "\n",
    "<img src=\"frozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 10)     5130        drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 10)     0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 10)           0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 10)           0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 727,626\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 722,496\n",
      "__________________________________________________________________________________________________\n",
      "input_1 False\n",
      "conv1 False\n",
      "relu_conv1 False\n",
      "pool1 False\n",
      "fire2/squeeze1x1 False\n",
      "fire2/relu_squeeze1x1 False\n",
      "fire2/expand1x1 False\n",
      "fire2/expand3x3 False\n",
      "fire2/relu_expand1x1 False\n",
      "fire2/relu_expand3x3 False\n",
      "fire2/concat False\n",
      "fire3/squeeze1x1 False\n",
      "fire3/relu_squeeze1x1 False\n",
      "fire3/expand1x1 False\n",
      "fire3/expand3x3 False\n",
      "fire3/relu_expand1x1 False\n",
      "fire3/relu_expand3x3 False\n",
      "fire3/concat False\n",
      "pool3 False\n",
      "fire4/squeeze1x1 False\n",
      "fire4/relu_squeeze1x1 False\n",
      "fire4/expand1x1 False\n",
      "fire4/expand3x3 False\n",
      "fire4/relu_expand1x1 False\n",
      "fire4/relu_expand3x3 False\n",
      "fire4/concat False\n",
      "fire5/squeeze1x1 False\n",
      "fire5/relu_squeeze1x1 False\n",
      "fire5/expand1x1 False\n",
      "fire5/expand3x3 False\n",
      "fire5/relu_expand1x1 False\n",
      "fire5/relu_expand3x3 False\n",
      "fire5/concat False\n",
      "pool5 False\n",
      "fire6/squeeze1x1 False\n",
      "fire6/relu_squeeze1x1 False\n",
      "fire6/expand1x1 False\n",
      "fire6/expand3x3 False\n",
      "fire6/relu_expand1x1 False\n",
      "fire6/relu_expand3x3 False\n",
      "fire6/concat False\n",
      "fire7/squeeze1x1 False\n",
      "fire7/relu_squeeze1x1 False\n",
      "fire7/expand1x1 False\n",
      "fire7/expand3x3 False\n",
      "fire7/relu_expand1x1 False\n",
      "fire7/relu_expand3x3 False\n",
      "fire7/concat False\n",
      "fire8/squeeze1x1 False\n",
      "fire8/relu_squeeze1x1 False\n",
      "fire8/expand1x1 False\n",
      "fire8/expand3x3 False\n",
      "fire8/relu_expand1x1 False\n",
      "fire8/relu_expand3x3 False\n",
      "fire8/concat False\n",
      "fire9/squeeze1x1 False\n",
      "fire9/relu_squeeze1x1 False\n",
      "fire9/expand1x1 False\n",
      "fire9/expand3x3 False\n",
      "fire9/relu_expand1x1 False\n",
      "fire9/relu_expand3x3 False\n",
      "fire9/concat False\n",
      "drop9 False\n",
      "conv10 True\n",
      "relu_conv10 True\n",
      "global_average_pooling2d_2 True\n",
      "loss True\n"
     ]
    }
   ],
   "source": [
    "def get_squeezenet_ft():\n",
    "    #=====================================\n",
    "    # Freezing layers\n",
    "    #=====================================\n",
    "\n",
    "    squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "    #freeze layers\n",
    "    for layer in squeezeNetModel.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #=====================================\n",
    "    # Add new classification layers\n",
    "    #=====================================\n",
    "\n",
    "    #--- Removing layers until drop 9\n",
    "    squeezeNetModel.layers.pop() #Convolution2D\n",
    "    squeezeNetModel.layers.pop() #Activation ReLU\n",
    "    squeezeNetModel.layers.pop() #Global Avg Pool\n",
    "    squeezeNetModel.layers.pop() #Activation Softmax\n",
    "\n",
    "    #--- Adding classification layer for 10 classes\n",
    "    out = Convolution2D(n_classes, (1, 1), padding='valid', name='conv10')(squeezeNetModel.layers[-1].output)\n",
    "    out = Activation('relu', name='relu_conv10')(out)\n",
    "\n",
    "    out = GlobalAveragePooling2D()(out)\n",
    "    out = Activation('softmax', name='loss')(out)\n",
    "\n",
    "    #=====================================\n",
    "    # New Model\n",
    "    #=====================================\n",
    "    model = Model(squeezeNetModel.inputs, out, name='squeezenet_new')\n",
    "    #=====================================\n",
    "    # Compile model\n",
    "    #=====================================\n",
    "\n",
    "\n",
    "    opt = optimizer=optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#SGD(lr=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model  = get_squeezenet_ft()\n",
    "model.summary()\n",
    "\n",
    "#--- Check the trainable status of the individual layers\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Split: 0\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542744509.6199977_fold[0]_pre-trained\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 2.3576 - acc: 0.1032 - val_loss: 2.3014 - val_acc: 0.1100\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.3156 - acc: 0.1141 - val_loss: 2.2907 - val_acc: 0.1386\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 2.2945 - acc: 0.1318 - val_loss: 2.2770 - val_acc: 0.1859\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 2.2815 - acc: 0.1454 - val_loss: 2.2573 - val_acc: 0.2170\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.2629 - acc: 0.1673 - val_loss: 2.2298 - val_acc: 0.2449\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 2.2454 - acc: 0.1824 - val_loss: 2.2044 - val_acc: 0.2634\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 2.2224 - acc: 0.1975 - val_loss: 2.1599 - val_acc: 0.2760\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.1915 - acc: 0.2153 - val_loss: 2.1153 - val_acc: 0.2962\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.1636 - acc: 0.2297 - val_loss: 2.0763 - val_acc: 0.3125\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.1284 - acc: 0.2423 - val_loss: 2.0389 - val_acc: 0.3297\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 2.1023 - acc: 0.2564 - val_loss: 2.0142 - val_acc: 0.3460\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.0801 - acc: 0.2648 - val_loss: 1.9945 - val_acc: 0.3554\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.0557 - acc: 0.2728 - val_loss: 1.9673 - val_acc: 0.3624\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 2.0270 - acc: 0.2787 - val_loss: 1.9378 - val_acc: 0.3646\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 2.0033 - acc: 0.2847 - val_loss: 1.9176 - val_acc: 0.3723\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9827 - acc: 0.2911 - val_loss: 1.9012 - val_acc: 0.3800\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9652 - acc: 0.2980 - val_loss: 1.8868 - val_acc: 0.3797\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.9533 - acc: 0.3040 - val_loss: 1.8744 - val_acc: 0.3845\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.9386 - acc: 0.3084 - val_loss: 1.8631 - val_acc: 0.3851\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9268 - acc: 0.3168 - val_loss: 1.8532 - val_acc: 0.3897\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.9204 - acc: 0.3152 - val_loss: 1.8441 - val_acc: 0.3909\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.9078 - acc: 0.3222 - val_loss: 1.8356 - val_acc: 0.3908\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.9038 - acc: 0.3216 - val_loss: 1.8283 - val_acc: 0.3926\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8973 - acc: 0.3247 - val_loss: 1.8213 - val_acc: 0.3948\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8945 - acc: 0.3248 - val_loss: 1.8149 - val_acc: 0.3952\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8847 - acc: 0.3301 - val_loss: 1.8089 - val_acc: 0.3963\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.8780 - acc: 0.3321 - val_loss: 1.8031 - val_acc: 0.3971\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.8809 - acc: 0.3309 - val_loss: 1.7978 - val_acc: 0.3976\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8714 - acc: 0.3315 - val_loss: 1.7930 - val_acc: 0.3994\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8651 - acc: 0.3356 - val_loss: 1.7882 - val_acc: 0.3987\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8621 - acc: 0.3364 - val_loss: 1.7837 - val_acc: 0.3997\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8593 - acc: 0.3402 - val_loss: 1.7798 - val_acc: 0.4010\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8550 - acc: 0.3390 - val_loss: 1.7758 - val_acc: 0.4019\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.8519 - acc: 0.3419 - val_loss: 1.7721 - val_acc: 0.4023\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8484 - acc: 0.3435 - val_loss: 1.7686 - val_acc: 0.4023\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8452 - acc: 0.3420 - val_loss: 1.7651 - val_acc: 0.4028\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8463 - acc: 0.3444 - val_loss: 1.7621 - val_acc: 0.4047\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8431 - acc: 0.3450 - val_loss: 1.7589 - val_acc: 0.4044\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8365 - acc: 0.3464 - val_loss: 1.7559 - val_acc: 0.4041\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8382 - acc: 0.3450 - val_loss: 1.7532 - val_acc: 0.4060\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8331 - acc: 0.3462 - val_loss: 1.7505 - val_acc: 0.4039\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.8322 - acc: 0.3473 - val_loss: 1.7480 - val_acc: 0.4075\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.8293 - acc: 0.3467 - val_loss: 1.7455 - val_acc: 0.4068\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 1.8318 - acc: 0.3457 - val_loss: 1.7430 - val_acc: 0.4075\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8264 - acc: 0.3501 - val_loss: 1.7409 - val_acc: 0.4084\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8265 - acc: 0.3472 - val_loss: 1.7388 - val_acc: 0.4082\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8245 - acc: 0.3489 - val_loss: 1.7367 - val_acc: 0.4071\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8206 - acc: 0.3486 - val_loss: 1.7348 - val_acc: 0.4082\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8198 - acc: 0.3513 - val_loss: 1.7328 - val_acc: 0.4078\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8206 - acc: 0.3497 - val_loss: 1.7309 - val_acc: 0.4085\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8188 - acc: 0.3513 - val_loss: 1.7289 - val_acc: 0.4106\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8122 - acc: 0.3535 - val_loss: 1.7270 - val_acc: 0.4096\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8126 - acc: 0.3539 - val_loss: 1.7254 - val_acc: 0.4128\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8111 - acc: 0.3546 - val_loss: 1.7236 - val_acc: 0.4124\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8133 - acc: 0.3519 - val_loss: 1.7223 - val_acc: 0.4110\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8120 - acc: 0.3547 - val_loss: 1.7208 - val_acc: 0.4135\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8105 - acc: 0.3531 - val_loss: 1.7193 - val_acc: 0.4140\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8053 - acc: 0.3577 - val_loss: 1.7178 - val_acc: 0.4137\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8078 - acc: 0.3561 - val_loss: 1.7164 - val_acc: 0.4122\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8104 - acc: 0.3530 - val_loss: 1.7151 - val_acc: 0.4146\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8068 - acc: 0.3538 - val_loss: 1.7139 - val_acc: 0.4142\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 1.8077 - acc: 0.3556 - val_loss: 1.7126 - val_acc: 0.4144\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 1s 36us/step - loss: 1.8027 - acc: 0.3548 - val_loss: 1.7117 - val_acc: 0.4136\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.8022 - acc: 0.3555 - val_loss: 1.7104 - val_acc: 0.4161\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7985 - acc: 0.3564 - val_loss: 1.7090 - val_acc: 0.4157\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.8040 - acc: 0.3569 - val_loss: 1.7079 - val_acc: 0.4158\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.8013 - acc: 0.3581 - val_loss: 1.7069 - val_acc: 0.4159\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.8010 - acc: 0.3578 - val_loss: 1.7057 - val_acc: 0.4156\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7953 - acc: 0.3575 - val_loss: 1.7046 - val_acc: 0.4163\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8006 - acc: 0.3555 - val_loss: 1.7038 - val_acc: 0.4160\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7973 - acc: 0.3584 - val_loss: 1.7028 - val_acc: 0.4170\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7961 - acc: 0.3582 - val_loss: 1.7017 - val_acc: 0.4171\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7960 - acc: 0.3640 - val_loss: 1.7009 - val_acc: 0.4178\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7952 - acc: 0.3580 - val_loss: 1.7001 - val_acc: 0.4166\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7914 - acc: 0.3635 - val_loss: 1.6990 - val_acc: 0.4153\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7943 - acc: 0.3599 - val_loss: 1.6979 - val_acc: 0.4163\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7913 - acc: 0.3594 - val_loss: 1.6971 - val_acc: 0.4176\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7919 - acc: 0.3593 - val_loss: 1.6962 - val_acc: 0.4185\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 1s 35us/step - loss: 1.7906 - acc: 0.3590 - val_loss: 1.6955 - val_acc: 0.4184\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7926 - acc: 0.3594 - val_loss: 1.6947 - val_acc: 0.4180\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7902 - acc: 0.3638 - val_loss: 1.6939 - val_acc: 0.4171\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7866 - acc: 0.3607 - val_loss: 1.6930 - val_acc: 0.4186\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7874 - acc: 0.3605 - val_loss: 1.6921 - val_acc: 0.4175\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7890 - acc: 0.3605 - val_loss: 1.6915 - val_acc: 0.4170\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7917 - acc: 0.3588 - val_loss: 1.6909 - val_acc: 0.4187\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7865 - acc: 0.3626 - val_loss: 1.6901 - val_acc: 0.4183\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7893 - acc: 0.3621 - val_loss: 1.6893 - val_acc: 0.4188\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7865 - acc: 0.3621 - val_loss: 1.6888 - val_acc: 0.4198\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7852 - acc: 0.3630 - val_loss: 1.6880 - val_acc: 0.4190\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7865 - acc: 0.3601 - val_loss: 1.6874 - val_acc: 0.4191\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7819 - acc: 0.3635 - val_loss: 1.6870 - val_acc: 0.4181\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7859 - acc: 0.3651 - val_loss: 1.6863 - val_acc: 0.4196\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7817 - acc: 0.3647 - val_loss: 1.6857 - val_acc: 0.4193\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7836 - acc: 0.3621 - val_loss: 1.6850 - val_acc: 0.4195\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7831 - acc: 0.3663 - val_loss: 1.6844 - val_acc: 0.4183\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7839 - acc: 0.3618 - val_loss: 1.6838 - val_acc: 0.4195\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7850 - acc: 0.3654 - val_loss: 1.6833 - val_acc: 0.4187\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7803 - acc: 0.3613 - val_loss: 1.6826 - val_acc: 0.4195\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 1s 34us/step - loss: 1.7795 - acc: 0.3659 - val_loss: 1.6820 - val_acc: 0.4188\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7798 - acc: 0.3639 - val_loss: 1.6816 - val_acc: 0.4202\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "Validation loss: 1.6816045526504517\n",
      "Validation accuracy (NORMALIZED): 0.4202\n",
      "================================================\n",
      "Split: 1\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542744650.568251_fold[1]_pre-trained\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 2.3834 - acc: 0.1023 - val_loss: 2.3046 - val_acc: 0.1248\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 2.3294 - acc: 0.1134 - val_loss: 2.2877 - val_acc: 0.1494\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.3015 - acc: 0.1305 - val_loss: 2.2775 - val_acc: 0.1853\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.2831 - acc: 0.1481 - val_loss: 2.2554 - val_acc: 0.2281\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.2618 - acc: 0.1718 - val_loss: 2.2264 - val_acc: 0.2481\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.2432 - acc: 0.1874 - val_loss: 2.1954 - val_acc: 0.2585\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.2159 - acc: 0.2038 - val_loss: 2.1523 - val_acc: 0.2795\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.1905 - acc: 0.2173 - val_loss: 2.1105 - val_acc: 0.2987\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.1627 - acc: 0.2303 - val_loss: 2.0740 - val_acc: 0.3203\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.1364 - acc: 0.2421 - val_loss: 2.0454 - val_acc: 0.3348\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.1062 - acc: 0.2554 - val_loss: 2.0236 - val_acc: 0.3431\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 2.0872 - acc: 0.2633 - val_loss: 2.0054 - val_acc: 0.3499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.0620 - acc: 0.2697 - val_loss: 1.9660 - val_acc: 0.3537\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.0341 - acc: 0.2739 - val_loss: 1.9401 - val_acc: 0.3564\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.0081 - acc: 0.2826 - val_loss: 1.9206 - val_acc: 0.3647\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9894 - acc: 0.2922 - val_loss: 1.9049 - val_acc: 0.3694\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9704 - acc: 0.2963 - val_loss: 1.8911 - val_acc: 0.3714\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9575 - acc: 0.3032 - val_loss: 1.8790 - val_acc: 0.3784\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9438 - acc: 0.3072 - val_loss: 1.8682 - val_acc: 0.3791\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9359 - acc: 0.3081 - val_loss: 1.8583 - val_acc: 0.3826\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9235 - acc: 0.3195 - val_loss: 1.8494 - val_acc: 0.3850\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9146 - acc: 0.3152 - val_loss: 1.8414 - val_acc: 0.3861\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9113 - acc: 0.3218 - val_loss: 1.8338 - val_acc: 0.3894\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8976 - acc: 0.3290 - val_loss: 1.8268 - val_acc: 0.3897\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8903 - acc: 0.3273 - val_loss: 1.8202 - val_acc: 0.3925\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8877 - acc: 0.3252 - val_loss: 1.8141 - val_acc: 0.3944\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8826 - acc: 0.3272 - val_loss: 1.8086 - val_acc: 0.3955\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8787 - acc: 0.3310 - val_loss: 1.8032 - val_acc: 0.3955\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8734 - acc: 0.3339 - val_loss: 1.7984 - val_acc: 0.3978\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8715 - acc: 0.3355 - val_loss: 1.7940 - val_acc: 0.3979\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8632 - acc: 0.3359 - val_loss: 1.7894 - val_acc: 0.3999\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8612 - acc: 0.3366 - val_loss: 1.7852 - val_acc: 0.4003\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8568 - acc: 0.3381 - val_loss: 1.7811 - val_acc: 0.4019\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8532 - acc: 0.3380 - val_loss: 1.7774 - val_acc: 0.4020\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8510 - acc: 0.3394 - val_loss: 1.7738 - val_acc: 0.4035\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8478 - acc: 0.3422 - val_loss: 1.7705 - val_acc: 0.4040\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8448 - acc: 0.3441 - val_loss: 1.7673 - val_acc: 0.4045\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8441 - acc: 0.3432 - val_loss: 1.7642 - val_acc: 0.4034\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8388 - acc: 0.3425 - val_loss: 1.7613 - val_acc: 0.4043\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8378 - acc: 0.3469 - val_loss: 1.7584 - val_acc: 0.4054\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8349 - acc: 0.3474 - val_loss: 1.7558 - val_acc: 0.4042\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8357 - acc: 0.3447 - val_loss: 1.7532 - val_acc: 0.4049\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8331 - acc: 0.3477 - val_loss: 1.7508 - val_acc: 0.4056\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8260 - acc: 0.3511 - val_loss: 1.7487 - val_acc: 0.4049\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8241 - acc: 0.3479 - val_loss: 1.7463 - val_acc: 0.4060\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8252 - acc: 0.3499 - val_loss: 1.7440 - val_acc: 0.4055\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8251 - acc: 0.3480 - val_loss: 1.7419 - val_acc: 0.4065\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8249 - acc: 0.3480 - val_loss: 1.7401 - val_acc: 0.4074\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8154 - acc: 0.3510 - val_loss: 1.7380 - val_acc: 0.4071\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8176 - acc: 0.3498 - val_loss: 1.7359 - val_acc: 0.4079\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8149 - acc: 0.3529 - val_loss: 1.7343 - val_acc: 0.4089\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8197 - acc: 0.3492 - val_loss: 1.7326 - val_acc: 0.4088\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8126 - acc: 0.3560 - val_loss: 1.7307 - val_acc: 0.4098\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8125 - acc: 0.3537 - val_loss: 1.7290 - val_acc: 0.4104\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8092 - acc: 0.3555 - val_loss: 1.7274 - val_acc: 0.4103\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8081 - acc: 0.3539 - val_loss: 1.7258 - val_acc: 0.4098\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8087 - acc: 0.3566 - val_loss: 1.7242 - val_acc: 0.4107\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8088 - acc: 0.3519 - val_loss: 1.7227 - val_acc: 0.4106\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8086 - acc: 0.3522 - val_loss: 1.7214 - val_acc: 0.4108\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8057 - acc: 0.3538 - val_loss: 1.7199 - val_acc: 0.4128\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8063 - acc: 0.3564 - val_loss: 1.7188 - val_acc: 0.4109\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8057 - acc: 0.3555 - val_loss: 1.7174 - val_acc: 0.4116\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8031 - acc: 0.3585 - val_loss: 1.7163 - val_acc: 0.4120\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8007 - acc: 0.3573 - val_loss: 1.7149 - val_acc: 0.4134\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7977 - acc: 0.3598 - val_loss: 1.7136 - val_acc: 0.4127\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8051 - acc: 0.3557 - val_loss: 1.7126 - val_acc: 0.4127\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7970 - acc: 0.3594 - val_loss: 1.7115 - val_acc: 0.4125\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8010 - acc: 0.3574 - val_loss: 1.7105 - val_acc: 0.4133\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7954 - acc: 0.3596 - val_loss: 1.7094 - val_acc: 0.4132\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7974 - acc: 0.3585 - val_loss: 1.7085 - val_acc: 0.4158\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7984 - acc: 0.3571 - val_loss: 1.7073 - val_acc: 0.4136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7955 - acc: 0.3608 - val_loss: 1.7065 - val_acc: 0.4124\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7923 - acc: 0.3613 - val_loss: 1.7055 - val_acc: 0.4158\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7914 - acc: 0.3603 - val_loss: 1.7043 - val_acc: 0.4149\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7925 - acc: 0.3606 - val_loss: 1.7034 - val_acc: 0.4148\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7932 - acc: 0.3574 - val_loss: 1.7027 - val_acc: 0.4147\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7919 - acc: 0.3584 - val_loss: 1.7020 - val_acc: 0.4160\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7892 - acc: 0.3621 - val_loss: 1.7010 - val_acc: 0.4158\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7894 - acc: 0.3622 - val_loss: 1.7000 - val_acc: 0.4164\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7879 - acc: 0.3607 - val_loss: 1.6993 - val_acc: 0.4169\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7897 - acc: 0.3618 - val_loss: 1.6985 - val_acc: 0.4167\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7890 - acc: 0.3610 - val_loss: 1.6977 - val_acc: 0.4166\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7879 - acc: 0.3629 - val_loss: 1.6970 - val_acc: 0.4174\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7853 - acc: 0.3631 - val_loss: 1.6961 - val_acc: 0.4171\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7867 - acc: 0.3624 - val_loss: 1.6955 - val_acc: 0.4168\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7826 - acc: 0.3621 - val_loss: 1.6946 - val_acc: 0.4191\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7824 - acc: 0.3627 - val_loss: 1.6943 - val_acc: 0.4161\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7840 - acc: 0.3617 - val_loss: 1.6934 - val_acc: 0.4180\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7851 - acc: 0.3599 - val_loss: 1.6929 - val_acc: 0.4180\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7812 - acc: 0.3618 - val_loss: 1.6921 - val_acc: 0.4190\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7832 - acc: 0.3618 - val_loss: 1.6915 - val_acc: 0.4180\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7830 - acc: 0.3616 - val_loss: 1.6910 - val_acc: 0.4191\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7851 - acc: 0.3626 - val_loss: 1.6905 - val_acc: 0.4182\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7806 - acc: 0.3644 - val_loss: 1.6899 - val_acc: 0.4195\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7828 - acc: 0.3645 - val_loss: 1.6894 - val_acc: 0.4180\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7806 - acc: 0.3629 - val_loss: 1.6888 - val_acc: 0.4194\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7801 - acc: 0.3631 - val_loss: 1.6880 - val_acc: 0.4183\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7818 - acc: 0.3642 - val_loss: 1.6878 - val_acc: 0.4193\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7779 - acc: 0.3636 - val_loss: 1.6869 - val_acc: 0.4187\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7755 - acc: 0.3640 - val_loss: 1.6864 - val_acc: 0.4201\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "Validation loss: 1.6863978769302368\n",
      "Validation accuracy (NORMALIZED): 0.4201\n",
      "================================================\n",
      "Split: 2\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542744779.3710616_fold[2]_pre-trained\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 2s 38us/step - loss: 2.3971 - acc: 0.1075 - val_loss: 2.3082 - val_acc: 0.1034\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.3322 - acc: 0.1219 - val_loss: 2.2780 - val_acc: 0.1554\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.3035 - acc: 0.1338 - val_loss: 2.2631 - val_acc: 0.2125\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.2821 - acc: 0.1519 - val_loss: 2.2453 - val_acc: 0.2384\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.2643 - acc: 0.1641 - val_loss: 2.2216 - val_acc: 0.2423\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.2443 - acc: 0.1809 - val_loss: 2.1927 - val_acc: 0.2476\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.2243 - acc: 0.1960 - val_loss: 2.1607 - val_acc: 0.2612\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.2035 - acc: 0.2047 - val_loss: 2.1238 - val_acc: 0.2817\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.1716 - acc: 0.2194 - val_loss: 2.0789 - val_acc: 0.3022\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.1358 - acc: 0.2306 - val_loss: 2.0222 - val_acc: 0.3353\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.0984 - acc: 0.2455 - val_loss: 1.9859 - val_acc: 0.3542\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.0677 - acc: 0.2590 - val_loss: 1.9591 - val_acc: 0.3615\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.0377 - acc: 0.2702 - val_loss: 1.9366 - val_acc: 0.3710\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.0141 - acc: 0.2794 - val_loss: 1.9176 - val_acc: 0.3776\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9935 - acc: 0.2892 - val_loss: 1.9012 - val_acc: 0.3797\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9764 - acc: 0.2990 - val_loss: 1.8866 - val_acc: 0.3830\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9678 - acc: 0.2995 - val_loss: 1.8739 - val_acc: 0.3842\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9515 - acc: 0.3075 - val_loss: 1.8625 - val_acc: 0.3861\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9423 - acc: 0.3048 - val_loss: 1.8523 - val_acc: 0.3872\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9333 - acc: 0.3111 - val_loss: 1.8429 - val_acc: 0.3914\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9243 - acc: 0.3165 - val_loss: 1.8341 - val_acc: 0.3914\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9170 - acc: 0.3168 - val_loss: 1.8264 - val_acc: 0.3929\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9111 - acc: 0.3199 - val_loss: 1.8189 - val_acc: 0.3937\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9006 - acc: 0.3233 - val_loss: 1.8120 - val_acc: 0.3953\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8998 - acc: 0.3234 - val_loss: 1.8056 - val_acc: 0.3949\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8868 - acc: 0.3297 - val_loss: 1.7997 - val_acc: 0.3977\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8820 - acc: 0.3337 - val_loss: 1.7940 - val_acc: 0.3986\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8779 - acc: 0.3322 - val_loss: 1.7886 - val_acc: 0.3994\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8750 - acc: 0.3336 - val_loss: 1.7838 - val_acc: 0.4002\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8707 - acc: 0.3347 - val_loss: 1.7789 - val_acc: 0.3989\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8645 - acc: 0.3372 - val_loss: 1.7745 - val_acc: 0.3993\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8636 - acc: 0.3383 - val_loss: 1.7704 - val_acc: 0.4002\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8574 - acc: 0.3391 - val_loss: 1.7663 - val_acc: 0.4008\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8525 - acc: 0.3423 - val_loss: 1.7625 - val_acc: 0.4020\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8544 - acc: 0.3381 - val_loss: 1.7588 - val_acc: 0.4022\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8505 - acc: 0.3415 - val_loss: 1.7554 - val_acc: 0.4031\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8503 - acc: 0.3414 - val_loss: 1.7521 - val_acc: 0.4034\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8415 - acc: 0.3430 - val_loss: 1.7490 - val_acc: 0.4041\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8397 - acc: 0.3458 - val_loss: 1.7460 - val_acc: 0.4050\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8383 - acc: 0.3434 - val_loss: 1.7431 - val_acc: 0.4039\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8387 - acc: 0.3462 - val_loss: 1.7404 - val_acc: 0.4069\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8378 - acc: 0.3444 - val_loss: 1.7379 - val_acc: 0.4075\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8298 - acc: 0.3472 - val_loss: 1.7352 - val_acc: 0.4071\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8329 - acc: 0.3465 - val_loss: 1.7328 - val_acc: 0.4079\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8329 - acc: 0.3459 - val_loss: 1.7305 - val_acc: 0.4093\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8293 - acc: 0.3511 - val_loss: 1.7283 - val_acc: 0.4077\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8237 - acc: 0.3516 - val_loss: 1.7260 - val_acc: 0.4075\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8251 - acc: 0.3498 - val_loss: 1.7243 - val_acc: 0.4090\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8253 - acc: 0.3476 - val_loss: 1.7223 - val_acc: 0.4100\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8229 - acc: 0.3521 - val_loss: 1.7203 - val_acc: 0.4102\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8226 - acc: 0.3476 - val_loss: 1.7186 - val_acc: 0.4116\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8168 - acc: 0.3533 - val_loss: 1.7168 - val_acc: 0.4107\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8175 - acc: 0.3491 - val_loss: 1.7151 - val_acc: 0.4105\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8179 - acc: 0.3534 - val_loss: 1.7134 - val_acc: 0.4108\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8112 - acc: 0.3555 - val_loss: 1.7117 - val_acc: 0.4104\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8116 - acc: 0.3552 - val_loss: 1.7101 - val_acc: 0.4113\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8119 - acc: 0.3560 - val_loss: 1.7086 - val_acc: 0.4122\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8127 - acc: 0.3566 - val_loss: 1.7071 - val_acc: 0.4121\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8090 - acc: 0.3542 - val_loss: 1.7057 - val_acc: 0.4130\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8074 - acc: 0.3551 - val_loss: 1.7041 - val_acc: 0.4131\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8086 - acc: 0.3559 - val_loss: 1.7028 - val_acc: 0.4149\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8066 - acc: 0.3585 - val_loss: 1.7015 - val_acc: 0.4156\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8047 - acc: 0.3556 - val_loss: 1.7003 - val_acc: 0.4148\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8017 - acc: 0.3564 - val_loss: 1.6991 - val_acc: 0.4145\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8023 - acc: 0.3586 - val_loss: 1.6978 - val_acc: 0.4146\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8045 - acc: 0.3537 - val_loss: 1.6966 - val_acc: 0.4156\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8004 - acc: 0.3574 - val_loss: 1.6955 - val_acc: 0.4168\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8019 - acc: 0.3570 - val_loss: 1.6944 - val_acc: 0.4153\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7984 - acc: 0.3586 - val_loss: 1.6933 - val_acc: 0.4165\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8006 - acc: 0.3565 - val_loss: 1.6923 - val_acc: 0.4164\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7982 - acc: 0.3601 - val_loss: 1.6913 - val_acc: 0.4173\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8007 - acc: 0.3580 - val_loss: 1.6905 - val_acc: 0.4173\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7944 - acc: 0.3615 - val_loss: 1.6894 - val_acc: 0.4175\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7987 - acc: 0.3584 - val_loss: 1.6884 - val_acc: 0.4177\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7953 - acc: 0.3607 - val_loss: 1.6875 - val_acc: 0.4191\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7946 - acc: 0.3628 - val_loss: 1.6864 - val_acc: 0.4178\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7915 - acc: 0.3595 - val_loss: 1.6855 - val_acc: 0.4171\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7901 - acc: 0.3604 - val_loss: 1.6846 - val_acc: 0.4179\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7927 - acc: 0.3590 - val_loss: 1.6839 - val_acc: 0.4190\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7944 - acc: 0.3581 - val_loss: 1.6830 - val_acc: 0.4182\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7928 - acc: 0.3603 - val_loss: 1.6822 - val_acc: 0.4183\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7940 - acc: 0.3599 - val_loss: 1.6815 - val_acc: 0.4194\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7867 - acc: 0.3626 - val_loss: 1.6808 - val_acc: 0.4209\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7934 - acc: 0.3604 - val_loss: 1.6800 - val_acc: 0.4204\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7927 - acc: 0.3599 - val_loss: 1.6794 - val_acc: 0.4199\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7890 - acc: 0.3629 - val_loss: 1.6787 - val_acc: 0.4217\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7913 - acc: 0.3611 - val_loss: 1.6779 - val_acc: 0.4197\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7897 - acc: 0.3590 - val_loss: 1.6774 - val_acc: 0.4207\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7885 - acc: 0.3628 - val_loss: 1.6767 - val_acc: 0.4215\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7843 - acc: 0.3648 - val_loss: 1.6760 - val_acc: 0.4222\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7852 - acc: 0.3623 - val_loss: 1.6754 - val_acc: 0.4223\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7874 - acc: 0.3641 - val_loss: 1.6747 - val_acc: 0.4216\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7882 - acc: 0.3634 - val_loss: 1.6742 - val_acc: 0.4237\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7838 - acc: 0.3629 - val_loss: 1.6735 - val_acc: 0.4225\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7853 - acc: 0.3639 - val_loss: 1.6728 - val_acc: 0.4208\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7829 - acc: 0.3643 - val_loss: 1.6722 - val_acc: 0.4219\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7865 - acc: 0.3627 - val_loss: 1.6716 - val_acc: 0.4218\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7824 - acc: 0.3642 - val_loss: 1.6712 - val_acc: 0.4221\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7830 - acc: 0.3619 - val_loss: 1.6706 - val_acc: 0.4210\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7808 - acc: 0.3614 - val_loss: 1.6700 - val_acc: 0.4207\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "Validation loss: 1.6700078247070314\n",
      "Validation accuracy (NORMALIZED): 0.4207\n",
      "================================================\n",
      "Split: 3\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542744906.6210046_fold[3]_pre-trained\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 2.3576 - acc: 0.1058 - val_loss: 2.2944 - val_acc: 0.1316\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.3127 - acc: 0.1241 - val_loss: 2.2830 - val_acc: 0.1742\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.2908 - acc: 0.1418 - val_loss: 2.2688 - val_acc: 0.2150\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.2733 - acc: 0.1596 - val_loss: 2.2509 - val_acc: 0.2323\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.2596 - acc: 0.1724 - val_loss: 2.2309 - val_acc: 0.2381\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.2396 - acc: 0.1868 - val_loss: 2.2010 - val_acc: 0.2505\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.2186 - acc: 0.2013 - val_loss: 2.1644 - val_acc: 0.2658\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.1974 - acc: 0.2134 - val_loss: 2.1299 - val_acc: 0.2766\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.1727 - acc: 0.2258 - val_loss: 2.0981 - val_acc: 0.2902\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.1434 - acc: 0.2354 - val_loss: 2.0536 - val_acc: 0.3073\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.1043 - acc: 0.2478 - val_loss: 2.0017 - val_acc: 0.3264\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.0760 - acc: 0.2567 - val_loss: 1.9688 - val_acc: 0.3395\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.0465 - acc: 0.2694 - val_loss: 1.9440 - val_acc: 0.3504\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.0212 - acc: 0.2768 - val_loss: 1.9235 - val_acc: 0.3602\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 2.0000 - acc: 0.2825 - val_loss: 1.9063 - val_acc: 0.3653\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9837 - acc: 0.2876 - val_loss: 1.8915 - val_acc: 0.3699\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9688 - acc: 0.2967 - val_loss: 1.8786 - val_acc: 0.3740\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9520 - acc: 0.3040 - val_loss: 1.8671 - val_acc: 0.3778\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9412 - acc: 0.3075 - val_loss: 1.8567 - val_acc: 0.3823\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9323 - acc: 0.3122 - val_loss: 1.8470 - val_acc: 0.3819\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9237 - acc: 0.3126 - val_loss: 1.8382 - val_acc: 0.3844\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9096 - acc: 0.3190 - val_loss: 1.8299 - val_acc: 0.3843\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9060 - acc: 0.3178 - val_loss: 1.8227 - val_acc: 0.3865\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.9016 - acc: 0.3209 - val_loss: 1.8159 - val_acc: 0.3880\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8908 - acc: 0.3265 - val_loss: 1.8097 - val_acc: 0.3916\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8846 - acc: 0.3306 - val_loss: 1.8039 - val_acc: 0.3939\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8795 - acc: 0.3319 - val_loss: 1.7981 - val_acc: 0.3946\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8763 - acc: 0.3339 - val_loss: 1.7929 - val_acc: 0.3947\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8714 - acc: 0.3320 - val_loss: 1.7879 - val_acc: 0.3951\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8684 - acc: 0.3330 - val_loss: 1.7836 - val_acc: 0.3981\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8677 - acc: 0.3348 - val_loss: 1.7792 - val_acc: 0.3955\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8632 - acc: 0.3376 - val_loss: 1.7751 - val_acc: 0.3969\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8574 - acc: 0.3370 - val_loss: 1.7715 - val_acc: 0.3978\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8542 - acc: 0.3408 - val_loss: 1.7678 - val_acc: 0.3993\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8539 - acc: 0.3386 - val_loss: 1.7644 - val_acc: 0.4001\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8485 - acc: 0.3440 - val_loss: 1.7612 - val_acc: 0.3985\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8446 - acc: 0.3435 - val_loss: 1.7580 - val_acc: 0.4020\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8450 - acc: 0.3422 - val_loss: 1.7550 - val_acc: 0.4026\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8386 - acc: 0.3446 - val_loss: 1.7521 - val_acc: 0.4021\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8379 - acc: 0.3453 - val_loss: 1.7492 - val_acc: 0.4035\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8361 - acc: 0.3449 - val_loss: 1.7468 - val_acc: 0.4039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8352 - acc: 0.3454 - val_loss: 1.7442 - val_acc: 0.4054\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8306 - acc: 0.3461 - val_loss: 1.7416 - val_acc: 0.4060\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8254 - acc: 0.3488 - val_loss: 1.7394 - val_acc: 0.4066\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8278 - acc: 0.3480 - val_loss: 1.7369 - val_acc: 0.4073\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8246 - acc: 0.3501 - val_loss: 1.7347 - val_acc: 0.4058\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8257 - acc: 0.3491 - val_loss: 1.7327 - val_acc: 0.4067\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8256 - acc: 0.3466 - val_loss: 1.7307 - val_acc: 0.4091\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8216 - acc: 0.3520 - val_loss: 1.7290 - val_acc: 0.4104\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8162 - acc: 0.3525 - val_loss: 1.7269 - val_acc: 0.4089\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8187 - acc: 0.3485 - val_loss: 1.7253 - val_acc: 0.4108\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8153 - acc: 0.3550 - val_loss: 1.7234 - val_acc: 0.4096\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8155 - acc: 0.3504 - val_loss: 1.7218 - val_acc: 0.4105\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8128 - acc: 0.3539 - val_loss: 1.7201 - val_acc: 0.4104\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8118 - acc: 0.3549 - val_loss: 1.7185 - val_acc: 0.4097\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8105 - acc: 0.3542 - val_loss: 1.7169 - val_acc: 0.4133\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8099 - acc: 0.3565 - val_loss: 1.7155 - val_acc: 0.4116\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8047 - acc: 0.3551 - val_loss: 1.7142 - val_acc: 0.4126\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8089 - acc: 0.3537 - val_loss: 1.7127 - val_acc: 0.4120\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8094 - acc: 0.3544 - val_loss: 1.7114 - val_acc: 0.4146\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8062 - acc: 0.3566 - val_loss: 1.7102 - val_acc: 0.4120\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8054 - acc: 0.3549 - val_loss: 1.7089 - val_acc: 0.4124\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8057 - acc: 0.3561 - val_loss: 1.7078 - val_acc: 0.4126\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8052 - acc: 0.3576 - val_loss: 1.7065 - val_acc: 0.4131\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7987 - acc: 0.3594 - val_loss: 1.7051 - val_acc: 0.4133\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8000 - acc: 0.3543 - val_loss: 1.7041 - val_acc: 0.4154\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8004 - acc: 0.3588 - val_loss: 1.7031 - val_acc: 0.4141\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7983 - acc: 0.3622 - val_loss: 1.7019 - val_acc: 0.4131\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.8013 - acc: 0.3575 - val_loss: 1.7010 - val_acc: 0.4138\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7961 - acc: 0.3572 - val_loss: 1.7003 - val_acc: 0.4148\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7967 - acc: 0.3573 - val_loss: 1.6992 - val_acc: 0.4155\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7957 - acc: 0.3577 - val_loss: 1.6981 - val_acc: 0.4152\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7972 - acc: 0.3589 - val_loss: 1.6971 - val_acc: 0.4152\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7991 - acc: 0.3598 - val_loss: 1.6963 - val_acc: 0.4161\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7935 - acc: 0.3598 - val_loss: 1.6954 - val_acc: 0.4164\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7915 - acc: 0.3599 - val_loss: 1.6947 - val_acc: 0.4150\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7974 - acc: 0.3614 - val_loss: 1.6939 - val_acc: 0.4162\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7900 - acc: 0.3594 - val_loss: 1.6928 - val_acc: 0.4155\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7937 - acc: 0.3616 - val_loss: 1.6921 - val_acc: 0.4164\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7881 - acc: 0.3649 - val_loss: 1.6912 - val_acc: 0.4160\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7883 - acc: 0.3620 - val_loss: 1.6903 - val_acc: 0.4169\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7903 - acc: 0.3603 - val_loss: 1.6895 - val_acc: 0.4166\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7875 - acc: 0.3625 - val_loss: 1.6887 - val_acc: 0.4172\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7879 - acc: 0.3619 - val_loss: 1.6881 - val_acc: 0.4159\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7875 - acc: 0.3607 - val_loss: 1.6875 - val_acc: 0.4172\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7895 - acc: 0.3597 - val_loss: 1.6868 - val_acc: 0.4156\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7855 - acc: 0.3627 - val_loss: 1.6861 - val_acc: 0.4182\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7862 - acc: 0.3627 - val_loss: 1.6853 - val_acc: 0.4174\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7886 - acc: 0.3608 - val_loss: 1.6848 - val_acc: 0.4180\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7876 - acc: 0.3600 - val_loss: 1.6842 - val_acc: 0.4184\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7846 - acc: 0.3629 - val_loss: 1.6834 - val_acc: 0.4195\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7838 - acc: 0.3647 - val_loss: 1.6828 - val_acc: 0.4192\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7861 - acc: 0.3613 - val_loss: 1.6823 - val_acc: 0.4190\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7843 - acc: 0.3611 - val_loss: 1.6817 - val_acc: 0.4186\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7843 - acc: 0.3621 - val_loss: 1.6813 - val_acc: 0.4190\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7845 - acc: 0.3637 - val_loss: 1.6807 - val_acc: 0.4193\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7864 - acc: 0.3656 - val_loss: 1.6802 - val_acc: 0.4197\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7829 - acc: 0.3628 - val_loss: 1.6797 - val_acc: 0.4190\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7795 - acc: 0.3675 - val_loss: 1.6791 - val_acc: 0.4203\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 1s 31us/step - loss: 1.7822 - acc: 0.3654 - val_loss: 1.6785 - val_acc: 0.4196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 31us/step\n",
      "Validation loss: 1.678535629272461\n",
      "Validation accuracy (NORMALIZED): 0.4196\n",
      "================================================\n",
      "Split: 4\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542745034.5268083_fold[4]_pre-trained\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 2.3281 - acc: 0.1118 - val_loss: 2.2958 - val_acc: 0.1300\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.2993 - acc: 0.1286 - val_loss: 2.2835 - val_acc: 0.1718\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.2864 - acc: 0.1389 - val_loss: 2.2691 - val_acc: 0.2082\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.2667 - acc: 0.1595 - val_loss: 2.2359 - val_acc: 0.2422\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.2428 - acc: 0.1842 - val_loss: 2.1964 - val_acc: 0.2705\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.2182 - acc: 0.2020 - val_loss: 2.1643 - val_acc: 0.2854\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.1947 - acc: 0.2148 - val_loss: 2.1363 - val_acc: 0.2991\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.1714 - acc: 0.2284 - val_loss: 2.1005 - val_acc: 0.3050\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.1479 - acc: 0.2370 - val_loss: 2.0675 - val_acc: 0.3208\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.1219 - acc: 0.2483 - val_loss: 2.0340 - val_acc: 0.3340\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.0955 - acc: 0.2582 - val_loss: 2.0037 - val_acc: 0.3499\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 2.0743 - acc: 0.2671 - val_loss: 1.9829 - val_acc: 0.3575\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.0558 - acc: 0.2751 - val_loss: 1.9667 - val_acc: 0.3647\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.0288 - acc: 0.2815 - val_loss: 1.9313 - val_acc: 0.3666\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 2.0059 - acc: 0.2882 - val_loss: 1.9071 - val_acc: 0.3783\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.9805 - acc: 0.2961 - val_loss: 1.8891 - val_acc: 0.3811\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9628 - acc: 0.3047 - val_loss: 1.8744 - val_acc: 0.3857\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9502 - acc: 0.3069 - val_loss: 1.8617 - val_acc: 0.3855\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9389 - acc: 0.3114 - val_loss: 1.8509 - val_acc: 0.3916\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.9269 - acc: 0.3176 - val_loss: 1.8408 - val_acc: 0.3924\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9188 - acc: 0.3195 - val_loss: 1.8320 - val_acc: 0.3933\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9087 - acc: 0.3254 - val_loss: 1.8239 - val_acc: 0.3941\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.9016 - acc: 0.3234 - val_loss: 1.8166 - val_acc: 0.3961\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8960 - acc: 0.3260 - val_loss: 1.8100 - val_acc: 0.3956\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8904 - acc: 0.3270 - val_loss: 1.8034 - val_acc: 0.3966\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8840 - acc: 0.3309 - val_loss: 1.7976 - val_acc: 0.3989\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8762 - acc: 0.3335 - val_loss: 1.7920 - val_acc: 0.4009\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8731 - acc: 0.3347 - val_loss: 1.7869 - val_acc: 0.4012\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8656 - acc: 0.3398 - val_loss: 1.7818 - val_acc: 0.4016\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8654 - acc: 0.3365 - val_loss: 1.7772 - val_acc: 0.4005\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8598 - acc: 0.3413 - val_loss: 1.7730 - val_acc: 0.4011\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8568 - acc: 0.3430 - val_loss: 1.7690 - val_acc: 0.4023\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8528 - acc: 0.3394 - val_loss: 1.7653 - val_acc: 0.4047\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8504 - acc: 0.3430 - val_loss: 1.7616 - val_acc: 0.4023\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8467 - acc: 0.3430 - val_loss: 1.7581 - val_acc: 0.4034\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8425 - acc: 0.3445 - val_loss: 1.7548 - val_acc: 0.4033\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8411 - acc: 0.3456 - val_loss: 1.7517 - val_acc: 0.4051\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8392 - acc: 0.3459 - val_loss: 1.7488 - val_acc: 0.4040\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8382 - acc: 0.3481 - val_loss: 1.7459 - val_acc: 0.4061\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8340 - acc: 0.3477 - val_loss: 1.7431 - val_acc: 0.4050\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8315 - acc: 0.3483 - val_loss: 1.7406 - val_acc: 0.4073\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8322 - acc: 0.3477 - val_loss: 1.7382 - val_acc: 0.4061\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8303 - acc: 0.3489 - val_loss: 1.7360 - val_acc: 0.4095\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8254 - acc: 0.3489 - val_loss: 1.7338 - val_acc: 0.4066\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8275 - acc: 0.3486 - val_loss: 1.7316 - val_acc: 0.4084\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8225 - acc: 0.3514 - val_loss: 1.7294 - val_acc: 0.4085\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8232 - acc: 0.3526 - val_loss: 1.7275 - val_acc: 0.4096\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8209 - acc: 0.3525 - val_loss: 1.7255 - val_acc: 0.4099\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8231 - acc: 0.3525 - val_loss: 1.7237 - val_acc: 0.4097\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8148 - acc: 0.3552 - val_loss: 1.7220 - val_acc: 0.4089\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8169 - acc: 0.3510 - val_loss: 1.7200 - val_acc: 0.4091\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8140 - acc: 0.3544 - val_loss: 1.7185 - val_acc: 0.4113\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8155 - acc: 0.3540 - val_loss: 1.7169 - val_acc: 0.4110\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8138 - acc: 0.3514 - val_loss: 1.7154 - val_acc: 0.4111\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8098 - acc: 0.3552 - val_loss: 1.7137 - val_acc: 0.4101\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8081 - acc: 0.3542 - val_loss: 1.7122 - val_acc: 0.4115\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8126 - acc: 0.3546 - val_loss: 1.7111 - val_acc: 0.4108\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8031 - acc: 0.3580 - val_loss: 1.7095 - val_acc: 0.4104\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8075 - acc: 0.3578 - val_loss: 1.7082 - val_acc: 0.4124\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.8054 - acc: 0.3572 - val_loss: 1.7068 - val_acc: 0.4119\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8066 - acc: 0.3564 - val_loss: 1.7056 - val_acc: 0.4121\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8015 - acc: 0.3578 - val_loss: 1.7044 - val_acc: 0.4124\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8021 - acc: 0.3567 - val_loss: 1.7033 - val_acc: 0.4116\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8050 - acc: 0.3569 - val_loss: 1.7018 - val_acc: 0.4149\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8027 - acc: 0.3566 - val_loss: 1.7009 - val_acc: 0.4142\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8007 - acc: 0.3570 - val_loss: 1.6997 - val_acc: 0.4152\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7991 - acc: 0.3555 - val_loss: 1.6987 - val_acc: 0.4138\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.8017 - acc: 0.3545 - val_loss: 1.6977 - val_acc: 0.4138\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7975 - acc: 0.3590 - val_loss: 1.6967 - val_acc: 0.4143\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7995 - acc: 0.3577 - val_loss: 1.6957 - val_acc: 0.4145\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7963 - acc: 0.3585 - val_loss: 1.6947 - val_acc: 0.4154\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7958 - acc: 0.3589 - val_loss: 1.6939 - val_acc: 0.4138\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7958 - acc: 0.3616 - val_loss: 1.6930 - val_acc: 0.4149\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7947 - acc: 0.3576 - val_loss: 1.6921 - val_acc: 0.4144\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7926 - acc: 0.3619 - val_loss: 1.6913 - val_acc: 0.4153\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7934 - acc: 0.3594 - val_loss: 1.6903 - val_acc: 0.4155\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7879 - acc: 0.3612 - val_loss: 1.6895 - val_acc: 0.4148\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7932 - acc: 0.3633 - val_loss: 1.6888 - val_acc: 0.4150\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7918 - acc: 0.3588 - val_loss: 1.6881 - val_acc: 0.4157\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7938 - acc: 0.3618 - val_loss: 1.6874 - val_acc: 0.4170\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7919 - acc: 0.3582 - val_loss: 1.6866 - val_acc: 0.4156\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7887 - acc: 0.3624 - val_loss: 1.6858 - val_acc: 0.4167\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7900 - acc: 0.3599 - val_loss: 1.6851 - val_acc: 0.4180\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7883 - acc: 0.3622 - val_loss: 1.6842 - val_acc: 0.4176\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7890 - acc: 0.3617 - val_loss: 1.6837 - val_acc: 0.4161\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7893 - acc: 0.3612 - val_loss: 1.6832 - val_acc: 0.4171\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7864 - acc: 0.3612 - val_loss: 1.6825 - val_acc: 0.4182\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7863 - acc: 0.3629 - val_loss: 1.6819 - val_acc: 0.4165\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7876 - acc: 0.3597 - val_loss: 1.6813 - val_acc: 0.4158\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7853 - acc: 0.3638 - val_loss: 1.6806 - val_acc: 0.4166\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7842 - acc: 0.3636 - val_loss: 1.6801 - val_acc: 0.4172\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7847 - acc: 0.3642 - val_loss: 1.6794 - val_acc: 0.4173\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7797 - acc: 0.3635 - val_loss: 1.6787 - val_acc: 0.4177\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7845 - acc: 0.3628 - val_loss: 1.6783 - val_acc: 0.4171\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 1s 33us/step - loss: 1.7873 - acc: 0.3641 - val_loss: 1.6778 - val_acc: 0.4194\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7814 - acc: 0.3612 - val_loss: 1.6772 - val_acc: 0.4175\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7780 - acc: 0.3680 - val_loss: 1.6766 - val_acc: 0.4173\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7791 - acc: 0.3655 - val_loss: 1.6760 - val_acc: 0.4181\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7816 - acc: 0.3640 - val_loss: 1.6756 - val_acc: 0.4177\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 1s 32us/step - loss: 1.7816 - acc: 0.3637 - val_loss: 1.6750 - val_acc: 0.4183\n",
      "10000/10000 [==============================] - 0s 32us/step\n",
      "Validation loss: 1.6749737756729126\n",
      "Validation accuracy (NORMALIZED): 0.4183\n",
      "[[1.6816045526504517, 0.4202], [1.6863978769302368, 0.4201], [1.6700078247070314, 0.4207], [1.678535629272461, 0.4196], [1.6749737756729126, 0.4183]]\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Training model and Evaluation\n",
    "#=====================================\n",
    "\n",
    "y_train_categorical = to_categorical(y_train, num_classes=n_classes)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=n_classes)\n",
    "\n",
    "scores = []\n",
    "for i in range(folds):\n",
    "    #--- Loading model\n",
    "    model  = get_squeezenet_ft()\n",
    "\n",
    "    \n",
    "    #--- Evaluating the model for split i\n",
    "    print(\"================================================\")\n",
    "    print(\"Split: \"+str(i))\n",
    "    print(\"Number of Epochs: \"+str(n_epochs))\n",
    "    print(\"Train shape:\",X_train[i].shape)\n",
    "    print(\"Train batch size: \"+str(train_batch_size))\n",
    "    print(\"Val batch size: \"+str(val_batch_size))\n",
    "    print(\"================================================\")\n",
    "    \n",
    "    #=====================================\n",
    "    # Tensorboard callback\n",
    "    #=====================================\n",
    "    print(\"--- Preparing tensorboard\")\n",
    "    log_dir = \"logs/{}_fold[{}]_{}\".format(time(), i, 'pre-trained')\n",
    "    print(\"Log Dir: \", log_dir)\n",
    "    tbCallBack = TensorBoard(log_dir=log_dir, write_graph=True)    \n",
    "    \n",
    "    # Training without data augmentation\n",
    "    model.fit(X_train[i],y_train_categorical[i], batch_size=train_batch_size, \n",
    "              epochs=n_epochs, \n",
    "              validation_data=(X_val[i],y_val_categorical[i]),\n",
    "              verbose=1,\n",
    "              callbacks=[tbCallBack])\n",
    "    \n",
    "    #--- Evaluating the model for split i\n",
    "    score = model.evaluate(x=X_val[i], y=y_val_categorical[i], batch_size=val_batch_size, verbose=1)\n",
    "    scores.append(score)\n",
    "    print('Validation loss:', score[0])\n",
    "    print('Validation accuracy (NORMALIZED):', score[1])\n",
    "    \n",
    "#--- Showing scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation loss: 1.6783039318466186\n",
      "Mean Validation accuracy (NORMALIZED): 0.41978\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Evaluate on validation\n",
    "#=====================================\n",
    "\n",
    "#--- The evaluation of the model \n",
    "np_aux = np.array(scores).mean(axis=0)\n",
    "\n",
    "print('Mean Validation loss:', np_aux[0])\n",
    "print('Mean Validation accuracy (NORMALIZED):', np_aux[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "-----------------\n",
    "\n",
    "# Training last 2 Fire Modules + classification layers\n",
    "As we could see, the frozen network performed very poorly. By freezing most layers, we do not allow SqueezeNet to adapt its weights to features present in CIFAR-10.\n",
    "\n",
    "Let's try to unfreeze the last two fire modules and train once more. The architecture will be:\n",
    "<img src=\"partFrozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 10)     5130        drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 10)     0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_14 (Gl (None, 10)           0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 10)           0           global_average_pooling2d_14[0][0]\n",
      "==================================================================================================\n",
      "Total params: 727,626\n",
      "Trainable params: 391,306\n",
      "Non-trainable params: 336,320\n",
      "__________________________________________________________________________________________________\n",
      "input_7 False\n",
      "conv1 False\n",
      "relu_conv1 False\n",
      "pool1 False\n",
      "fire2/squeeze1x1 False\n",
      "fire2/relu_squeeze1x1 False\n",
      "fire2/expand1x1 False\n",
      "fire2/expand3x3 False\n",
      "fire2/relu_expand1x1 False\n",
      "fire2/relu_expand3x3 False\n",
      "fire2/concat False\n",
      "fire3/squeeze1x1 False\n",
      "fire3/relu_squeeze1x1 False\n",
      "fire3/expand1x1 False\n",
      "fire3/expand3x3 False\n",
      "fire3/relu_expand1x1 False\n",
      "fire3/relu_expand3x3 False\n",
      "fire3/concat False\n",
      "pool3 False\n",
      "fire4/squeeze1x1 False\n",
      "fire4/relu_squeeze1x1 False\n",
      "fire4/expand1x1 False\n",
      "fire4/expand3x3 False\n",
      "fire4/relu_expand1x1 False\n",
      "fire4/relu_expand3x3 False\n",
      "fire4/concat False\n",
      "fire5/squeeze1x1 False\n",
      "fire5/relu_squeeze1x1 False\n",
      "fire5/expand1x1 False\n",
      "fire5/expand3x3 False\n",
      "fire5/relu_expand1x1 False\n",
      "fire5/relu_expand3x3 False\n",
      "fire5/concat False\n",
      "pool5 False\n",
      "fire6/squeeze1x1 False\n",
      "fire6/relu_squeeze1x1 False\n",
      "fire6/expand1x1 False\n",
      "fire6/expand3x3 False\n",
      "fire6/relu_expand1x1 False\n",
      "fire6/relu_expand3x3 False\n",
      "fire6/concat False\n",
      "fire7/squeeze1x1 False\n",
      "fire7/relu_squeeze1x1 False\n",
      "fire7/expand1x1 False\n",
      "fire7/expand3x3 False\n",
      "fire7/relu_expand1x1 False\n",
      "fire7/relu_expand3x3 False\n",
      "fire7/concat False\n",
      "fire8/squeeze1x1 True\n",
      "fire8/relu_squeeze1x1 True\n",
      "fire8/expand1x1 True\n",
      "fire8/expand3x3 True\n",
      "fire8/relu_expand1x1 True\n",
      "fire8/relu_expand3x3 True\n",
      "fire8/concat True\n",
      "fire9/squeeze1x1 True\n",
      "fire9/relu_squeeze1x1 True\n",
      "fire9/expand1x1 True\n",
      "fire9/expand3x3 True\n",
      "fire9/relu_expand1x1 True\n",
      "fire9/relu_expand3x3 True\n",
      "fire9/concat True\n",
      "drop9 True\n",
      "conv10 True\n",
      "relu_conv10 True\n",
      "global_average_pooling2d_14 True\n",
      "loss True\n"
     ]
    }
   ],
   "source": [
    "def get_squeezenet_ft2():\n",
    "    squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "    #=====================================\n",
    "    # Freezing mentioned layers\n",
    "    #=====================================\n",
    "\n",
    "    trainable_layer_index = 19\n",
    "    for i in range(len(squeezeNetModel.layers)-trainable_layer_index):\n",
    "        squeezeNetModel.layers[i].trainable = False\n",
    "\n",
    "    #=====================================\n",
    "    # Add new classification layers\n",
    "    #=====================================\n",
    "\n",
    "    #--- Removing layers until drop 9\n",
    "    squeezeNetModel.layers.pop() #Convolution2D\n",
    "    squeezeNetModel.layers.pop() #Activation ReLU\n",
    "    squeezeNetModel.layers.pop() #Global Avg Pool\n",
    "    squeezeNetModel.layers.pop() #Activation Softmax\n",
    "\n",
    "    #--- Adding classification layer for 10 classes\n",
    "    out = Convolution2D(n_classes, (1, 1), padding='valid', name='conv10')(squeezeNetModel.layers[-1].output)\n",
    "    out = Activation('relu', name='relu_conv10')(out)\n",
    "\n",
    "    out = GlobalAveragePooling2D()(out)\n",
    "    out = Activation('softmax', name='loss')(out)\n",
    "\n",
    "    #=====================================\n",
    "    # New Model\n",
    "    #=====================================\n",
    "    model = Model(squeezeNetModel.inputs, out, name='squeezenet_new')\n",
    "    opt = optimizer=optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#SGD(lr=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_squeezenet_ft2()\n",
    "model.summary()\n",
    "\n",
    "#--- Check the trainable status of the individual layers\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Split: 0\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542745167.5783021_fold[0]_fine-tunned\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 2s 54us/step - loss: 2.2367 - acc: 0.1845 - val_loss: 2.0404 - val_acc: 0.3121\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.8945 - acc: 0.3330 - val_loss: 1.6590 - val_acc: 0.4238\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.6940 - acc: 0.3953 - val_loss: 1.5580 - val_acc: 0.4509\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.6133 - acc: 0.4262 - val_loss: 1.5058 - val_acc: 0.4665\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.5662 - acc: 0.4433 - val_loss: 1.4765 - val_acc: 0.4796\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.5288 - acc: 0.4552 - val_loss: 1.4500 - val_acc: 0.4872\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.5069 - acc: 0.4663 - val_loss: 1.4329 - val_acc: 0.4930\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4884 - acc: 0.4736 - val_loss: 1.4205 - val_acc: 0.4959\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4713 - acc: 0.4815 - val_loss: 1.4116 - val_acc: 0.4991\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4572 - acc: 0.4847 - val_loss: 1.4002 - val_acc: 0.5007\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4456 - acc: 0.4882 - val_loss: 1.3938 - val_acc: 0.5049\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4369 - acc: 0.4944 - val_loss: 1.3857 - val_acc: 0.5042\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4266 - acc: 0.4944 - val_loss: 1.3796 - val_acc: 0.5069\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4148 - acc: 0.4995 - val_loss: 1.3742 - val_acc: 0.5109\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4082 - acc: 0.5024 - val_loss: 1.3693 - val_acc: 0.5107\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3975 - acc: 0.5074 - val_loss: 1.3651 - val_acc: 0.5159\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3952 - acc: 0.5081 - val_loss: 1.3582 - val_acc: 0.5183\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3875 - acc: 0.5091 - val_loss: 1.3573 - val_acc: 0.5176\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3794 - acc: 0.5123 - val_loss: 1.3522 - val_acc: 0.5195\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3729 - acc: 0.5144 - val_loss: 1.3489 - val_acc: 0.5225\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3749 - acc: 0.5137 - val_loss: 1.3446 - val_acc: 0.5222\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3636 - acc: 0.5175 - val_loss: 1.3465 - val_acc: 0.5212\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3598 - acc: 0.5194 - val_loss: 1.3414 - val_acc: 0.5232\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3551 - acc: 0.5228 - val_loss: 1.3383 - val_acc: 0.5255\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3515 - acc: 0.5222 - val_loss: 1.3339 - val_acc: 0.5243\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3471 - acc: 0.5260 - val_loss: 1.3350 - val_acc: 0.5256\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3401 - acc: 0.5281 - val_loss: 1.3297 - val_acc: 0.5270\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3362 - acc: 0.5277 - val_loss: 1.3261 - val_acc: 0.5310\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3318 - acc: 0.5288 - val_loss: 1.3230 - val_acc: 0.5284\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3310 - acc: 0.5301 - val_loss: 1.3225 - val_acc: 0.5302\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3256 - acc: 0.5318 - val_loss: 1.3213 - val_acc: 0.5316\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3253 - acc: 0.5328 - val_loss: 1.3213 - val_acc: 0.5293\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3230 - acc: 0.5349 - val_loss: 1.3166 - val_acc: 0.5346\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3147 - acc: 0.5354 - val_loss: 1.3137 - val_acc: 0.5352\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3154 - acc: 0.5378 - val_loss: 1.3131 - val_acc: 0.5343\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3107 - acc: 0.5392 - val_loss: 1.3163 - val_acc: 0.5321\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3073 - acc: 0.5400 - val_loss: 1.3087 - val_acc: 0.5363\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3081 - acc: 0.5388 - val_loss: 1.3067 - val_acc: 0.5376\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3018 - acc: 0.5416 - val_loss: 1.3093 - val_acc: 0.5352\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3022 - acc: 0.5415 - val_loss: 1.3065 - val_acc: 0.5402\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2981 - acc: 0.5430 - val_loss: 1.3040 - val_acc: 0.5388\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2956 - acc: 0.5435 - val_loss: 1.3010 - val_acc: 0.5372\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2919 - acc: 0.5452 - val_loss: 1.3027 - val_acc: 0.5395\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2890 - acc: 0.5448 - val_loss: 1.2999 - val_acc: 0.5396\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2873 - acc: 0.5453 - val_loss: 1.2986 - val_acc: 0.5415\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2844 - acc: 0.5495 - val_loss: 1.2975 - val_acc: 0.5417\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2813 - acc: 0.5475 - val_loss: 1.2977 - val_acc: 0.5430\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2825 - acc: 0.5469 - val_loss: 1.2969 - val_acc: 0.5413\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2780 - acc: 0.5490 - val_loss: 1.2941 - val_acc: 0.5444\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2730 - acc: 0.5502 - val_loss: 1.2963 - val_acc: 0.5405\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2743 - acc: 0.5498 - val_loss: 1.2970 - val_acc: 0.5425\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2690 - acc: 0.5519 - val_loss: 1.3017 - val_acc: 0.5386\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2707 - acc: 0.5514 - val_loss: 1.2920 - val_acc: 0.5449\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2672 - acc: 0.5523 - val_loss: 1.2900 - val_acc: 0.5429\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2661 - acc: 0.5528 - val_loss: 1.2911 - val_acc: 0.5435\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2639 - acc: 0.5525 - val_loss: 1.2883 - val_acc: 0.5466\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2608 - acc: 0.5543 - val_loss: 1.2879 - val_acc: 0.5468\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2595 - acc: 0.5538 - val_loss: 1.2902 - val_acc: 0.5467\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2615 - acc: 0.5551 - val_loss: 1.2878 - val_acc: 0.5462\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2548 - acc: 0.5571 - val_loss: 1.2912 - val_acc: 0.5448\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2527 - acc: 0.5572 - val_loss: 1.2847 - val_acc: 0.5480\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2538 - acc: 0.5572 - val_loss: 1.2846 - val_acc: 0.5480\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2501 - acc: 0.5592 - val_loss: 1.2876 - val_acc: 0.5463\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2483 - acc: 0.5593 - val_loss: 1.2853 - val_acc: 0.5464\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2486 - acc: 0.5590 - val_loss: 1.2835 - val_acc: 0.5461\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2432 - acc: 0.5617 - val_loss: 1.2878 - val_acc: 0.5435\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2422 - acc: 0.5608 - val_loss: 1.2837 - val_acc: 0.5493\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2399 - acc: 0.5632 - val_loss: 1.2817 - val_acc: 0.5481\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2388 - acc: 0.5605 - val_loss: 1.2854 - val_acc: 0.5479\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2394 - acc: 0.5620 - val_loss: 1.2790 - val_acc: 0.5502\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2344 - acc: 0.5634 - val_loss: 1.2775 - val_acc: 0.5494\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2346 - acc: 0.5657 - val_loss: 1.2808 - val_acc: 0.5478\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2316 - acc: 0.5648 - val_loss: 1.2782 - val_acc: 0.5470\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2327 - acc: 0.5639 - val_loss: 1.2807 - val_acc: 0.5481\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2312 - acc: 0.5639 - val_loss: 1.2779 - val_acc: 0.5506\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2295 - acc: 0.5665 - val_loss: 1.2785 - val_acc: 0.5496\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2278 - acc: 0.5676 - val_loss: 1.2802 - val_acc: 0.5481\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2251 - acc: 0.5663 - val_loss: 1.2795 - val_acc: 0.5498\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2218 - acc: 0.5685 - val_loss: 1.2814 - val_acc: 0.5485\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2205 - acc: 0.5686 - val_loss: 1.2746 - val_acc: 0.5493\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2210 - acc: 0.5692 - val_loss: 1.2741 - val_acc: 0.5516\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2163 - acc: 0.5694 - val_loss: 1.2748 - val_acc: 0.5533\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2174 - acc: 0.5680 - val_loss: 1.2721 - val_acc: 0.5520\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2147 - acc: 0.5718 - val_loss: 1.2737 - val_acc: 0.5551\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2140 - acc: 0.5691 - val_loss: 1.2739 - val_acc: 0.5516\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2117 - acc: 0.5721 - val_loss: 1.2712 - val_acc: 0.5527\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2102 - acc: 0.5690 - val_loss: 1.2727 - val_acc: 0.5525\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2073 - acc: 0.5727 - val_loss: 1.2692 - val_acc: 0.5535\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2062 - acc: 0.5723 - val_loss: 1.2729 - val_acc: 0.5522\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2043 - acc: 0.5738 - val_loss: 1.2720 - val_acc: 0.5539\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2042 - acc: 0.5749 - val_loss: 1.2732 - val_acc: 0.5523\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2041 - acc: 0.5739 - val_loss: 1.2731 - val_acc: 0.5509\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2019 - acc: 0.5744 - val_loss: 1.2736 - val_acc: 0.5526\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2007 - acc: 0.5747 - val_loss: 1.2687 - val_acc: 0.5536\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.1981 - acc: 0.5757 - val_loss: 1.2679 - val_acc: 0.5530\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.1986 - acc: 0.5758 - val_loss: 1.2701 - val_acc: 0.5515\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.1980 - acc: 0.5731 - val_loss: 1.2750 - val_acc: 0.5529\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.1966 - acc: 0.5770 - val_loss: 1.2717 - val_acc: 0.5544\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.1943 - acc: 0.5760 - val_loss: 1.2700 - val_acc: 0.5539\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.1919 - acc: 0.5769 - val_loss: 1.2713 - val_acc: 0.5507\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "Validation loss: 1.2712964567184448\n",
      "Validation accuracy (NORMALIZED): 0.5507\n",
      "================================================\n",
      "Split: 1\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542745329.7643616_fold[1]_fine-tunned\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 2s 52us/step - loss: 2.2216 - acc: 0.1956 - val_loss: 2.0486 - val_acc: 0.3121\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.9254 - acc: 0.3273 - val_loss: 1.6810 - val_acc: 0.4183\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.6993 - acc: 0.3918 - val_loss: 1.5632 - val_acc: 0.4483\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.6139 - acc: 0.4245 - val_loss: 1.5142 - val_acc: 0.4585\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.5681 - acc: 0.4403 - val_loss: 1.4906 - val_acc: 0.4722\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.5313 - acc: 0.4586 - val_loss: 1.4637 - val_acc: 0.4797\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.5056 - acc: 0.4661 - val_loss: 1.4445 - val_acc: 0.4865\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4864 - acc: 0.4724 - val_loss: 1.4354 - val_acc: 0.4890\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4692 - acc: 0.4811 - val_loss: 1.4214 - val_acc: 0.4940\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4569 - acc: 0.4840 - val_loss: 1.4119 - val_acc: 0.4982\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4406 - acc: 0.4919 - val_loss: 1.4021 - val_acc: 0.5017\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4315 - acc: 0.4943 - val_loss: 1.3952 - val_acc: 0.5053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4222 - acc: 0.4984 - val_loss: 1.3877 - val_acc: 0.5056\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4149 - acc: 0.4973 - val_loss: 1.3873 - val_acc: 0.5053\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4056 - acc: 0.5039 - val_loss: 1.3767 - val_acc: 0.5129\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3976 - acc: 0.5064 - val_loss: 1.3737 - val_acc: 0.5115\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3896 - acc: 0.5091 - val_loss: 1.3671 - val_acc: 0.5117\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3837 - acc: 0.5105 - val_loss: 1.3627 - val_acc: 0.5150\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3779 - acc: 0.5142 - val_loss: 1.3615 - val_acc: 0.5150\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3716 - acc: 0.5166 - val_loss: 1.3617 - val_acc: 0.5151\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3675 - acc: 0.5179 - val_loss: 1.3547 - val_acc: 0.5192\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3653 - acc: 0.5198 - val_loss: 1.3523 - val_acc: 0.5209\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3575 - acc: 0.5207 - val_loss: 1.3484 - val_acc: 0.5194\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3539 - acc: 0.5210 - val_loss: 1.3463 - val_acc: 0.5239\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3510 - acc: 0.5236 - val_loss: 1.3433 - val_acc: 0.5198\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3469 - acc: 0.5248 - val_loss: 1.3394 - val_acc: 0.5226\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3410 - acc: 0.5256 - val_loss: 1.3376 - val_acc: 0.5272\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3363 - acc: 0.5278 - val_loss: 1.3361 - val_acc: 0.5278\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3337 - acc: 0.5295 - val_loss: 1.3350 - val_acc: 0.5266\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3305 - acc: 0.5298 - val_loss: 1.3314 - val_acc: 0.5284\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3274 - acc: 0.5323 - val_loss: 1.3301 - val_acc: 0.5282\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3250 - acc: 0.5343 - val_loss: 1.3295 - val_acc: 0.5270\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3188 - acc: 0.5368 - val_loss: 1.3303 - val_acc: 0.5289\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3189 - acc: 0.5349 - val_loss: 1.3260 - val_acc: 0.5298\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3143 - acc: 0.5364 - val_loss: 1.3281 - val_acc: 0.5298\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3110 - acc: 0.5387 - val_loss: 1.3213 - val_acc: 0.5312\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3085 - acc: 0.5397 - val_loss: 1.3200 - val_acc: 0.5326\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3054 - acc: 0.5381 - val_loss: 1.3215 - val_acc: 0.5317\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3029 - acc: 0.5427 - val_loss: 1.3202 - val_acc: 0.5330\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3006 - acc: 0.5418 - val_loss: 1.3181 - val_acc: 0.5349\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2979 - acc: 0.5439 - val_loss: 1.3182 - val_acc: 0.5312\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2929 - acc: 0.5438 - val_loss: 1.3176 - val_acc: 0.5355\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2946 - acc: 0.5443 - val_loss: 1.3162 - val_acc: 0.5331\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2898 - acc: 0.5456 - val_loss: 1.3145 - val_acc: 0.5361\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2888 - acc: 0.5449 - val_loss: 1.3174 - val_acc: 0.5339\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2843 - acc: 0.5462 - val_loss: 1.3144 - val_acc: 0.5381\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2817 - acc: 0.5471 - val_loss: 1.3131 - val_acc: 0.5341\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2822 - acc: 0.5480 - val_loss: 1.3107 - val_acc: 0.5334\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2808 - acc: 0.5489 - val_loss: 1.3140 - val_acc: 0.5338\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2765 - acc: 0.5480 - val_loss: 1.3077 - val_acc: 0.5404\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2738 - acc: 0.5486 - val_loss: 1.3059 - val_acc: 0.5373\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2738 - acc: 0.5509 - val_loss: 1.3087 - val_acc: 0.5394\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2709 - acc: 0.5528 - val_loss: 1.3062 - val_acc: 0.5372\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2709 - acc: 0.5507 - val_loss: 1.3073 - val_acc: 0.5387\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2646 - acc: 0.5514 - val_loss: 1.3050 - val_acc: 0.5402\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2634 - acc: 0.5525 - val_loss: 1.3023 - val_acc: 0.5383\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2609 - acc: 0.5570 - val_loss: 1.3027 - val_acc: 0.5379\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2612 - acc: 0.5559 - val_loss: 1.3044 - val_acc: 0.5373\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2627 - acc: 0.5540 - val_loss: 1.3010 - val_acc: 0.5397\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2577 - acc: 0.5554 - val_loss: 1.3013 - val_acc: 0.5392\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2545 - acc: 0.5596 - val_loss: 1.3039 - val_acc: 0.5405\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2550 - acc: 0.5580 - val_loss: 1.2997 - val_acc: 0.5425\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2515 - acc: 0.5594 - val_loss: 1.2986 - val_acc: 0.5444\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2526 - acc: 0.5589 - val_loss: 1.3001 - val_acc: 0.5427\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2488 - acc: 0.5604 - val_loss: 1.2979 - val_acc: 0.5403\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2473 - acc: 0.5578 - val_loss: 1.2995 - val_acc: 0.5399\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2449 - acc: 0.5611 - val_loss: 1.2995 - val_acc: 0.5422\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2457 - acc: 0.5604 - val_loss: 1.2997 - val_acc: 0.5463\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2444 - acc: 0.5635 - val_loss: 1.2978 - val_acc: 0.5417\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2387 - acc: 0.5618 - val_loss: 1.3012 - val_acc: 0.5423\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2406 - acc: 0.5621 - val_loss: 1.2963 - val_acc: 0.5427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2371 - acc: 0.5644 - val_loss: 1.2998 - val_acc: 0.5415\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2363 - acc: 0.5637 - val_loss: 1.2950 - val_acc: 0.5436\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2352 - acc: 0.5613 - val_loss: 1.2964 - val_acc: 0.5455\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2326 - acc: 0.5646 - val_loss: 1.2953 - val_acc: 0.5453\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2297 - acc: 0.5650 - val_loss: 1.2926 - val_acc: 0.5437\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2308 - acc: 0.5654 - val_loss: 1.3019 - val_acc: 0.5406\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2280 - acc: 0.5664 - val_loss: 1.2967 - val_acc: 0.5436\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2290 - acc: 0.5650 - val_loss: 1.2923 - val_acc: 0.5439\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2212 - acc: 0.5689 - val_loss: 1.2920 - val_acc: 0.5451\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2227 - acc: 0.5664 - val_loss: 1.2943 - val_acc: 0.5436\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2209 - acc: 0.5702 - val_loss: 1.2950 - val_acc: 0.5483\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2195 - acc: 0.5677 - val_loss: 1.2932 - val_acc: 0.5456\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2207 - acc: 0.5664 - val_loss: 1.2950 - val_acc: 0.5430\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2166 - acc: 0.5679 - val_loss: 1.2939 - val_acc: 0.5478\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2136 - acc: 0.5715 - val_loss: 1.2910 - val_acc: 0.5466\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2151 - acc: 0.5706 - val_loss: 1.2895 - val_acc: 0.5465\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2135 - acc: 0.5711 - val_loss: 1.2917 - val_acc: 0.5474\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2123 - acc: 0.5711 - val_loss: 1.2912 - val_acc: 0.5475\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2105 - acc: 0.5722 - val_loss: 1.2909 - val_acc: 0.5482\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2091 - acc: 0.5716 - val_loss: 1.2879 - val_acc: 0.5488\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2068 - acc: 0.5720 - val_loss: 1.2915 - val_acc: 0.5486\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2055 - acc: 0.5729 - val_loss: 1.2885 - val_acc: 0.5470\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2049 - acc: 0.5730 - val_loss: 1.2919 - val_acc: 0.5454\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2046 - acc: 0.5736 - val_loss: 1.2875 - val_acc: 0.5483\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2023 - acc: 0.5739 - val_loss: 1.2934 - val_acc: 0.5474\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2025 - acc: 0.5763 - val_loss: 1.2890 - val_acc: 0.5507\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.1993 - acc: 0.5751 - val_loss: 1.2890 - val_acc: 0.5495\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.1965 - acc: 0.5769 - val_loss: 1.2903 - val_acc: 0.5485\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.1941 - acc: 0.5745 - val_loss: 1.2858 - val_acc: 0.5476\n",
      "10000/10000 [==============================] - 0s 34us/step\n",
      "Validation loss: 1.2858314598083496\n",
      "Validation accuracy (NORMALIZED): 0.5476\n",
      "================================================\n",
      "Split: 2\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542745491.2639496_fold[2]_fine-tunned\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 2s 54us/step - loss: 2.2761 - acc: 0.1625 - val_loss: 2.0615 - val_acc: 0.3044\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.9309 - acc: 0.3055 - val_loss: 1.7017 - val_acc: 0.4055\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.7357 - acc: 0.3758 - val_loss: 1.5784 - val_acc: 0.4464\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.6432 - acc: 0.4110 - val_loss: 1.5211 - val_acc: 0.4606\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.5949 - acc: 0.4272 - val_loss: 1.4847 - val_acc: 0.4705\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.5540 - acc: 0.4462 - val_loss: 1.4551 - val_acc: 0.4756\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.5260 - acc: 0.4572 - val_loss: 1.4396 - val_acc: 0.4866\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.5052 - acc: 0.4675 - val_loss: 1.4165 - val_acc: 0.4916\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4866 - acc: 0.4750 - val_loss: 1.4070 - val_acc: 0.4967\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4698 - acc: 0.4797 - val_loss: 1.3989 - val_acc: 0.5012\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4579 - acc: 0.4857 - val_loss: 1.3891 - val_acc: 0.5041\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4492 - acc: 0.4900 - val_loss: 1.3826 - val_acc: 0.5045\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4349 - acc: 0.4911 - val_loss: 1.3736 - val_acc: 0.5073\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4287 - acc: 0.4973 - val_loss: 1.3700 - val_acc: 0.5112\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4183 - acc: 0.4996 - val_loss: 1.3656 - val_acc: 0.5111\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4111 - acc: 0.5011 - val_loss: 1.3567 - val_acc: 0.5155\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4055 - acc: 0.5054 - val_loss: 1.3535 - val_acc: 0.5175\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4006 - acc: 0.5061 - val_loss: 1.3469 - val_acc: 0.5213\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3947 - acc: 0.5067 - val_loss: 1.3441 - val_acc: 0.5198\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3845 - acc: 0.5116 - val_loss: 1.3406 - val_acc: 0.5228\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3805 - acc: 0.5132 - val_loss: 1.3355 - val_acc: 0.5244\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3760 - acc: 0.5136 - val_loss: 1.3341 - val_acc: 0.5257\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3717 - acc: 0.5171 - val_loss: 1.3317 - val_acc: 0.5269\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3657 - acc: 0.5191 - val_loss: 1.3286 - val_acc: 0.5245\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3627 - acc: 0.5212 - val_loss: 1.3228 - val_acc: 0.5271\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3585 - acc: 0.5210 - val_loss: 1.3211 - val_acc: 0.5282\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3547 - acc: 0.5206 - val_loss: 1.3182 - val_acc: 0.5293\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3500 - acc: 0.5264 - val_loss: 1.3199 - val_acc: 0.5305\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.3481 - acc: 0.5253 - val_loss: 1.3192 - val_acc: 0.5303\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3433 - acc: 0.5274 - val_loss: 1.3182 - val_acc: 0.5301\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3387 - acc: 0.5287 - val_loss: 1.3152 - val_acc: 0.5321\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3369 - acc: 0.5304 - val_loss: 1.3102 - val_acc: 0.5325\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3296 - acc: 0.5327 - val_loss: 1.3065 - val_acc: 0.5338\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3287 - acc: 0.5324 - val_loss: 1.3043 - val_acc: 0.5357\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3246 - acc: 0.5335 - val_loss: 1.3070 - val_acc: 0.5351\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3249 - acc: 0.5340 - val_loss: 1.3012 - val_acc: 0.5386\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3199 - acc: 0.5355 - val_loss: 1.3022 - val_acc: 0.5370\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3187 - acc: 0.5366 - val_loss: 1.3003 - val_acc: 0.5382\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3123 - acc: 0.5375 - val_loss: 1.3035 - val_acc: 0.5366\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3115 - acc: 0.5389 - val_loss: 1.3005 - val_acc: 0.5378\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3094 - acc: 0.5394 - val_loss: 1.3003 - val_acc: 0.5380\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3078 - acc: 0.5420 - val_loss: 1.2934 - val_acc: 0.5405\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3045 - acc: 0.5392 - val_loss: 1.2956 - val_acc: 0.5371\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3045 - acc: 0.5413 - val_loss: 1.2935 - val_acc: 0.5427\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.3022 - acc: 0.5397 - val_loss: 1.2919 - val_acc: 0.5411\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2975 - acc: 0.5428 - val_loss: 1.2948 - val_acc: 0.5378\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2963 - acc: 0.5444 - val_loss: 1.2945 - val_acc: 0.5395\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2921 - acc: 0.5435 - val_loss: 1.2890 - val_acc: 0.5421\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2896 - acc: 0.5458 - val_loss: 1.2891 - val_acc: 0.5400\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2910 - acc: 0.5455 - val_loss: 1.2875 - val_acc: 0.5423\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2877 - acc: 0.5463 - val_loss: 1.2876 - val_acc: 0.5412\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2836 - acc: 0.5475 - val_loss: 1.2850 - val_acc: 0.5420\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2806 - acc: 0.5503 - val_loss: 1.2874 - val_acc: 0.5399\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2822 - acc: 0.5489 - val_loss: 1.2861 - val_acc: 0.5425\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2780 - acc: 0.5484 - val_loss: 1.2829 - val_acc: 0.5448\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2772 - acc: 0.5509 - val_loss: 1.2815 - val_acc: 0.5458\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2770 - acc: 0.5486 - val_loss: 1.2800 - val_acc: 0.5427\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2742 - acc: 0.5515 - val_loss: 1.2809 - val_acc: 0.5437\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2721 - acc: 0.5520 - val_loss: 1.2817 - val_acc: 0.5420\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2716 - acc: 0.5532 - val_loss: 1.2809 - val_acc: 0.5444\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2711 - acc: 0.5525 - val_loss: 1.2788 - val_acc: 0.5452\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2655 - acc: 0.5524 - val_loss: 1.2786 - val_acc: 0.5454\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2643 - acc: 0.5578 - val_loss: 1.2786 - val_acc: 0.5449\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2616 - acc: 0.5575 - val_loss: 1.2781 - val_acc: 0.5455\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2598 - acc: 0.5568 - val_loss: 1.2787 - val_acc: 0.5436\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2604 - acc: 0.5568 - val_loss: 1.2757 - val_acc: 0.5485\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2579 - acc: 0.5579 - val_loss: 1.2753 - val_acc: 0.5468\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2564 - acc: 0.5560 - val_loss: 1.2784 - val_acc: 0.5443\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2529 - acc: 0.5599 - val_loss: 1.2778 - val_acc: 0.5461\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2537 - acc: 0.5584 - val_loss: 1.2772 - val_acc: 0.5436\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2496 - acc: 0.5613 - val_loss: 1.2773 - val_acc: 0.5448\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2503 - acc: 0.5610 - val_loss: 1.2789 - val_acc: 0.5430\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2474 - acc: 0.5596 - val_loss: 1.2744 - val_acc: 0.5456\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2448 - acc: 0.5623 - val_loss: 1.2724 - val_acc: 0.5460\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2434 - acc: 0.5614 - val_loss: 1.2725 - val_acc: 0.5456\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2433 - acc: 0.5625 - val_loss: 1.2721 - val_acc: 0.5462\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2385 - acc: 0.5640 - val_loss: 1.2696 - val_acc: 0.5512\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2374 - acc: 0.5644 - val_loss: 1.2737 - val_acc: 0.5440\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2344 - acc: 0.5648 - val_loss: 1.2723 - val_acc: 0.5493\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2363 - acc: 0.5640 - val_loss: 1.2712 - val_acc: 0.5500\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2350 - acc: 0.5659 - val_loss: 1.2736 - val_acc: 0.5452\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2329 - acc: 0.5670 - val_loss: 1.2723 - val_acc: 0.5448\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2317 - acc: 0.5670 - val_loss: 1.2680 - val_acc: 0.5483\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2325 - acc: 0.5698 - val_loss: 1.2726 - val_acc: 0.5464\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2309 - acc: 0.5668 - val_loss: 1.2675 - val_acc: 0.5497\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2290 - acc: 0.5680 - val_loss: 1.2673 - val_acc: 0.5513\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2258 - acc: 0.5678 - val_loss: 1.2683 - val_acc: 0.5483\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2244 - acc: 0.5692 - val_loss: 1.2689 - val_acc: 0.5475\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2266 - acc: 0.5685 - val_loss: 1.2676 - val_acc: 0.5499\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2208 - acc: 0.5715 - val_loss: 1.2669 - val_acc: 0.5486\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2223 - acc: 0.5699 - val_loss: 1.2680 - val_acc: 0.5478\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2198 - acc: 0.5711 - val_loss: 1.2680 - val_acc: 0.5482\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2199 - acc: 0.5711 - val_loss: 1.2715 - val_acc: 0.5496\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2170 - acc: 0.5698 - val_loss: 1.2695 - val_acc: 0.5489\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2151 - acc: 0.5718 - val_loss: 1.2664 - val_acc: 0.5511\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2133 - acc: 0.5738 - val_loss: 1.2700 - val_acc: 0.5465\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2124 - acc: 0.5739 - val_loss: 1.2672 - val_acc: 0.5476\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2095 - acc: 0.5750 - val_loss: 1.2663 - val_acc: 0.5526\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2078 - acc: 0.5753 - val_loss: 1.2671 - val_acc: 0.5483\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2069 - acc: 0.5752 - val_loss: 1.2698 - val_acc: 0.5473\n",
      "10000/10000 [==============================] - 0s 35us/step\n",
      "Validation loss: 1.2698415264129639\n",
      "Validation accuracy (NORMALIZED): 0.5473\n",
      "================================================\n",
      "Split: 3\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542745656.8669908_fold[3]_fine-tunned\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 2s 54us/step - loss: 2.2216 - acc: 0.1919 - val_loss: 1.9944 - val_acc: 0.3156\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.8483 - acc: 0.3394 - val_loss: 1.6262 - val_acc: 0.4253\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.6705 - acc: 0.3988 - val_loss: 1.5437 - val_acc: 0.4506\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.5982 - acc: 0.4287 - val_loss: 1.5015 - val_acc: 0.4650\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.5604 - acc: 0.4452 - val_loss: 1.4726 - val_acc: 0.4795\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.5226 - acc: 0.4584 - val_loss: 1.4503 - val_acc: 0.4873\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.5054 - acc: 0.4685 - val_loss: 1.4316 - val_acc: 0.4932\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4814 - acc: 0.4733 - val_loss: 1.4190 - val_acc: 0.4972\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4667 - acc: 0.4817 - val_loss: 1.4060 - val_acc: 0.5007\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4517 - acc: 0.4884 - val_loss: 1.3952 - val_acc: 0.5031\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4398 - acc: 0.4928 - val_loss: 1.3859 - val_acc: 0.5045\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.4314 - acc: 0.4947 - val_loss: 1.3840 - val_acc: 0.5065\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4225 - acc: 0.4979 - val_loss: 1.3742 - val_acc: 0.5130\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4114 - acc: 0.5016 - val_loss: 1.3689 - val_acc: 0.5145\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4036 - acc: 0.5042 - val_loss: 1.3630 - val_acc: 0.5139\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3943 - acc: 0.5083 - val_loss: 1.3572 - val_acc: 0.5170\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3911 - acc: 0.5091 - val_loss: 1.3555 - val_acc: 0.5178\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3824 - acc: 0.5117 - val_loss: 1.3497 - val_acc: 0.5205\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3790 - acc: 0.5149 - val_loss: 1.3434 - val_acc: 0.5195\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3738 - acc: 0.5151 - val_loss: 1.3470 - val_acc: 0.5208\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3663 - acc: 0.5162 - val_loss: 1.3417 - val_acc: 0.5215\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3611 - acc: 0.5190 - val_loss: 1.3387 - val_acc: 0.5253\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3573 - acc: 0.5210 - val_loss: 1.3324 - val_acc: 0.5202\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3520 - acc: 0.5242 - val_loss: 1.3311 - val_acc: 0.5232\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3499 - acc: 0.5232 - val_loss: 1.3333 - val_acc: 0.5238\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3461 - acc: 0.5231 - val_loss: 1.3277 - val_acc: 0.5234\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3410 - acc: 0.5275 - val_loss: 1.3230 - val_acc: 0.5266\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3391 - acc: 0.5262 - val_loss: 1.3219 - val_acc: 0.5259\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3345 - acc: 0.5312 - val_loss: 1.3252 - val_acc: 0.5269\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3323 - acc: 0.5288 - val_loss: 1.3181 - val_acc: 0.5286\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3255 - acc: 0.5320 - val_loss: 1.3249 - val_acc: 0.5280\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3249 - acc: 0.5343 - val_loss: 1.3146 - val_acc: 0.5274\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3204 - acc: 0.5328 - val_loss: 1.3134 - val_acc: 0.5328\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3195 - acc: 0.5335 - val_loss: 1.3119 - val_acc: 0.5330\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3154 - acc: 0.5362 - val_loss: 1.3095 - val_acc: 0.5327\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3144 - acc: 0.5371 - val_loss: 1.3077 - val_acc: 0.5355\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3114 - acc: 0.5364 - val_loss: 1.3075 - val_acc: 0.5299\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3063 - acc: 0.5423 - val_loss: 1.3072 - val_acc: 0.5313\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.3022 - acc: 0.5417 - val_loss: 1.3049 - val_acc: 0.5343\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3004 - acc: 0.5418 - val_loss: 1.3021 - val_acc: 0.5373\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2980 - acc: 0.5421 - val_loss: 1.3037 - val_acc: 0.5357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3000 - acc: 0.5403 - val_loss: 1.2993 - val_acc: 0.5366\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2964 - acc: 0.5419 - val_loss: 1.2996 - val_acc: 0.5345\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2910 - acc: 0.5446 - val_loss: 1.2993 - val_acc: 0.5368\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2920 - acc: 0.5437 - val_loss: 1.3004 - val_acc: 0.5376\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2897 - acc: 0.5444 - val_loss: 1.2989 - val_acc: 0.5362\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2856 - acc: 0.5460 - val_loss: 1.3002 - val_acc: 0.5371\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2827 - acc: 0.5474 - val_loss: 1.2975 - val_acc: 0.5385\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2804 - acc: 0.5488 - val_loss: 1.2938 - val_acc: 0.5376\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2795 - acc: 0.5484 - val_loss: 1.2932 - val_acc: 0.5419\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2776 - acc: 0.5499 - val_loss: 1.2936 - val_acc: 0.5400\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2755 - acc: 0.5519 - val_loss: 1.2945 - val_acc: 0.5418\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2733 - acc: 0.5520 - val_loss: 1.2903 - val_acc: 0.5406\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2709 - acc: 0.5500 - val_loss: 1.2902 - val_acc: 0.5415\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2689 - acc: 0.5529 - val_loss: 1.2892 - val_acc: 0.5408\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2677 - acc: 0.5548 - val_loss: 1.2918 - val_acc: 0.5421\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2668 - acc: 0.5541 - val_loss: 1.2884 - val_acc: 0.5400\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2654 - acc: 0.5535 - val_loss: 1.2884 - val_acc: 0.5424\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2633 - acc: 0.5562 - val_loss: 1.2884 - val_acc: 0.5417\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2618 - acc: 0.5551 - val_loss: 1.2853 - val_acc: 0.5427\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2576 - acc: 0.5557 - val_loss: 1.2869 - val_acc: 0.5409\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2554 - acc: 0.5566 - val_loss: 1.2836 - val_acc: 0.5413\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2534 - acc: 0.5583 - val_loss: 1.2853 - val_acc: 0.5429\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2525 - acc: 0.5576 - val_loss: 1.2815 - val_acc: 0.5434\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2530 - acc: 0.5566 - val_loss: 1.2863 - val_acc: 0.5424\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2493 - acc: 0.5590 - val_loss: 1.2837 - val_acc: 0.5453\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2444 - acc: 0.5603 - val_loss: 1.2846 - val_acc: 0.5439\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2446 - acc: 0.5637 - val_loss: 1.2837 - val_acc: 0.5415\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2445 - acc: 0.5601 - val_loss: 1.2806 - val_acc: 0.5448\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2426 - acc: 0.5623 - val_loss: 1.2797 - val_acc: 0.5433\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2417 - acc: 0.5584 - val_loss: 1.2792 - val_acc: 0.5473\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2389 - acc: 0.5624 - val_loss: 1.2823 - val_acc: 0.5432\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2375 - acc: 0.5638 - val_loss: 1.2809 - val_acc: 0.5481\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2339 - acc: 0.5643 - val_loss: 1.2798 - val_acc: 0.5446\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2356 - acc: 0.5636 - val_loss: 1.2822 - val_acc: 0.5444\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2333 - acc: 0.5636 - val_loss: 1.2764 - val_acc: 0.5475\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2312 - acc: 0.5647 - val_loss: 1.2772 - val_acc: 0.5472\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2260 - acc: 0.5684 - val_loss: 1.2791 - val_acc: 0.5466\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2303 - acc: 0.5651 - val_loss: 1.2778 - val_acc: 0.5471\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2266 - acc: 0.5672 - val_loss: 1.2759 - val_acc: 0.5448\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2251 - acc: 0.5665 - val_loss: 1.2789 - val_acc: 0.5465\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2232 - acc: 0.5659 - val_loss: 1.2770 - val_acc: 0.5482\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2221 - acc: 0.5671 - val_loss: 1.2748 - val_acc: 0.5462\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2179 - acc: 0.5715 - val_loss: 1.2753 - val_acc: 0.5494\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2191 - acc: 0.5711 - val_loss: 1.2743 - val_acc: 0.5476\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2171 - acc: 0.5707 - val_loss: 1.2736 - val_acc: 0.5499\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2181 - acc: 0.5711 - val_loss: 1.2730 - val_acc: 0.5480\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2140 - acc: 0.5709 - val_loss: 1.2734 - val_acc: 0.5461\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2104 - acc: 0.5719 - val_loss: 1.2751 - val_acc: 0.5507\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2145 - acc: 0.5701 - val_loss: 1.2744 - val_acc: 0.5489\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2108 - acc: 0.5728 - val_loss: 1.2756 - val_acc: 0.5488\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2083 - acc: 0.5740 - val_loss: 1.2745 - val_acc: 0.5487\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2097 - acc: 0.5717 - val_loss: 1.2766 - val_acc: 0.5484\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2069 - acc: 0.5738 - val_loss: 1.2730 - val_acc: 0.5486\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2071 - acc: 0.5725 - val_loss: 1.2762 - val_acc: 0.5483\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2031 - acc: 0.5741 - val_loss: 1.2749 - val_acc: 0.5483\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.2006 - acc: 0.5746 - val_loss: 1.2724 - val_acc: 0.5467\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2014 - acc: 0.5775 - val_loss: 1.2703 - val_acc: 0.5510\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 2s 39us/step - loss: 1.1993 - acc: 0.5784 - val_loss: 1.2753 - val_acc: 0.5473\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.1955 - acc: 0.5762 - val_loss: 1.2725 - val_acc: 0.5497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 36us/step\n",
      "Validation loss: 1.272544974708557\n",
      "Validation accuracy (NORMALIZED): 0.5497\n",
      "================================================\n",
      "Split: 4\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542745821.4284937_fold[4]_fine-tunned\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 2s 56us/step - loss: 2.2545 - acc: 0.1662 - val_loss: 2.1039 - val_acc: 0.2816\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.9314 - acc: 0.3152 - val_loss: 1.6611 - val_acc: 0.4211\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.6834 - acc: 0.4022 - val_loss: 1.5517 - val_acc: 0.4524\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.6031 - acc: 0.4285 - val_loss: 1.5081 - val_acc: 0.4644\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.5611 - acc: 0.4474 - val_loss: 1.4736 - val_acc: 0.4742\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.5301 - acc: 0.4556 - val_loss: 1.4576 - val_acc: 0.4747\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.5062 - acc: 0.4676 - val_loss: 1.4374 - val_acc: 0.4859\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4831 - acc: 0.4765 - val_loss: 1.4282 - val_acc: 0.4914\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4714 - acc: 0.4804 - val_loss: 1.4113 - val_acc: 0.4949\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.4574 - acc: 0.4849 - val_loss: 1.4038 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4404 - acc: 0.4918 - val_loss: 1.3942 - val_acc: 0.5035\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4329 - acc: 0.4945 - val_loss: 1.3863 - val_acc: 0.5078\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.4194 - acc: 0.4974 - val_loss: 1.3773 - val_acc: 0.5093\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4132 - acc: 0.5002 - val_loss: 1.3735 - val_acc: 0.5132\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.4068 - acc: 0.5008 - val_loss: 1.3724 - val_acc: 0.5142\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.4006 - acc: 0.5050 - val_loss: 1.3638 - val_acc: 0.5159\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3916 - acc: 0.5092 - val_loss: 1.3631 - val_acc: 0.5166\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3835 - acc: 0.5110 - val_loss: 1.3554 - val_acc: 0.5181\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.3797 - acc: 0.5149 - val_loss: 1.3500 - val_acc: 0.5219\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3735 - acc: 0.5143 - val_loss: 1.3473 - val_acc: 0.5193\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3665 - acc: 0.5169 - val_loss: 1.3492 - val_acc: 0.5198\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3631 - acc: 0.5184 - val_loss: 1.3412 - val_acc: 0.5236\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.3599 - acc: 0.5211 - val_loss: 1.3374 - val_acc: 0.5255\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3511 - acc: 0.5224 - val_loss: 1.3366 - val_acc: 0.5239\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3506 - acc: 0.5237 - val_loss: 1.3345 - val_acc: 0.5249\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.3441 - acc: 0.5260 - val_loss: 1.3311 - val_acc: 0.5288\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3408 - acc: 0.5263 - val_loss: 1.3316 - val_acc: 0.5281\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3386 - acc: 0.5276 - val_loss: 1.3262 - val_acc: 0.5298\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.3326 - acc: 0.5289 - val_loss: 1.3242 - val_acc: 0.5296\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3310 - acc: 0.5310 - val_loss: 1.3220 - val_acc: 0.5317\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3270 - acc: 0.5336 - val_loss: 1.3217 - val_acc: 0.5296\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.3234 - acc: 0.5337 - val_loss: 1.3180 - val_acc: 0.5334\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3200 - acc: 0.5378 - val_loss: 1.3184 - val_acc: 0.5329\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3190 - acc: 0.5357 - val_loss: 1.3152 - val_acc: 0.5362\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.3144 - acc: 0.5348 - val_loss: 1.3131 - val_acc: 0.5349\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3108 - acc: 0.5382 - val_loss: 1.3142 - val_acc: 0.5367\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3110 - acc: 0.5388 - val_loss: 1.3167 - val_acc: 0.5303\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.3088 - acc: 0.5378 - val_loss: 1.3102 - val_acc: 0.5349\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3049 - acc: 0.5409 - val_loss: 1.3076 - val_acc: 0.5376\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.3035 - acc: 0.5411 - val_loss: 1.3094 - val_acc: 0.5351\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2985 - acc: 0.5437 - val_loss: 1.3053 - val_acc: 0.5374\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2971 - acc: 0.5435 - val_loss: 1.3077 - val_acc: 0.5359\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2919 - acc: 0.5425 - val_loss: 1.3043 - val_acc: 0.5362\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2928 - acc: 0.5452 - val_loss: 1.3027 - val_acc: 0.5387\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2897 - acc: 0.5448 - val_loss: 1.3042 - val_acc: 0.5368\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2862 - acc: 0.5438 - val_loss: 1.3009 - val_acc: 0.5368\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2824 - acc: 0.5458 - val_loss: 1.3000 - val_acc: 0.5367\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2822 - acc: 0.5483 - val_loss: 1.3016 - val_acc: 0.5391\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2808 - acc: 0.5471 - val_loss: 1.3025 - val_acc: 0.5384\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2762 - acc: 0.5495 - val_loss: 1.2966 - val_acc: 0.5373\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2779 - acc: 0.5499 - val_loss: 1.3008 - val_acc: 0.5373\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2736 - acc: 0.5507 - val_loss: 1.2954 - val_acc: 0.5381\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2727 - acc: 0.5516 - val_loss: 1.2952 - val_acc: 0.5393\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2696 - acc: 0.5511 - val_loss: 1.2937 - val_acc: 0.5384\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2693 - acc: 0.5524 - val_loss: 1.2981 - val_acc: 0.5404\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2651 - acc: 0.5530 - val_loss: 1.2964 - val_acc: 0.5398\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2682 - acc: 0.5508 - val_loss: 1.2966 - val_acc: 0.5393\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2625 - acc: 0.5547 - val_loss: 1.2916 - val_acc: 0.5428\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2603 - acc: 0.5549 - val_loss: 1.2955 - val_acc: 0.5376\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 2s 42us/step - loss: 1.2597 - acc: 0.5590 - val_loss: 1.2895 - val_acc: 0.5415\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2587 - acc: 0.5573 - val_loss: 1.2894 - val_acc: 0.5415\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2556 - acc: 0.5577 - val_loss: 1.2883 - val_acc: 0.5422\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2531 - acc: 0.5574 - val_loss: 1.2910 - val_acc: 0.5381\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2526 - acc: 0.5578 - val_loss: 1.2913 - val_acc: 0.5434\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2503 - acc: 0.5584 - val_loss: 1.2885 - val_acc: 0.5418\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2491 - acc: 0.5601 - val_loss: 1.2899 - val_acc: 0.5449\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2476 - acc: 0.5580 - val_loss: 1.2861 - val_acc: 0.5425\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2461 - acc: 0.5607 - val_loss: 1.2888 - val_acc: 0.5415\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2445 - acc: 0.5614 - val_loss: 1.2908 - val_acc: 0.5409\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2423 - acc: 0.5611 - val_loss: 1.2861 - val_acc: 0.5425\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2409 - acc: 0.5632 - val_loss: 1.2854 - val_acc: 0.5396\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2378 - acc: 0.5626 - val_loss: 1.2855 - val_acc: 0.5450\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2398 - acc: 0.5619 - val_loss: 1.2840 - val_acc: 0.5454\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2370 - acc: 0.5648 - val_loss: 1.2867 - val_acc: 0.5435\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2359 - acc: 0.5643 - val_loss: 1.2848 - val_acc: 0.5421\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2290 - acc: 0.5642 - val_loss: 1.2853 - val_acc: 0.5447\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2318 - acc: 0.5649 - val_loss: 1.2822 - val_acc: 0.5449\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2281 - acc: 0.5671 - val_loss: 1.2827 - val_acc: 0.5426\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2258 - acc: 0.5669 - val_loss: 1.2848 - val_acc: 0.5437\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2267 - acc: 0.5640 - val_loss: 1.2828 - val_acc: 0.5436\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2272 - acc: 0.5680 - val_loss: 1.2807 - val_acc: 0.5455\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2244 - acc: 0.5670 - val_loss: 1.2790 - val_acc: 0.5447\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2215 - acc: 0.5677 - val_loss: 1.2852 - val_acc: 0.5405\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2193 - acc: 0.5691 - val_loss: 1.2796 - val_acc: 0.5432\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2195 - acc: 0.5698 - val_loss: 1.2859 - val_acc: 0.5436\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2191 - acc: 0.5691 - val_loss: 1.2778 - val_acc: 0.5460\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2162 - acc: 0.5706 - val_loss: 1.2798 - val_acc: 0.5470\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2163 - acc: 0.5704 - val_loss: 1.2810 - val_acc: 0.5445\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2139 - acc: 0.5712 - val_loss: 1.2823 - val_acc: 0.5429\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2147 - acc: 0.5700 - val_loss: 1.2799 - val_acc: 0.5447\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2121 - acc: 0.5721 - val_loss: 1.2783 - val_acc: 0.5450\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2094 - acc: 0.5728 - val_loss: 1.2772 - val_acc: 0.5459\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2088 - acc: 0.5718 - val_loss: 1.2768 - val_acc: 0.5468\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2077 - acc: 0.5745 - val_loss: 1.2781 - val_acc: 0.5454\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2075 - acc: 0.5748 - val_loss: 1.2797 - val_acc: 0.5447\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2059 - acc: 0.5749 - val_loss: 1.2786 - val_acc: 0.5454\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2076 - acc: 0.5734 - val_loss: 1.2777 - val_acc: 0.5460\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 2s 41us/step - loss: 1.2017 - acc: 0.5771 - val_loss: 1.2772 - val_acc: 0.5444\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.2002 - acc: 0.5763 - val_loss: 1.2764 - val_acc: 0.5452\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 2s 40us/step - loss: 1.1990 - acc: 0.5761 - val_loss: 1.2761 - val_acc: 0.5471\n",
      "10000/10000 [==============================] - 0s 36us/step\n",
      "Validation loss: 1.2761274951934813\n",
      "Validation accuracy (NORMALIZED): 0.5471\n",
      "[[1.2712964567184448, 0.5507], [1.2858314598083496, 0.5476], [1.2698415264129639, 0.5473], [1.272544974708557, 0.5497], [1.2761274951934813, 0.5471]]\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Training model and Evaluation\n",
    "#=====================================\n",
    "\n",
    "y_train_categorical = to_categorical(y_train, num_classes=n_classes)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=n_classes)\n",
    "\n",
    "scores = []\n",
    "for i in range(folds):\n",
    "    #--- Loading model\n",
    "    model = get_squeezenet_ft2()    \n",
    "    \n",
    "    #--- Evaluating the model for split i\n",
    "    print(\"================================================\")\n",
    "    print(\"Split: \"+str(i))\n",
    "    print(\"Number of Epochs: \"+str(n_epochs))\n",
    "    print(\"Train shape:\",X_train[i].shape)\n",
    "    print(\"Train batch size: \"+str(train_batch_size))\n",
    "    print(\"Val batch size: \"+str(val_batch_size))\n",
    "    print(\"================================================\")\n",
    "    \n",
    "    #=====================================\n",
    "    # Tensorboard callback\n",
    "    #=====================================\n",
    "    print(\"--- Preparing tensorboard\")\n",
    "    log_dir = \"logs/{}_fold[{}]_{}\".format(time(), i, 'fine-tunned')\n",
    "    print(\"Log Dir: \", log_dir)\n",
    "    tbCallBack = TensorBoard(log_dir=log_dir, write_graph=True)    \n",
    "    \n",
    "    # Training without data augmentation\n",
    "    model.fit(X_train[i],y_train_categorical[i], batch_size=train_batch_size, \n",
    "              epochs=n_epochs, \n",
    "              validation_data=(X_val[i],y_val_categorical[i]),\n",
    "              verbose=1,\n",
    "              callbacks=[tbCallBack])\n",
    "    \n",
    "    #--- Evaluating the model for split i\n",
    "    score = model.evaluate(x=X_val[i], y=y_val_categorical[i], batch_size=val_batch_size, verbose=1)\n",
    "    scores.append(score)\n",
    "    print('Validation loss:', score[0])\n",
    "    print('Validation accuracy (NORMALIZED):', score[1])\n",
    "    \n",
    "#--- Showing scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation loss: 1.2751283825683593\n",
      "Mean Validation accuracy (NORMALIZED): 0.54848\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Evaluate on validation\n",
    "#=====================================\n",
    "\n",
    "#--- The evaluation of the model \n",
    "np_aux = np.array(scores).mean(axis=0)\n",
    "\n",
    "print('Mean Validation loss:', np_aux[0])\n",
    "print('Mean Validation accuracy (NORMALIZED):', np_aux[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "# Tensorboard\n",
    "\n",
    "Tensorboard is a visualization tool for Tensorflow. Among other things, it allows us to monitor the progress of our training, plot metrics per epochs, visualize the architecture's schematics. \n",
    "\n",
    "Just like for Early Stopping, we will use the [Tensorboard callback](https://keras.io/callbacks/#tensorboard) to log the information about our training. An example of usage, would be:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Just an example, DON'T RUN! \n",
    "### You will need to change <<LOG_DIR>>\n",
    "import keras.callbacks as callbacks\n",
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./<<LOG_DIR>>\")\n",
    "model.fit(..., callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your training progresses, Keras will log the metrics (e.g., loss, accuracy) to `<<LOG_DIR>>` (**make sure `<<LOG_DIR>>` is a valid directory)**. On your terminal, you will need to run Tensorboard, assign a port and access it via browser (just like jupyter).\n",
    "\n",
    "#### ----> MAKE SURE YOU USE A DIFFERENT PORT FOR JUPYTER AND TENSORBOARD <----\n",
    "\n",
    "### Docker\n",
    "For those using docker, open a new terminal and create a new container (using the same image) running Tensorboard:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ docker run -it -p <<port_host>>:<<port_container>>\n",
    "            --volume=<<LOG_DIR>>:<<LOG_DIR>>\n",
    "            --name=<<container_name>> <<docker_image>> \n",
    "            tensorboard --logdir=<<LOG_DIR>> --port=<<port_container>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ docker run -it -p 8887:8887\n",
    "            --volume=/your/path/ml2018/:/ml2018\n",
    "            --name=mdc_container_tensorboard mdc-keras:cpu\n",
    "            tensorboard --logdir=/ml2018/logs --port=8887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After starting Tensorboard, access it via browser on `http://localhost:<<port_container>>`.\n",
    "\n",
    "### Anaconda\n",
    "$ tensorboard --logdir=<<LOG_DIR>> --port=<<port>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After starting Tensorboard, access it via browser on `http://localhost:<<port>>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "\n",
    "# Fine-tuning all layers\n",
    "\n",
    "What if we fine-tune all layers of SqueezeNet?\n",
    "<img src=\"unfrozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Compiling model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 10)     5130        drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 10)     0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_26 (Gl (None, 10)           0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 10)           0           global_average_pooling2d_26[0][0]\n",
      "==================================================================================================\n",
      "Total params: 727,626\n",
      "Trainable params: 727,626\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_squeezenet_ft3():\n",
    "    squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "    for layer in squeezeNetModel.layers:\n",
    "        layer.trainable = True       #by default they are all trainable, but just for clarification\n",
    "\n",
    "    #=====================================\n",
    "    # Add new classification layers\n",
    "    #=====================================\n",
    "\n",
    "    #--- Removing layers until drop 9\n",
    "    squeezeNetModel.layers.pop() #Convolution2D\n",
    "    squeezeNetModel.layers.pop() #Activation ReLU\n",
    "    squeezeNetModel.layers.pop() #Global Avg Pool\n",
    "    squeezeNetModel.layers.pop() #Activation Softmax\n",
    "\n",
    "    #--- Adding classification layer for 10 classes\n",
    "    out = Convolution2D(n_classes, (1, 1), padding='valid', name='conv10')(squeezeNetModel.layers[-1].output)\n",
    "    out = Activation('relu', name='relu_conv10')(out)\n",
    "\n",
    "    out = GlobalAveragePooling2D()(out)\n",
    "    out = Activation('softmax', name='loss')(out)\n",
    "\n",
    "    #=====================================\n",
    "    # New Model\n",
    "    #=====================================\n",
    "    model = Model(squeezeNetModel.inputs, out, name='squeezenet_new')\n",
    "    opt = optimizer=optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#SGD(lr=learning_rate)\n",
    "    print(\"--- Compiling model\")\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = get_squeezenet_ft3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start training\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 0\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542745991.8031373_fold[0]_fully-trained\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 4s 106us/step - loss: 2.0651 - acc: 0.2551 - val_loss: 1.5466 - val_acc: 0.4700\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 1.4453 - acc: 0.4947 - val_loss: 1.1812 - val_acc: 0.5921\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 1.1988 - acc: 0.5890 - val_loss: 1.0725 - val_acc: 0.6271\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 1.0886 - acc: 0.6323 - val_loss: 1.0070 - val_acc: 0.6545\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 1.0088 - acc: 0.6596 - val_loss: 0.9548 - val_acc: 0.6713\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.9510 - acc: 0.6796 - val_loss: 0.9157 - val_acc: 0.6866\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.9097 - acc: 0.6957 - val_loss: 0.9144 - val_acc: 0.6903\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.8656 - acc: 0.7117 - val_loss: 0.8754 - val_acc: 0.7002\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.8355 - acc: 0.7233 - val_loss: 0.8660 - val_acc: 0.7054\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.8124 - acc: 0.7293 - val_loss: 0.8515 - val_acc: 0.7075\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.7889 - acc: 0.7376 - val_loss: 0.8328 - val_acc: 0.7162\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.7611 - acc: 0.7484 - val_loss: 0.8329 - val_acc: 0.7169\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.7404 - acc: 0.7547 - val_loss: 0.8356 - val_acc: 0.7159\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.7210 - acc: 0.7605 - val_loss: 0.8144 - val_acc: 0.7235\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.6965 - acc: 0.7689 - val_loss: 0.8025 - val_acc: 0.7274\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.6763 - acc: 0.7758 - val_loss: 0.7984 - val_acc: 0.7299\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.6659 - acc: 0.7800 - val_loss: 0.8188 - val_acc: 0.7232\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.6499 - acc: 0.7827 - val_loss: 0.7930 - val_acc: 0.7347\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.6328 - acc: 0.7886 - val_loss: 0.7840 - val_acc: 0.7371\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.6154 - acc: 0.7963 - val_loss: 0.8036 - val_acc: 0.7371\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.6043 - acc: 0.8006 - val_loss: 0.7856 - val_acc: 0.7395\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.5858 - acc: 0.8061 - val_loss: 0.7819 - val_acc: 0.7419\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.5721 - acc: 0.8107 - val_loss: 0.7858 - val_acc: 0.7388\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.5579 - acc: 0.8160 - val_loss: 0.7841 - val_acc: 0.7439\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.5501 - acc: 0.8201 - val_loss: 0.7956 - val_acc: 0.7412\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.5378 - acc: 0.8235 - val_loss: 0.7924 - val_acc: 0.7446\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.5285 - acc: 0.8258 - val_loss: 0.7925 - val_acc: 0.7454\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.5136 - acc: 0.8305 - val_loss: 0.7904 - val_acc: 0.7441\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.4978 - acc: 0.8374 - val_loss: 0.8130 - val_acc: 0.7426\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.4878 - acc: 0.8390 - val_loss: 0.7921 - val_acc: 0.7456\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.4804 - acc: 0.8412 - val_loss: 0.8044 - val_acc: 0.7478\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.4674 - acc: 0.8483 - val_loss: 0.7995 - val_acc: 0.7498\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.4567 - acc: 0.8505 - val_loss: 0.8048 - val_acc: 0.7474\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.4448 - acc: 0.8553 - val_loss: 0.8406 - val_acc: 0.7471\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.4339 - acc: 0.8589 - val_loss: 0.8239 - val_acc: 0.7517\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.4247 - acc: 0.8622 - val_loss: 0.8287 - val_acc: 0.7474\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.4163 - acc: 0.8647 - val_loss: 0.8309 - val_acc: 0.7502\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.4077 - acc: 0.8663 - val_loss: 0.8419 - val_acc: 0.7490\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.3933 - acc: 0.8729 - val_loss: 0.8581 - val_acc: 0.7495\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.3851 - acc: 0.8754 - val_loss: 0.8572 - val_acc: 0.7456\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.3763 - acc: 0.8783 - val_loss: 0.8680 - val_acc: 0.7482\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.3699 - acc: 0.8809 - val_loss: 0.8939 - val_acc: 0.7497\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.3601 - acc: 0.8842 - val_loss: 0.8743 - val_acc: 0.7502\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.3512 - acc: 0.8876 - val_loss: 0.9027 - val_acc: 0.7501\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.3387 - acc: 0.8919 - val_loss: 0.9033 - val_acc: 0.7518\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.3338 - acc: 0.8922 - val_loss: 0.9131 - val_acc: 0.7530\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.3261 - acc: 0.8952 - val_loss: 0.9363 - val_acc: 0.7506\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.3163 - acc: 0.8989 - val_loss: 0.9311 - val_acc: 0.7469\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.3074 - acc: 0.9009 - val_loss: 0.9571 - val_acc: 0.7483\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2986 - acc: 0.9048 - val_loss: 0.9568 - val_acc: 0.7529\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2863 - acc: 0.9099 - val_loss: 1.0003 - val_acc: 0.7450\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2827 - acc: 0.9109 - val_loss: 1.0107 - val_acc: 0.7470\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2759 - acc: 0.9120 - val_loss: 1.0126 - val_acc: 0.7490\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2637 - acc: 0.9170 - val_loss: 1.0243 - val_acc: 0.7482\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2589 - acc: 0.9202 - val_loss: 1.0520 - val_acc: 0.7477\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2453 - acc: 0.9238 - val_loss: 1.0654 - val_acc: 0.7455\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2422 - acc: 0.9249 - val_loss: 1.0774 - val_acc: 0.7443\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2342 - acc: 0.9274 - val_loss: 1.1065 - val_acc: 0.7451\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2276 - acc: 0.9292 - val_loss: 1.1280 - val_acc: 0.7413\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2181 - acc: 0.9332 - val_loss: 1.1263 - val_acc: 0.7472\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2208 - acc: 0.9311 - val_loss: 1.1306 - val_acc: 0.7480\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2131 - acc: 0.9343 - val_loss: 1.1661 - val_acc: 0.7434\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2061 - acc: 0.9363 - val_loss: 1.1870 - val_acc: 0.7442\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1958 - acc: 0.9407 - val_loss: 1.2066 - val_acc: 0.7434\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2008 - acc: 0.9380 - val_loss: 1.2168 - val_acc: 0.7467\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1866 - acc: 0.9431 - val_loss: 1.2828 - val_acc: 0.7411\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1812 - acc: 0.9445 - val_loss: 1.2636 - val_acc: 0.7438\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1708 - acc: 0.9482 - val_loss: 1.2823 - val_acc: 0.7413\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1698 - acc: 0.9484 - val_loss: 1.2613 - val_acc: 0.7451\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1663 - acc: 0.9497 - val_loss: 1.2803 - val_acc: 0.7441\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1604 - acc: 0.9526 - val_loss: 1.3128 - val_acc: 0.7434\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1579 - acc: 0.9522 - val_loss: 1.3089 - val_acc: 0.7479\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1487 - acc: 0.9558 - val_loss: 1.3909 - val_acc: 0.7424\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1454 - acc: 0.9563 - val_loss: 1.3944 - val_acc: 0.7422\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1447 - acc: 0.9569 - val_loss: 1.3944 - val_acc: 0.7416\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1377 - acc: 0.9601 - val_loss: 1.4007 - val_acc: 0.7396\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1340 - acc: 0.9608 - val_loss: 1.4519 - val_acc: 0.7435\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1366 - acc: 0.9597 - val_loss: 1.4500 - val_acc: 0.7419\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1261 - acc: 0.9634 - val_loss: 1.4812 - val_acc: 0.7428\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.1152 - acc: 0.9667 - val_loss: 1.4764 - val_acc: 0.7421\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1145 - acc: 0.9673 - val_loss: 1.4994 - val_acc: 0.7451\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1177 - acc: 0.9647 - val_loss: 1.5641 - val_acc: 0.7413\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1128 - acc: 0.9673 - val_loss: 1.5197 - val_acc: 0.7412\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1065 - acc: 0.9695 - val_loss: 1.5804 - val_acc: 0.7378\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1039 - acc: 0.9702 - val_loss: 1.5776 - val_acc: 0.7409\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1059 - acc: 0.9695 - val_loss: 1.5773 - val_acc: 0.7425\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 3s 72us/step - loss: 0.0977 - acc: 0.9718 - val_loss: 1.6271 - val_acc: 0.7390\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0947 - acc: 0.9730 - val_loss: 1.6584 - val_acc: 0.7378\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1021 - acc: 0.9697 - val_loss: 1.5909 - val_acc: 0.7418\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0882 - acc: 0.9749 - val_loss: 1.6672 - val_acc: 0.7371\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0911 - acc: 0.9736 - val_loss: 1.6854 - val_acc: 0.7387\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0867 - acc: 0.9753 - val_loss: 1.6630 - val_acc: 0.7388\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0834 - acc: 0.9763 - val_loss: 1.7506 - val_acc: 0.7346\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0982 - acc: 0.9714 - val_loss: 1.7082 - val_acc: 0.7401\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0810 - acc: 0.9767 - val_loss: 1.7385 - val_acc: 0.7390\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0672 - acc: 0.9821 - val_loss: 1.7849 - val_acc: 0.7408\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0696 - acc: 0.9810 - val_loss: 1.8211 - val_acc: 0.7386\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0855 - acc: 0.9761 - val_loss: 1.8317 - val_acc: 0.7344\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0697 - acc: 0.9804 - val_loss: 1.7755 - val_acc: 0.7432\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.0731 - acc: 0.9797 - val_loss: 1.8407 - val_acc: 0.7386\n",
      "10000/10000 [==============================] - 0s 38us/step\n",
      "Validation loss: 1.8406555080413818\n",
      "Validation accuracy (NORMALIZED): 0.7386\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 1\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542746292.853698_fold[1]_fully-trained\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 4s 111us/step - loss: 1.9781 - acc: 0.3035 - val_loss: 1.4781 - val_acc: 0.4999\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 1.4406 - acc: 0.5035 - val_loss: 1.2343 - val_acc: 0.5732\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 1.2425 - acc: 0.5791 - val_loss: 1.1293 - val_acc: 0.6161\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 1.1374 - acc: 0.6156 - val_loss: 1.0569 - val_acc: 0.6352\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.0597 - acc: 0.6425 - val_loss: 1.0126 - val_acc: 0.6495\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.9949 - acc: 0.6672 - val_loss: 0.9859 - val_acc: 0.6596\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 0.9493 - acc: 0.6837 - val_loss: 0.9455 - val_acc: 0.6737\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.9094 - acc: 0.6976 - val_loss: 0.9270 - val_acc: 0.6837\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 3s 82us/step - loss: 0.8784 - acc: 0.7061 - val_loss: 0.9087 - val_acc: 0.6885\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.8577 - acc: 0.7137 - val_loss: 0.8924 - val_acc: 0.6939\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 0.8200 - acc: 0.7264 - val_loss: 0.8816 - val_acc: 0.6996\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.7971 - acc: 0.7355 - val_loss: 0.8722 - val_acc: 0.7035\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 0.7777 - acc: 0.7403 - val_loss: 0.8580 - val_acc: 0.7074\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 0.7534 - acc: 0.7479 - val_loss: 0.8453 - val_acc: 0.7163\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 0.7329 - acc: 0.7571 - val_loss: 0.8441 - val_acc: 0.7160\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 0.7140 - acc: 0.7643 - val_loss: 0.8394 - val_acc: 0.7166\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.6994 - acc: 0.7686 - val_loss: 0.8319 - val_acc: 0.7242\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.6802 - acc: 0.7749 - val_loss: 0.8376 - val_acc: 0.7206\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.6703 - acc: 0.7805 - val_loss: 0.8303 - val_acc: 0.7226\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 0.6481 - acc: 0.7852 - val_loss: 0.8267 - val_acc: 0.7285\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 0.6326 - acc: 0.7901 - val_loss: 0.8143 - val_acc: 0.7306\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.6199 - acc: 0.7946 - val_loss: 0.8279 - val_acc: 0.7290\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.6066 - acc: 0.8001 - val_loss: 0.8195 - val_acc: 0.7335\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.5937 - acc: 0.8029 - val_loss: 0.8188 - val_acc: 0.7309\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.5775 - acc: 0.8091 - val_loss: 0.8212 - val_acc: 0.7316\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.5677 - acc: 0.8131 - val_loss: 0.8301 - val_acc: 0.7316\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.5575 - acc: 0.8156 - val_loss: 0.8270 - val_acc: 0.7358\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.5432 - acc: 0.8226 - val_loss: 0.8127 - val_acc: 0.7382\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 0.5313 - acc: 0.8256 - val_loss: 0.8339 - val_acc: 0.7367\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 0.5168 - acc: 0.8302 - val_loss: 0.8253 - val_acc: 0.7359\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5070 - acc: 0.8349 - val_loss: 0.8234 - val_acc: 0.7428\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.4933 - acc: 0.8380 - val_loss: 0.8334 - val_acc: 0.7395\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 0.4890 - acc: 0.8409 - val_loss: 0.8380 - val_acc: 0.7396\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.4750 - acc: 0.8442 - val_loss: 0.8308 - val_acc: 0.7413\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.4626 - acc: 0.8487 - val_loss: 0.8434 - val_acc: 0.7405\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.4535 - acc: 0.8535 - val_loss: 0.8564 - val_acc: 0.7362\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4408 - acc: 0.8559 - val_loss: 0.8583 - val_acc: 0.7383\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 0.4312 - acc: 0.8595 - val_loss: 0.8500 - val_acc: 0.7374\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 0.4287 - acc: 0.8599 - val_loss: 0.8844 - val_acc: 0.7344\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.4155 - acc: 0.8636 - val_loss: 0.8816 - val_acc: 0.7398\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4016 - acc: 0.8699 - val_loss: 0.9003 - val_acc: 0.7345\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.4013 - acc: 0.8703 - val_loss: 0.8895 - val_acc: 0.7425\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.3824 - acc: 0.8758 - val_loss: 0.9078 - val_acc: 0.7413\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3735 - acc: 0.8797 - val_loss: 0.9166 - val_acc: 0.7376\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3637 - acc: 0.8831 - val_loss: 0.9225 - val_acc: 0.7418\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3553 - acc: 0.8861 - val_loss: 0.9263 - val_acc: 0.7420\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3494 - acc: 0.8874 - val_loss: 0.9443 - val_acc: 0.7381\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.3399 - acc: 0.8906 - val_loss: 0.9621 - val_acc: 0.7383\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.3298 - acc: 0.8952 - val_loss: 0.9882 - val_acc: 0.7384\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3270 - acc: 0.8948 - val_loss: 0.9845 - val_acc: 0.7379\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 0.3151 - acc: 0.8992 - val_loss: 1.0099 - val_acc: 0.7389\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3092 - acc: 0.8997 - val_loss: 1.0138 - val_acc: 0.7391\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2984 - acc: 0.9061 - val_loss: 1.0582 - val_acc: 0.7387\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2871 - acc: 0.9107 - val_loss: 1.0410 - val_acc: 0.7411\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2830 - acc: 0.9116 - val_loss: 1.0643 - val_acc: 0.7364\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2825 - acc: 0.9101 - val_loss: 1.0505 - val_acc: 0.7423\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2659 - acc: 0.9166 - val_loss: 1.0704 - val_acc: 0.7402\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.2634 - acc: 0.9176 - val_loss: 1.0913 - val_acc: 0.7380\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.2546 - acc: 0.9202 - val_loss: 1.1326 - val_acc: 0.7313\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.2501 - acc: 0.9219 - val_loss: 1.1432 - val_acc: 0.7393\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2388 - acc: 0.9263 - val_loss: 1.1508 - val_acc: 0.7394\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2324 - acc: 0.9277 - val_loss: 1.1534 - val_acc: 0.7367\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2327 - acc: 0.9271 - val_loss: 1.1444 - val_acc: 0.7398\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2244 - acc: 0.9302 - val_loss: 1.1841 - val_acc: 0.7398\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.2146 - acc: 0.9355 - val_loss: 1.2378 - val_acc: 0.7386\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2092 - acc: 0.9364 - val_loss: 1.2386 - val_acc: 0.7354\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1981 - acc: 0.9405 - val_loss: 1.2101 - val_acc: 0.7390\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1973 - acc: 0.9397 - val_loss: 1.2553 - val_acc: 0.7381\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1918 - acc: 0.9413 - val_loss: 1.2554 - val_acc: 0.7380\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 0.1875 - acc: 0.9436 - val_loss: 1.3019 - val_acc: 0.7321\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 81us/step - loss: 0.1833 - acc: 0.9446 - val_loss: 1.2907 - val_acc: 0.7357\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1762 - acc: 0.9463 - val_loss: 1.3224 - val_acc: 0.7343\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.1763 - acc: 0.9464 - val_loss: 1.3029 - val_acc: 0.7333\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.1767 - acc: 0.9457 - val_loss: 1.3333 - val_acc: 0.7373\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.1559 - acc: 0.9543 - val_loss: 1.3881 - val_acc: 0.7333\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 0.1698 - acc: 0.9491 - val_loss: 1.4294 - val_acc: 0.7350\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 0.1562 - acc: 0.9534 - val_loss: 1.3849 - val_acc: 0.7324\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 0.1451 - acc: 0.9586 - val_loss: 1.4184 - val_acc: 0.7348\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 0.1452 - acc: 0.9572 - val_loss: 1.4583 - val_acc: 0.7344\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 0.1436 - acc: 0.9577 - val_loss: 1.4393 - val_acc: 0.7382\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.1351 - acc: 0.9611 - val_loss: 1.4599 - val_acc: 0.7326\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 0.1297 - acc: 0.9624 - val_loss: 1.5084 - val_acc: 0.7332\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.1299 - acc: 0.9620 - val_loss: 1.4906 - val_acc: 0.7328\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1233 - acc: 0.9650 - val_loss: 1.5110 - val_acc: 0.7337\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1217 - acc: 0.9648 - val_loss: 1.5414 - val_acc: 0.7352\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 0.1208 - acc: 0.9659 - val_loss: 1.5826 - val_acc: 0.7263\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.1290 - acc: 0.9628 - val_loss: 1.5610 - val_acc: 0.7346\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1117 - acc: 0.9682 - val_loss: 1.6158 - val_acc: 0.7374\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1148 - acc: 0.9663 - val_loss: 1.6548 - val_acc: 0.7331\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1094 - acc: 0.9687 - val_loss: 1.6311 - val_acc: 0.7335\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1097 - acc: 0.9689 - val_loss: 1.6613 - val_acc: 0.7360\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.1080 - acc: 0.9678 - val_loss: 1.6912 - val_acc: 0.7334\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1030 - acc: 0.9706 - val_loss: 1.6733 - val_acc: 0.7337\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0953 - acc: 0.9736 - val_loss: 1.6742 - val_acc: 0.7352\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0877 - acc: 0.9766 - val_loss: 1.6800 - val_acc: 0.7356\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1188 - acc: 0.9639 - val_loss: 1.6546 - val_acc: 0.7351\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0878 - acc: 0.9761 - val_loss: 1.7058 - val_acc: 0.7304\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0877 - acc: 0.9763 - val_loss: 1.7124 - val_acc: 0.7341\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.0875 - acc: 0.9755 - val_loss: 1.7259 - val_acc: 0.7339\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0844 - acc: 0.9772 - val_loss: 1.7573 - val_acc: 0.7333\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "Validation loss: 1.757320142364502\n",
      "Validation accuracy (NORMALIZED): 0.7333\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 2\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542746612.80099_fold[2]_fully-trained\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 4s 111us/step - loss: 2.0780 - acc: 0.2554 - val_loss: 1.5777 - val_acc: 0.4669\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.4878 - acc: 0.4876 - val_loss: 1.2062 - val_acc: 0.5890\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.2401 - acc: 0.5769 - val_loss: 1.0936 - val_acc: 0.6270\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.1335 - acc: 0.6136 - val_loss: 1.0370 - val_acc: 0.6421\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 1.0571 - acc: 0.6412 - val_loss: 0.9981 - val_acc: 0.6545\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.9961 - acc: 0.6632 - val_loss: 0.9683 - val_acc: 0.6681\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.9582 - acc: 0.6784 - val_loss: 0.9409 - val_acc: 0.6792\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.9154 - acc: 0.6918 - val_loss: 0.9083 - val_acc: 0.6892\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.8838 - acc: 0.7032 - val_loss: 0.8930 - val_acc: 0.6959\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.8565 - acc: 0.7142 - val_loss: 0.8737 - val_acc: 0.7043\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.8275 - acc: 0.7225 - val_loss: 0.8654 - val_acc: 0.7070\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.8049 - acc: 0.7311 - val_loss: 0.8512 - val_acc: 0.7125\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.7808 - acc: 0.7399 - val_loss: 0.8590 - val_acc: 0.7125\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.7585 - acc: 0.7466 - val_loss: 0.8293 - val_acc: 0.7196\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.7437 - acc: 0.7529 - val_loss: 0.8337 - val_acc: 0.7223\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.7282 - acc: 0.7572 - val_loss: 0.8306 - val_acc: 0.7258\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.7062 - acc: 0.7646 - val_loss: 0.8169 - val_acc: 0.7287\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.6915 - acc: 0.7701 - val_loss: 0.8301 - val_acc: 0.7290\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.6790 - acc: 0.7720 - val_loss: 0.8466 - val_acc: 0.7257\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.6644 - acc: 0.7784 - val_loss: 0.8067 - val_acc: 0.7342\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.6519 - acc: 0.7835 - val_loss: 0.8261 - val_acc: 0.7329\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.6343 - acc: 0.7893 - val_loss: 0.8121 - val_acc: 0.7315\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.6205 - acc: 0.7933 - val_loss: 0.8041 - val_acc: 0.7343\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.6075 - acc: 0.7980 - val_loss: 0.8072 - val_acc: 0.7328\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 0.5986 - acc: 0.8010 - val_loss: 0.8014 - val_acc: 0.7363\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.5847 - acc: 0.8060 - val_loss: 0.7992 - val_acc: 0.7418\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.5708 - acc: 0.8103 - val_loss: 0.8176 - val_acc: 0.7404\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 3s 81us/step - loss: 0.5638 - acc: 0.8141 - val_loss: 0.8190 - val_acc: 0.7361\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 0.5505 - acc: 0.8189 - val_loss: 0.8049 - val_acc: 0.7406\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.5355 - acc: 0.8240 - val_loss: 0.7995 - val_acc: 0.7431\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.5236 - acc: 0.8279 - val_loss: 0.8054 - val_acc: 0.7464\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.5198 - acc: 0.8263 - val_loss: 0.8130 - val_acc: 0.7458\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.5108 - acc: 0.8310 - val_loss: 0.8078 - val_acc: 0.7394\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4963 - acc: 0.8370 - val_loss: 0.8207 - val_acc: 0.7473\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.4841 - acc: 0.8410 - val_loss: 0.8277 - val_acc: 0.7468\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4776 - acc: 0.8428 - val_loss: 0.8323 - val_acc: 0.7438\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4658 - acc: 0.8458 - val_loss: 0.8272 - val_acc: 0.7492\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4570 - acc: 0.8495 - val_loss: 0.8287 - val_acc: 0.7505\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.4511 - acc: 0.8509 - val_loss: 0.8335 - val_acc: 0.7486\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.4401 - acc: 0.8554 - val_loss: 0.8510 - val_acc: 0.7444\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4356 - acc: 0.8562 - val_loss: 0.8492 - val_acc: 0.7510\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.4215 - acc: 0.8629 - val_loss: 0.8318 - val_acc: 0.7467\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4175 - acc: 0.8617 - val_loss: 0.8465 - val_acc: 0.7514\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4038 - acc: 0.8663 - val_loss: 0.8707 - val_acc: 0.7488\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.3967 - acc: 0.8682 - val_loss: 0.8732 - val_acc: 0.7459\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3848 - acc: 0.8742 - val_loss: 0.8956 - val_acc: 0.7514\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3832 - acc: 0.8736 - val_loss: 0.8810 - val_acc: 0.7512\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3675 - acc: 0.8809 - val_loss: 0.8884 - val_acc: 0.7502\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.3613 - acc: 0.8818 - val_loss: 0.9107 - val_acc: 0.7474\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.3550 - acc: 0.8842 - val_loss: 0.9400 - val_acc: 0.7458\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3435 - acc: 0.8871 - val_loss: 0.9365 - val_acc: 0.7497\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.3467 - acc: 0.8873 - val_loss: 0.9311 - val_acc: 0.7486\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3311 - acc: 0.8925 - val_loss: 0.9589 - val_acc: 0.7472\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3234 - acc: 0.8945 - val_loss: 0.9945 - val_acc: 0.7462\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.3175 - acc: 0.8976 - val_loss: 0.9825 - val_acc: 0.7481\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3068 - acc: 0.9010 - val_loss: 1.0144 - val_acc: 0.7489\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3024 - acc: 0.9013 - val_loss: 0.9921 - val_acc: 0.7485\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2957 - acc: 0.9036 - val_loss: 0.9985 - val_acc: 0.7504\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2872 - acc: 0.9067 - val_loss: 1.0321 - val_acc: 0.7492\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2846 - acc: 0.9078 - val_loss: 1.0413 - val_acc: 0.7508\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2733 - acc: 0.9125 - val_loss: 1.0479 - val_acc: 0.7473\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2670 - acc: 0.9153 - val_loss: 1.0587 - val_acc: 0.7450\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2595 - acc: 0.9158 - val_loss: 1.0804 - val_acc: 0.7483\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2561 - acc: 0.9166 - val_loss: 1.1124 - val_acc: 0.7448\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2485 - acc: 0.9199 - val_loss: 1.1305 - val_acc: 0.7472\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2405 - acc: 0.9223 - val_loss: 1.1572 - val_acc: 0.7406\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2381 - acc: 0.9232 - val_loss: 1.1279 - val_acc: 0.7459\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2338 - acc: 0.9250 - val_loss: 1.1573 - val_acc: 0.7445\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2233 - acc: 0.9286 - val_loss: 1.1992 - val_acc: 0.7451\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2168 - acc: 0.9312 - val_loss: 1.1826 - val_acc: 0.7453\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2155 - acc: 0.9315 - val_loss: 1.2259 - val_acc: 0.7440\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.2126 - acc: 0.9331 - val_loss: 1.1853 - val_acc: 0.7472\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2038 - acc: 0.9353 - val_loss: 1.2309 - val_acc: 0.7466\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.1970 - acc: 0.9378 - val_loss: 1.2639 - val_acc: 0.7431\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.1994 - acc: 0.9355 - val_loss: 1.2400 - val_acc: 0.7475\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1911 - acc: 0.9395 - val_loss: 1.2852 - val_acc: 0.7431\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.1823 - acc: 0.9426 - val_loss: 1.3271 - val_acc: 0.7430\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1891 - acc: 0.9391 - val_loss: 1.3161 - val_acc: 0.7464\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 3s 78us/step - loss: 0.1785 - acc: 0.9435 - val_loss: 1.3501 - val_acc: 0.7455\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 3s 80us/step - loss: 0.1685 - acc: 0.9478 - val_loss: 1.3300 - val_acc: 0.7437\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 3s 79us/step - loss: 0.1631 - acc: 0.9499 - val_loss: 1.3770 - val_acc: 0.7461\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 3s 77us/step - loss: 0.1621 - acc: 0.9499 - val_loss: 1.3622 - val_acc: 0.7471\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1501 - acc: 0.9550 - val_loss: 1.3995 - val_acc: 0.7434\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1557 - acc: 0.9524 - val_loss: 1.4212 - val_acc: 0.7448\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1433 - acc: 0.9564 - val_loss: 1.4384 - val_acc: 0.7408\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1464 - acc: 0.9555 - val_loss: 1.4268 - val_acc: 0.7410\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1438 - acc: 0.9566 - val_loss: 1.4561 - val_acc: 0.7446\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1418 - acc: 0.9569 - val_loss: 1.4938 - val_acc: 0.7431\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1327 - acc: 0.9600 - val_loss: 1.5234 - val_acc: 0.7414\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1535 - acc: 0.9526 - val_loss: 1.4606 - val_acc: 0.7436\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1277 - acc: 0.9613 - val_loss: 1.4923 - val_acc: 0.7446\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1221 - acc: 0.9648 - val_loss: 1.5508 - val_acc: 0.7461\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1165 - acc: 0.9655 - val_loss: 1.5550 - val_acc: 0.7446\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1180 - acc: 0.9651 - val_loss: 1.5769 - val_acc: 0.7416\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1216 - acc: 0.9635 - val_loss: 1.5516 - val_acc: 0.7444\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1093 - acc: 0.9681 - val_loss: 1.6001 - val_acc: 0.7395\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1073 - acc: 0.9684 - val_loss: 1.6248 - val_acc: 0.7423\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 3s 73us/step - loss: 0.1033 - acc: 0.9695 - val_loss: 1.6573 - val_acc: 0.7381\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1092 - acc: 0.9676 - val_loss: 1.6929 - val_acc: 0.7393\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1167 - acc: 0.9654 - val_loss: 1.6716 - val_acc: 0.7410\n",
      "10000/10000 [==============================] - 0s 42us/step\n",
      "Validation loss: 1.6715750986099243\n",
      "Validation accuracy (NORMALIZED): 0.741\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 3\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542746929.8244143_fold[3]_fully-trained\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 4s 109us/step - loss: 2.0695 - acc: 0.2634 - val_loss: 1.6217 - val_acc: 0.4619\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 1.4813 - acc: 0.4982 - val_loss: 1.2077 - val_acc: 0.5882\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 1.2457 - acc: 0.5812 - val_loss: 1.0986 - val_acc: 0.6239\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 1.1219 - acc: 0.6257 - val_loss: 1.0229 - val_acc: 0.6450\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 1.0527 - acc: 0.6502 - val_loss: 0.9820 - val_acc: 0.6655\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.9989 - acc: 0.6690 - val_loss: 0.9462 - val_acc: 0.6765\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.9513 - acc: 0.6848 - val_loss: 0.9188 - val_acc: 0.6860\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.9182 - acc: 0.6962 - val_loss: 0.8980 - val_acc: 0.6933\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.8825 - acc: 0.7078 - val_loss: 0.8927 - val_acc: 0.6946\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.8566 - acc: 0.7166 - val_loss: 0.8605 - val_acc: 0.7014\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.8273 - acc: 0.7275 - val_loss: 0.8548 - val_acc: 0.7057\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.7982 - acc: 0.7374 - val_loss: 0.8543 - val_acc: 0.7087\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.7808 - acc: 0.7452 - val_loss: 0.8340 - val_acc: 0.7122\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.7601 - acc: 0.7493 - val_loss: 0.8314 - val_acc: 0.7163\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.7346 - acc: 0.7595 - val_loss: 0.8209 - val_acc: 0.7195\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.7183 - acc: 0.7651 - val_loss: 0.8199 - val_acc: 0.7171\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.7017 - acc: 0.7690 - val_loss: 0.7986 - val_acc: 0.7268\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.6818 - acc: 0.7774 - val_loss: 0.8050 - val_acc: 0.7260\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.6673 - acc: 0.7813 - val_loss: 0.8011 - val_acc: 0.7275\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.6505 - acc: 0.7869 - val_loss: 0.7948 - val_acc: 0.7299\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.6341 - acc: 0.7932 - val_loss: 0.7890 - val_acc: 0.7323\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.6209 - acc: 0.7962 - val_loss: 0.7907 - val_acc: 0.7344\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.6054 - acc: 0.8026 - val_loss: 0.7923 - val_acc: 0.7354\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5934 - acc: 0.8059 - val_loss: 0.8034 - val_acc: 0.7351\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5820 - acc: 0.8109 - val_loss: 0.7958 - val_acc: 0.7410\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5670 - acc: 0.8162 - val_loss: 0.7972 - val_acc: 0.7393\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5507 - acc: 0.8202 - val_loss: 0.7988 - val_acc: 0.7371\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5474 - acc: 0.8227 - val_loss: 0.7937 - val_acc: 0.7381\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5286 - acc: 0.8276 - val_loss: 0.7916 - val_acc: 0.7412\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5174 - acc: 0.8331 - val_loss: 0.8006 - val_acc: 0.7412\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5102 - acc: 0.8338 - val_loss: 0.8055 - val_acc: 0.7435\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4954 - acc: 0.8403 - val_loss: 0.8207 - val_acc: 0.7411\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4846 - acc: 0.8430 - val_loss: 0.8111 - val_acc: 0.7465\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4737 - acc: 0.8454 - val_loss: 0.8225 - val_acc: 0.7430\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4636 - acc: 0.8509 - val_loss: 0.8098 - val_acc: 0.7461\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4470 - acc: 0.8568 - val_loss: 0.8271 - val_acc: 0.7469\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4461 - acc: 0.8569 - val_loss: 0.8329 - val_acc: 0.7443\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4298 - acc: 0.8619 - val_loss: 0.8594 - val_acc: 0.7435\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4208 - acc: 0.8669 - val_loss: 0.8449 - val_acc: 0.7446\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4124 - acc: 0.8670 - val_loss: 0.8532 - val_acc: 0.7488\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4018 - acc: 0.8715 - val_loss: 0.8611 - val_acc: 0.7494\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3993 - acc: 0.8727 - val_loss: 0.8839 - val_acc: 0.7419\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3883 - acc: 0.8755 - val_loss: 0.8698 - val_acc: 0.7472\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3776 - acc: 0.8798 - val_loss: 0.8713 - val_acc: 0.7512\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3642 - acc: 0.8839 - val_loss: 0.8862 - val_acc: 0.7508\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3534 - acc: 0.8873 - val_loss: 0.9007 - val_acc: 0.7504\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3476 - acc: 0.8898 - val_loss: 0.9361 - val_acc: 0.7468\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3341 - acc: 0.8942 - val_loss: 0.9213 - val_acc: 0.7491\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3303 - acc: 0.8967 - val_loss: 0.9489 - val_acc: 0.7494\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3208 - acc: 0.8999 - val_loss: 0.9530 - val_acc: 0.7496\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3110 - acc: 0.9038 - val_loss: 0.9564 - val_acc: 0.7503\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.3054 - acc: 0.9039 - val_loss: 0.9689 - val_acc: 0.7498\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2947 - acc: 0.9092 - val_loss: 1.0008 - val_acc: 0.7467\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2905 - acc: 0.9095 - val_loss: 0.9728 - val_acc: 0.7485\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2822 - acc: 0.9123 - val_loss: 1.0229 - val_acc: 0.7433\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2735 - acc: 0.9157 - val_loss: 1.0180 - val_acc: 0.7493\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2671 - acc: 0.9181 - val_loss: 1.0354 - val_acc: 0.7527\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2568 - acc: 0.9214 - val_loss: 1.0521 - val_acc: 0.7486\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2522 - acc: 0.9229 - val_loss: 1.0763 - val_acc: 0.7495\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2422 - acc: 0.9273 - val_loss: 1.0830 - val_acc: 0.7496\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2355 - acc: 0.9286 - val_loss: 1.1164 - val_acc: 0.7533\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.2351 - acc: 0.9285 - val_loss: 1.1040 - val_acc: 0.7477\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2254 - acc: 0.9329 - val_loss: 1.1628 - val_acc: 0.7438\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2191 - acc: 0.9333 - val_loss: 1.1498 - val_acc: 0.7479\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.2065 - acc: 0.9389 - val_loss: 1.1717 - val_acc: 0.7481\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2032 - acc: 0.9393 - val_loss: 1.1787 - val_acc: 0.7483\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.2025 - acc: 0.9398 - val_loss: 1.1979 - val_acc: 0.7503\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1953 - acc: 0.9421 - val_loss: 1.2044 - val_acc: 0.7471\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1888 - acc: 0.9439 - val_loss: 1.2247 - val_acc: 0.7488\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1832 - acc: 0.9454 - val_loss: 1.2475 - val_acc: 0.7508\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1807 - acc: 0.9463 - val_loss: 1.2734 - val_acc: 0.7504\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1705 - acc: 0.9503 - val_loss: 1.2865 - val_acc: 0.7511\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1679 - acc: 0.9518 - val_loss: 1.3097 - val_acc: 0.7469\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 3s 74us/step - loss: 0.1636 - acc: 0.9521 - val_loss: 1.3150 - val_acc: 0.7476\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1619 - acc: 0.9532 - val_loss: 1.3528 - val_acc: 0.7453\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1547 - acc: 0.9552 - val_loss: 1.3445 - val_acc: 0.7437\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1479 - acc: 0.9576 - val_loss: 1.3699 - val_acc: 0.7493\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1481 - acc: 0.9569 - val_loss: 1.3657 - val_acc: 0.7477\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1350 - acc: 0.9614 - val_loss: 1.4476 - val_acc: 0.7469\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1406 - acc: 0.9591 - val_loss: 1.4262 - val_acc: 0.7486\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1366 - acc: 0.9603 - val_loss: 1.4456 - val_acc: 0.7494\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1363 - acc: 0.9590 - val_loss: 1.4252 - val_acc: 0.7493\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1213 - acc: 0.9659 - val_loss: 1.4785 - val_acc: 0.7491\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1142 - acc: 0.9678 - val_loss: 1.5377 - val_acc: 0.7455\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1158 - acc: 0.9671 - val_loss: 1.5534 - val_acc: 0.7495\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1110 - acc: 0.9680 - val_loss: 1.5633 - val_acc: 0.7473\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1112 - acc: 0.9680 - val_loss: 1.5525 - val_acc: 0.7473\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1193 - acc: 0.9658 - val_loss: 1.5950 - val_acc: 0.7432\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1113 - acc: 0.9682 - val_loss: 1.6334 - val_acc: 0.7427\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1045 - acc: 0.9707 - val_loss: 1.5744 - val_acc: 0.7440\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1015 - acc: 0.9716 - val_loss: 1.6000 - val_acc: 0.7448\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1088 - acc: 0.9689 - val_loss: 1.6523 - val_acc: 0.7419\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0976 - acc: 0.9724 - val_loss: 1.6622 - val_acc: 0.7454\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0948 - acc: 0.9734 - val_loss: 1.6692 - val_acc: 0.7450\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0908 - acc: 0.9749 - val_loss: 1.6667 - val_acc: 0.7477\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0808 - acc: 0.9786 - val_loss: 1.7162 - val_acc: 0.7473\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0881 - acc: 0.9756 - val_loss: 1.7170 - val_acc: 0.7453\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0899 - acc: 0.9747 - val_loss: 1.7400 - val_acc: 0.7411\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0843 - acc: 0.9772 - val_loss: 1.7598 - val_acc: 0.7417\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0806 - acc: 0.9777 - val_loss: 1.7530 - val_acc: 0.7448\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "Validation loss: 1.7529984481811522\n",
      "Validation accuracy (NORMALIZED): 0.7448\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 4\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542747242.5939288_fold[4]_fully-trained\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 5s 113us/step - loss: 2.0348 - acc: 0.2672 - val_loss: 1.5443 - val_acc: 0.4708\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 1.4651 - acc: 0.4936 - val_loss: 1.2230 - val_acc: 0.5709\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 1.2567 - acc: 0.5683 - val_loss: 1.1096 - val_acc: 0.6194\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 1.1474 - acc: 0.6089 - val_loss: 1.0428 - val_acc: 0.6372\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 1.0639 - acc: 0.6404 - val_loss: 0.9911 - val_acc: 0.6596\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 1.0014 - acc: 0.6637 - val_loss: 0.9548 - val_acc: 0.6757\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.9541 - acc: 0.6803 - val_loss: 0.9210 - val_acc: 0.6853\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.9125 - acc: 0.6954 - val_loss: 0.9045 - val_acc: 0.6888\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.8822 - acc: 0.7062 - val_loss: 0.8937 - val_acc: 0.6927\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.8442 - acc: 0.7189 - val_loss: 0.8655 - val_acc: 0.7035\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.8160 - acc: 0.7281 - val_loss: 0.8537 - val_acc: 0.7099\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.7992 - acc: 0.7329 - val_loss: 0.8442 - val_acc: 0.7148\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.7712 - acc: 0.7439 - val_loss: 0.8381 - val_acc: 0.7158\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.7463 - acc: 0.7520 - val_loss: 0.8227 - val_acc: 0.7227\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.7311 - acc: 0.7575 - val_loss: 0.8256 - val_acc: 0.7219\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.7100 - acc: 0.7643 - val_loss: 0.8182 - val_acc: 0.7258\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.6926 - acc: 0.7691 - val_loss: 0.8102 - val_acc: 0.7281\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.6763 - acc: 0.7745 - val_loss: 0.8008 - val_acc: 0.7311\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.6587 - acc: 0.7803 - val_loss: 0.8027 - val_acc: 0.7316\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.6505 - acc: 0.7831 - val_loss: 0.8142 - val_acc: 0.7308\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.6367 - acc: 0.7893 - val_loss: 0.8003 - val_acc: 0.7333\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.6155 - acc: 0.7958 - val_loss: 0.8010 - val_acc: 0.7364\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.6018 - acc: 0.8008 - val_loss: 0.8028 - val_acc: 0.7386\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.5935 - acc: 0.8044 - val_loss: 0.7922 - val_acc: 0.7384\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5739 - acc: 0.8091 - val_loss: 0.7883 - val_acc: 0.7440\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.5642 - acc: 0.8120 - val_loss: 0.8065 - val_acc: 0.7397\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5521 - acc: 0.8147 - val_loss: 0.8132 - val_acc: 0.7373\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.5407 - acc: 0.8202 - val_loss: 0.7967 - val_acc: 0.7425\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.5258 - acc: 0.8254 - val_loss: 0.7896 - val_acc: 0.7470\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.5169 - acc: 0.8282 - val_loss: 0.8069 - val_acc: 0.7451\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.5036 - acc: 0.8333 - val_loss: 0.8118 - val_acc: 0.7443\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.5005 - acc: 0.8335 - val_loss: 0.8121 - val_acc: 0.7447\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4810 - acc: 0.8419 - val_loss: 0.8104 - val_acc: 0.7478\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4703 - acc: 0.8446 - val_loss: 0.8230 - val_acc: 0.7471\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4625 - acc: 0.8488 - val_loss: 0.8213 - val_acc: 0.7496\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4574 - acc: 0.8497 - val_loss: 0.8323 - val_acc: 0.7432\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4428 - acc: 0.8541 - val_loss: 0.8534 - val_acc: 0.7423\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4323 - acc: 0.8568 - val_loss: 0.8476 - val_acc: 0.7459\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.4234 - acc: 0.8604 - val_loss: 0.8879 - val_acc: 0.7414\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.4103 - acc: 0.8642 - val_loss: 0.8567 - val_acc: 0.7490\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3999 - acc: 0.8679 - val_loss: 0.8634 - val_acc: 0.7491\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3898 - acc: 0.8701 - val_loss: 0.8688 - val_acc: 0.7470\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3808 - acc: 0.8744 - val_loss: 0.8789 - val_acc: 0.7464\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3722 - acc: 0.8771 - val_loss: 0.9018 - val_acc: 0.7481\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3621 - acc: 0.8813 - val_loss: 0.9004 - val_acc: 0.7497\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3557 - acc: 0.8828 - val_loss: 0.9076 - val_acc: 0.7517\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3471 - acc: 0.8860 - val_loss: 0.9392 - val_acc: 0.7498\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3429 - acc: 0.8870 - val_loss: 0.9382 - val_acc: 0.7464\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3319 - acc: 0.8928 - val_loss: 0.9646 - val_acc: 0.7455\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3231 - acc: 0.8942 - val_loss: 0.9518 - val_acc: 0.7538\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3134 - acc: 0.8973 - val_loss: 0.9690 - val_acc: 0.7527\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.3035 - acc: 0.9012 - val_loss: 0.9843 - val_acc: 0.7507\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2973 - acc: 0.9039 - val_loss: 0.9845 - val_acc: 0.7520\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2875 - acc: 0.9077 - val_loss: 1.0071 - val_acc: 0.7551\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2833 - acc: 0.9080 - val_loss: 1.0513 - val_acc: 0.7484\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2801 - acc: 0.9082 - val_loss: 1.0378 - val_acc: 0.7477\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2627 - acc: 0.9164 - val_loss: 1.0414 - val_acc: 0.7514\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2638 - acc: 0.9158 - val_loss: 1.0718 - val_acc: 0.7501\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2691 - acc: 0.9130 - val_loss: 1.0504 - val_acc: 0.7484\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2536 - acc: 0.9185 - val_loss: 1.0882 - val_acc: 0.7477\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2437 - acc: 0.9211 - val_loss: 1.0874 - val_acc: 0.7485\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2353 - acc: 0.9253 - val_loss: 1.1130 - val_acc: 0.7501\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2287 - acc: 0.9273 - val_loss: 1.1502 - val_acc: 0.7486\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2248 - acc: 0.9285 - val_loss: 1.1861 - val_acc: 0.7471\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2145 - acc: 0.9310 - val_loss: 1.1907 - val_acc: 0.7469\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.2057 - acc: 0.9351 - val_loss: 1.2547 - val_acc: 0.7398\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.2109 - acc: 0.9317 - val_loss: 1.2096 - val_acc: 0.7456\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1981 - acc: 0.9365 - val_loss: 1.2293 - val_acc: 0.7431\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1932 - acc: 0.9392 - val_loss: 1.2681 - val_acc: 0.7427\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1878 - acc: 0.9399 - val_loss: 1.2621 - val_acc: 0.7490\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1823 - acc: 0.9429 - val_loss: 1.2746 - val_acc: 0.7456\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1807 - acc: 0.9430 - val_loss: 1.3740 - val_acc: 0.7380\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1742 - acc: 0.9452 - val_loss: 1.3172 - val_acc: 0.7422\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1690 - acc: 0.9466 - val_loss: 1.3768 - val_acc: 0.7418\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1658 - acc: 0.9475 - val_loss: 1.3605 - val_acc: 0.7446\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1565 - acc: 0.9509 - val_loss: 1.3869 - val_acc: 0.7395\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1615 - acc: 0.9480 - val_loss: 1.3770 - val_acc: 0.7413\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1509 - acc: 0.9525 - val_loss: 1.4166 - val_acc: 0.7457\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1500 - acc: 0.9530 - val_loss: 1.4377 - val_acc: 0.7401\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1450 - acc: 0.9551 - val_loss: 1.4305 - val_acc: 0.7394\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1438 - acc: 0.9559 - val_loss: 1.4807 - val_acc: 0.7378\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1420 - acc: 0.9554 - val_loss: 1.4616 - val_acc: 0.7422\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1261 - acc: 0.9612 - val_loss: 1.4843 - val_acc: 0.7403\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1440 - acc: 0.9547 - val_loss: 1.5192 - val_acc: 0.7366\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1277 - acc: 0.9604 - val_loss: 1.5349 - val_acc: 0.7395\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1187 - acc: 0.9641 - val_loss: 1.5602 - val_acc: 0.7426\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1144 - acc: 0.9649 - val_loss: 1.6404 - val_acc: 0.7374\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1186 - acc: 0.9635 - val_loss: 1.5875 - val_acc: 0.7403\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1094 - acc: 0.9668 - val_loss: 1.6543 - val_acc: 0.7353\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1128 - acc: 0.9654 - val_loss: 1.6297 - val_acc: 0.7422\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.1089 - acc: 0.9667 - val_loss: 1.6380 - val_acc: 0.7375\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1024 - acc: 0.9697 - val_loss: 1.6116 - val_acc: 0.7322\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1003 - acc: 0.9702 - val_loss: 1.6953 - val_acc: 0.7372\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0936 - acc: 0.9725 - val_loss: 1.7174 - val_acc: 0.7351\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0856 - acc: 0.9759 - val_loss: 1.7336 - val_acc: 0.7335\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0857 - acc: 0.9747 - val_loss: 1.7134 - val_acc: 0.7366\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0925 - acc: 0.9723 - val_loss: 1.7295 - val_acc: 0.7346\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.1282 - acc: 0.9601 - val_loss: 1.6894 - val_acc: 0.7328\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 3s 75us/step - loss: 0.0892 - acc: 0.9729 - val_loss: 1.6995 - val_acc: 0.7357\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 3s 76us/step - loss: 0.0810 - acc: 0.9758 - val_loss: 1.7484 - val_acc: 0.7347\n",
      "10000/10000 [==============================] - 0s 44us/step\n",
      "Validation loss: 1.7484136039733886\n",
      "Validation accuracy (NORMALIZED): 0.7347\n",
      "[[1.8406555080413818, 0.7386], [1.757320142364502, 0.7333], [1.6715750986099243, 0.741], [1.7529984481811522, 0.7448], [1.7484136039733886, 0.7347]]\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "\n",
    "\n",
    "#=====================================\n",
    "# Training model and Evaluation\n",
    "#=====================================\n",
    "print(\"--- Start training\")\n",
    "y_train_categorical = to_categorical(y_train, num_classes=n_classes)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=n_classes)\n",
    "scores = []\n",
    "\n",
    "for i in range(folds):\n",
    "    #--- Loading model\n",
    "    model = get_squeezenet_ft3()\n",
    "\n",
    "    \n",
    "    #--- Evaluating the model for split i\n",
    "    print(\"================================================\")\n",
    "    print(\"Split: \"+str(i))\n",
    "    print(\"Number of Epochs: \"+str(n_epochs))\n",
    "    print(\"Train shape:\",X_train[i].shape)\n",
    "    print(\"Train batch size: \"+str(train_batch_size))\n",
    "    print(\"Val batch size: \"+str(val_batch_size))\n",
    "    print(\"================================================\")\n",
    "          \n",
    "    #=====================================\n",
    "    # Tensorboard callback\n",
    "    #=====================================\n",
    "    print(\"--- Preparing tensorboard\")\n",
    "    log_dir = \"logs/{}_fold[{}]_{}\".format(time(), i, 'fully-trained')\n",
    "    print(\"Log Dir: \", log_dir)\n",
    "    tbCallBack = TensorBoard(log_dir=log_dir, write_graph=True)    \n",
    "    \n",
    "    # Training without data augmentation\n",
    "    model.fit(X_train[i],y_train_categorical[i], batch_size=train_batch_size, \n",
    "              epochs=n_epochs, \n",
    "              validation_data=(X_val[i],y_val_categorical[i]),\n",
    "              verbose=1,\n",
    "              callbacks=[tbCallBack])\n",
    "          \n",
    "    #--- Evaluating the model for split i\n",
    "    score = model.evaluate(x=X_val[i], y=y_val_categorical[i], batch_size=val_batch_size, verbose=1)\n",
    "    scores.append(score)\n",
    "    print('Validation loss:', score[0])\n",
    "    print('Validation accuracy (NORMALIZED):', score[1])\n",
    "    \n",
    "#--- Showing scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation loss: 1.7541925602340698\n",
      "Mean Validation accuracy (NORMALIZED): 0.73848\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Evaluate on validation\n",
    "#=====================================\n",
    "\n",
    "#--- The evaluation of the model \n",
    "np_aux = np.array(scores).mean(axis=0)\n",
    "\n",
    "print('Mean Validation loss:', np_aux[0])\n",
    "print('Mean Validation accuracy (NORMALIZED):', np_aux[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your best model on test\n",
    "# ... \n",
    "# Done with the loading model cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "Now that we are working on more complex tasks and our trainings are starting to take more time it is usually a good idea to save the trained model from time to time. [Keras has a lot of ways of saving and loading the model](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model), but in this exercise we will use the simplest of them all: `model.save()`. It saves the architecture, the weights, the choice of loss function/optimizer/metrics and even the current state of the training, so you can resume your training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The better model obtained was when retraining the whole network \n",
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a model\n",
    "Once we have our model trained, we can load it using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 211us/step\n",
      "Test loss: 1.7840327156066895\n",
      "Test accuracy (NORMALIZED): 0.7375\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "del model  # Will delete model, only to check if load_model is working\n",
    "\n",
    "y_test_categorical = to_categorical(y_test, num_classes=n_classes)\n",
    "\n",
    "# returns a compiled model identical to the previous one\n",
    "model = load_model('my_model.h5')\n",
    "\n",
    "score = model.evaluate(x=X_test, y=y_test_categorical, batch_size=val_batch_size, verbose=1)    \n",
    "# evaluate test set again... should give us the same result\n",
    "# ...\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy (NORMALIZED):', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Run\n",
    "\n",
    "* Using the whole traning \n",
    "* Adding early stop as a callback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Compiling model\n",
      "================================================\n",
      "Number of Epochs: 100\n",
      "Train shape: 47500.0\n",
      "Train batch size: 384\n",
      "Val batch size: 128\n",
      "================================================\n",
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542747580.8250608\n",
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/100\n",
      "47500/47500 [==============================] - 6s 117us/step - loss: 1.9774 - acc: 0.2813 - val_loss: 1.3808 - val_acc: 0.5240\n",
      "Epoch 2/100\n",
      "47500/47500 [==============================] - 4s 78us/step - loss: 1.3706 - acc: 0.5188 - val_loss: 1.1434 - val_acc: 0.6084\n",
      "Epoch 3/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 1.1731 - acc: 0.5941 - val_loss: 1.0357 - val_acc: 0.6436\n",
      "Epoch 4/100\n",
      "47500/47500 [==============================] - 4s 78us/step - loss: 1.0752 - acc: 0.6312 - val_loss: 0.9569 - val_acc: 0.6784\n",
      "Epoch 5/100\n",
      "47500/47500 [==============================] - 4s 78us/step - loss: 0.9991 - acc: 0.6629 - val_loss: 0.9317 - val_acc: 0.6808\n",
      "Epoch 6/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.9440 - acc: 0.6810 - val_loss: 0.8808 - val_acc: 0.6972\n",
      "Epoch 7/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.9025 - acc: 0.6958 - val_loss: 0.8396 - val_acc: 0.7108\n",
      "Epoch 8/100\n",
      "47500/47500 [==============================] - 4s 78us/step - loss: 0.8633 - acc: 0.7100 - val_loss: 0.8342 - val_acc: 0.7092\n",
      "Epoch 9/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.8310 - acc: 0.7215 - val_loss: 0.8045 - val_acc: 0.7180\n",
      "Epoch 10/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.8028 - acc: 0.7317 - val_loss: 0.7963 - val_acc: 0.7232\n",
      "Epoch 11/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.7777 - acc: 0.7409 - val_loss: 0.7930 - val_acc: 0.7232\n",
      "Epoch 12/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.7579 - acc: 0.7479 - val_loss: 0.7655 - val_acc: 0.7360\n",
      "Epoch 13/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.7323 - acc: 0.7552 - val_loss: 0.7858 - val_acc: 0.7276\n",
      "Epoch 14/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.7126 - acc: 0.7634 - val_loss: 0.7662 - val_acc: 0.7324\n",
      "Epoch 15/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.6943 - acc: 0.7703 - val_loss: 0.7438 - val_acc: 0.7444\n",
      "Epoch 16/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.6792 - acc: 0.7741 - val_loss: 0.7613 - val_acc: 0.7400\n",
      "Epoch 17/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.6645 - acc: 0.7818 - val_loss: 0.7409 - val_acc: 0.7408\n",
      "Epoch 18/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.6497 - acc: 0.7864 - val_loss: 0.7394 - val_acc: 0.7440\n",
      "Epoch 19/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.6310 - acc: 0.7920 - val_loss: 0.7387 - val_acc: 0.7496\n",
      "Epoch 20/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.6128 - acc: 0.7965 - val_loss: 0.7285 - val_acc: 0.7508\n",
      "Epoch 21/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.6002 - acc: 0.8005 - val_loss: 0.7265 - val_acc: 0.7568\n",
      "Epoch 22/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.5927 - acc: 0.8048 - val_loss: 0.7320 - val_acc: 0.7492\n",
      "Epoch 23/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.5742 - acc: 0.8113 - val_loss: 0.7299 - val_acc: 0.7568\n",
      "Epoch 24/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.5620 - acc: 0.8140 - val_loss: 0.7444 - val_acc: 0.7552\n",
      "Epoch 25/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.5515 - acc: 0.8188 - val_loss: 0.7328 - val_acc: 0.7576\n",
      "Epoch 26/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.5389 - acc: 0.8215 - val_loss: 0.7294 - val_acc: 0.7576\n",
      "Epoch 27/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.5257 - acc: 0.8254 - val_loss: 0.7450 - val_acc: 0.7576\n",
      "Epoch 28/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.5159 - acc: 0.8304 - val_loss: 0.7374 - val_acc: 0.7588\n",
      "Epoch 29/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.5063 - acc: 0.8330 - val_loss: 0.7295 - val_acc: 0.7576\n",
      "Epoch 30/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.4938 - acc: 0.8376 - val_loss: 0.7319 - val_acc: 0.7608\n",
      "Epoch 31/100\n",
      "47500/47500 [==============================] - 4s 77us/step - loss: 0.4830 - acc: 0.8411 - val_loss: 0.7565 - val_acc: 0.7516\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "model = get_squeezenet_ft3()\n",
    "    \n",
    "#--- Evaluating the model for split i\n",
    "print(\"================================================\")\n",
    "print(\"Number of Epochs: \"+str(n_epochs))\n",
    "print(\"Train shape:\",trainVal_label.shape[0] * 0.95)\n",
    "print(\"Train batch size: \"+str(train_batch_size))\n",
    "print(\"Val batch size: \"+str(val_batch_size))\n",
    "#print(\"Optimizer:\", opt)\n",
    "print(\"================================================\")\n",
    "\n",
    "y_train_categorical = to_categorical(trainVal_label, num_classes=n_classes)\n",
    "\n",
    "earlyStopcb = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, \n",
    "                                            patience=10, verbose=1, mode='auto', \n",
    "                                            baseline=None, restore_best_weights=True)\n",
    "print(\"--- Preparing tensorboard\")\n",
    "log_dir = \"logs/{}\".format(time())\n",
    "print(\"Log Dir: \", log_dir)\n",
    "tbCallBack = TensorBoard(log_dir=log_dir, write_graph=True)\n",
    "\n",
    "\n",
    "#--- Training without data augmentation\n",
    "model.fit(trainVal_data,y_train_categorical, batch_size=train_batch_size,\n",
    "          epochs=n_epochs, \n",
    "          validation_split=0.05,\n",
    "          verbose=1,\n",
    "          callbacks=[tbCallBack, earlyStopcb])\n",
    "\n",
    "\n",
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 258us/step\n",
      "Test loss: 0.7755689340591431\n",
      "Test accuracy (NORMALIZED): 0.7445\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "del model  # Will delete model, only to check if load_model is working\n",
    "\n",
    "y_test_categorical = to_categorical(y_test, num_classes=n_classes)\n",
    "\n",
    "# returns a compiled model identical to the previous one\n",
    "model = load_model('my_model.h5')\n",
    "\n",
    "score = model.evaluate(x=X_test, y=y_test_categorical, batch_size=val_batch_size, verbose=1)    \n",
    "# evaluate test set again... should give us the same result\n",
    "# ...\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy (NORMALIZED):', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
