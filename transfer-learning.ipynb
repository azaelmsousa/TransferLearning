{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorflow version: 1.12.0-rc0\n",
    "scikit-learn version: 0.17\n",
    "keras version: 2.2.4\n",
    "tensorboard version: 1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "In this assignment, we will use the weights of a network pre-trained in a particular problem as starting point to train our CNN to a different problem. As training a network from scratch is time-consuming and demands a lot of data, this is a frequent strategy, specially if both datasets (the one used for pre-training and the target) shares similar structures/elements/concepts. \n",
    "\n",
    "This is specially true when working with images. Most filters learned in initial convolutional layers will detect low-level elements, such as borders, corners and color blobs, which are common to most problems in the image domain. \n",
    "\n",
    "In this notebook, we will load the SqueezeNet architecture trained in the ImageNet dataset and fine-tune it to CIFAR-10.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.5/dist-packages (2.2.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (3.13)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.11.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.0.6)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (2.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras==2.2.4) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.20.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "if (sklearn.__version__ == '0.20.0'):\n",
    "    from sklearn.model_selection import StratifiedShuffleSplit\n",
    "else:\n",
    "    from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "#======================================\n",
    "# Global definitions\n",
    "#======================================\n",
    "n_epochs         = 100\n",
    "learning_rate    = 1e-4\n",
    "n_classes        = 10\n",
    "train_batch_size = 32\n",
    "val_batch_size   = 10\n",
    "    \n",
    "#Utility to plot\n",
    "def plotImages(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "        \n",
    "        \n",
    "def plotImage(img):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.imshow(np.uint8(img), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SqueezeNet definition\n",
    "These methods define our architecture and load the weights obtained using ImageNet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Module Definition\n",
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "#SqueezeNet model definition\n",
    "def SqueezeNet(input_shape):\n",
    "    img_input = Input(shape=input_shape) #placeholder\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(1000, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    # Download and load ImageNet weights\n",
    "    model.load_weights('./squeezenet_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The class are **airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val data. X:  (50000, 32, 32, 3) , Y:  (50000, 1)\n",
      "Test data. X:  (10000, 32, 32, 3) , Y:  (10000, 1)\n",
      "--- Splitting data into train and val\n",
      "Train data. X: (5, 40000, 32, 32, 3) Y: (5, 40000, 1)\n",
      "Val data. X: (5, 10000, 32, 32, 3) Y: (5, 10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "(trainVal_data, trainVal_label), (X_test, y_test) = cifar10.load_data()\n",
    "print(\"Train/Val data. X: \", trainVal_data.shape, \", Y: \", trainVal_label.shape)\n",
    "print(\"Test data. X: \", X_test.shape, \", Y: \", y_test.shape)\n",
    "\n",
    "#=====================================\n",
    "# Prepare the data\n",
    "#=====================================\n",
    "\n",
    "#--- Dividing the data into training and validation\n",
    "folds = 5\n",
    "if (sklearn.__version__ == '0.20.0'):\n",
    "    sss = StratifiedShuffleSplit(folds, test_size=0.2, random_state=42)\n",
    "    sss = sss.split(trainVal_data,trainVal_label)\n",
    "else:\n",
    "    sss = StratifiedShuffleSplit(trainVal_label, folds, test_size=0.2, random_state=42)\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "for train_index, val_index in sss:\n",
    "    X_train.append(trainVal_data[train_index])\n",
    "    X_val.append(trainVal_data[val_index])\n",
    "    y_train.append(trainVal_label[train_index])\n",
    "    y_val.append(trainVal_label[val_index])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "    \n",
    "print(\"--- Splitting data into train and val\")\n",
    "print(\"Train data. X:\",X_train.shape,\"Y:\",y_train.shape)\n",
    "print(\"Val data. X:\",X_val.shape,\"Y:\",y_val.shape)\n",
    "\n",
    "#--- Data augmentation\n",
    "aug = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True,\n",
    "                         rotation_range=20, \n",
    "                         width_shift_range=0.2, height_shift_range=0.2, \n",
    "                         horizontal_flip=True, vertical_flip=True, \n",
    "                         fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000 4000 4000 4000 4000 4000 4000 4000 4000 4000]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cheking if the splits are balanced\n",
    "for i in range(folds):\n",
    "    hist = np.histogram(np.squeeze(y_train[i]))[0]\n",
    "    print(hist)    \n",
    "    plt.bar(hist,np.amax(hist),alpha=0.5)\n",
    "    plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## SqueezeNet with frozen layers\n",
    "Our initial attempt will be to remove SqueezeNet's top layers --- responsible for the classification into ImageNet classes --- and train a new set of layers to our CIFAR-10 classes. We will also freeze the layers before `drop9`. Our architecture will be like this:\n",
    "\n",
    "<img src=\"frozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 1000)   513000      drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 1000)   0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1000)         0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 1000)         0           global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,235,496\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,235,496\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 0\n",
      "Non-trainable params: 722,496\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 10)     5130        drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 10)     0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 10)           0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 10)           0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 727,626\n",
      "Trainable params: 5,130\n",
      "Non-trainable params: 722,496\n",
      "__________________________________________________________________________________________________\n",
      "<keras.engine.input_layer.InputLayer object at 0x7f7a7553b8d0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a75517400> False\n",
      "<keras.layers.core.Activation object at 0x7f7a75517a90> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f7a75517128> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a754d2400> False\n",
      "<keras.layers.core.Activation object at 0x7f7a754f8b70> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a754f8f28> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a74c979e8> False\n",
      "<keras.layers.core.Activation object at 0x7f7a74c97a20> False\n",
      "<keras.layers.core.Activation object at 0x7f7a74cb0f60> False\n",
      "<keras.layers.merge.Concatenate object at 0x7f7a74c4c470> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a754d2048> False\n",
      "<keras.layers.core.Activation object at 0x7f7a74c6dda0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a74c6d588> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a74c0b9e8> False\n",
      "<keras.layers.core.Activation object at 0x7f7a74c0ba20> False\n",
      "<keras.layers.core.Activation object at 0x7f7a74c23f60> False\n",
      "<keras.layers.merge.Concatenate object at 0x7f7a74c3e470> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f7a74c4c7f0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a74c3e668> False\n",
      "<keras.layers.core.Activation object at 0x7f7a74bde898> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a74bdef28> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a74b91c18> False\n",
      "<keras.layers.core.Activation object at 0x7f7a74bfdc88> False\n",
      "<keras.layers.core.Activation object at 0x7f7a74bb14a8> False\n",
      "<keras.layers.merge.Concatenate object at 0x7f7a74bb16d8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a74c3e0f0> False\n",
      "<keras.layers.core.Activation object at 0x7f7a74b4dcc0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a74b4dac8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a74b05be0> False\n",
      "<keras.layers.core.Activation object at 0x7f7a74b6dcc0> False\n",
      "<keras.layers.core.Activation object at 0x7f7a74b23470> False\n",
      "<keras.layers.merge.Concatenate object at 0x7f7a74b236a0> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x7f7a74bb1710> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a74b237b8> False\n",
      "<keras.layers.core.Activation object at 0x7f7b38d1f588> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a8f527630> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a7552eb38> False\n",
      "<keras.layers.core.Activation object at 0x7f7a7552e7b8> False\n",
      "<keras.layers.core.Activation object at 0x7f7a7551e5c0> False\n",
      "<keras.layers.merge.Concatenate object at 0x7f7a7553b320> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a74b23a90> False\n",
      "<keras.layers.core.Activation object at 0x7f7a75524fd0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a75524080> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a7550cb38> False\n",
      "<keras.layers.core.Activation object at 0x7f7a75529c18> False\n",
      "<keras.layers.core.Activation object at 0x7f7a754c78d0> False\n",
      "<keras.layers.merge.Concatenate object at 0x7f7a755326d8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a7551ea90> False\n",
      "<keras.layers.core.Activation object at 0x7f7a755129e8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a75512898> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a7556f940> False\n",
      "<keras.layers.core.Activation object at 0x7f7a7557bcc0> False\n",
      "<keras.layers.core.Activation object at 0x7f7a7554a0f0> False\n",
      "<keras.layers.merge.Concatenate object at 0x7f7a7554a588> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a754c7cf8> False\n",
      "<keras.layers.core.Activation object at 0x7f7a75564080> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a75544a20> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a7555a6a0> False\n",
      "<keras.layers.core.Activation object at 0x7f7a7555aa90> False\n",
      "<keras.layers.core.Activation object at 0x7f7a755a5f98> False\n",
      "<keras.layers.merge.Concatenate object at 0x7f7a755a5a90> False\n",
      "<keras.layers.core.Dropout object at 0x7f7a7554a438> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x7f7a755f7438> True\n",
      "<keras.layers.core.Activation object at 0x7f7b08029cc0> True\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x7f7b08029710> True\n",
      "<keras.layers.core.Activation object at 0x7f7a78e4d7b8> True\n"
     ]
    }
   ],
   "source": [
    "def get_squeezenet_ft():\n",
    "    #=====================================\n",
    "    # Freezing layers\n",
    "    #=====================================\n",
    "\n",
    "    squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "    #freeze layers\n",
    "    for layer in squeezeNetModel.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    #=====================================\n",
    "    # Add new classification layers\n",
    "    #=====================================\n",
    "\n",
    "    #--- Removing layers until drop 9\n",
    "    squeezeNetModel.summary()\n",
    "    squeezeNetModel.layers.pop() #Convolution2D\n",
    "    squeezeNetModel.layers.pop() #Activation ReLU\n",
    "    squeezeNetModel.layers.pop() #Global Avg Pool\n",
    "    squeezeNetModel.layers.pop() #Activation Softmax\n",
    "    squeezeNetModel.summary()\n",
    "\n",
    "    #--- Adding classification layer for 10 classes\n",
    "    out = Convolution2D(n_classes, (1, 1), padding='valid', name='conv10')(squeezeNetModel.layers[-1].output)\n",
    "    out = Activation('relu', name='relu_conv10')(out)\n",
    "\n",
    "    out = GlobalAveragePooling2D()(out)\n",
    "    out = Activation('softmax', name='loss')(out)\n",
    "\n",
    "    #=====================================\n",
    "    # New Model\n",
    "    #=====================================\n",
    "    model = Model(squeezeNetModel.inputs, out, name='squeezenet_new')\n",
    "    #=====================================\n",
    "    # Compile model\n",
    "    #=====================================\n",
    "\n",
    "    #--- Compile the model\n",
    "    # It means to configure the model for training.\n",
    "    # Other types of optimizer:\n",
    "    #    optimizers.Adam(lr=learning_rate)\n",
    "    opt = optimizer=optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#SGD(lr=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model \n",
    "model  = get_squeezenet_ft()\n",
    "model.summary()\n",
    "\n",
    "#--- Check the trainable status of the individual layers\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 1000)   513000      drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 1000)   0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_3 (Glo (None, 1000)         0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 1000)         0           global_average_pooling2d_3[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,235,496\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,235,496\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 0\n",
      "Non-trainable params: 722,496\n",
      "__________________________________________________________________________________________________\n",
      "================================================\n",
      "Split: 0\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 7s 169us/step - loss: 5.3216 - acc: 0.1115 - val_loss: 2.3109 - val_acc: 0.1052\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 5s 136us/step - loss: 2.5055 - acc: 0.1102 - val_loss: 2.3030 - val_acc: 0.0998\n",
      "10000/10000 [==============================] - 3s 254us/step\n",
      "Validation loss: 2.3030051221847536\n",
      "Validation accuracy (NORMALIZED): 0.09980000189691782\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 1000)   513000      drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 1000)   0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 1000)         0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 1000)         0           global_average_pooling2d_5[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,235,496\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,235,496\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 0\n",
      "Non-trainable params: 722,496\n",
      "__________________________________________________________________________________________________\n",
      "================================================\n",
      "Split: 1\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 5.4345 - acc: 0.1151 - val_loss: 2.3104 - val_acc: 0.1026\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 2.4704 - acc: 0.1119 - val_loss: 2.3023 - val_acc: 0.1000\n",
      "10000/10000 [==============================] - 3s 260us/step\n",
      "Validation loss: 2.30229803609848\n",
      "Validation accuracy (NORMALIZED): 0.1000000019222498\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 1000)   513000      drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 1000)   0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 1000)         0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 1000)         0           global_average_pooling2d_7[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,235,496\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,235,496\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 0\n",
      "Non-trainable params: 722,496\n",
      "__________________________________________________________________________________________________\n",
      "================================================\n",
      "Split: 2\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 6s 159us/step - loss: 5.2147 - acc: 0.1055 - val_loss: 2.3000 - val_acc: 0.1006\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 6s 143us/step - loss: 2.4726 - acc: 0.1072 - val_loss: 2.3020 - val_acc: 0.1003\n",
      "10000/10000 [==============================] - 2s 243us/step\n",
      "Validation loss: 2.302048394441605\n",
      "Validation accuracy (NORMALIZED): 0.10030000187456607\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 1000)   513000      drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 1000)   0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 1000)         0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 1000)         0           global_average_pooling2d_9[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,235,496\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,235,496\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 0\n",
      "Non-trainable params: 722,496\n",
      "__________________________________________________________________________________________________\n",
      "================================================\n",
      "Split: 3\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 7s 183us/step - loss: 5.2060 - acc: 0.1091 - val_loss: 2.3047 - val_acc: 0.1048\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 2.5312 - acc: 0.1075 - val_loss: 2.3024 - val_acc: 0.1006\n",
      "10000/10000 [==============================] - 2s 242us/step\n",
      "Validation loss: 2.3024360327720643\n",
      "Validation accuracy (NORMALIZED): 0.10060000187158584\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 1, 1, 1000)   513000      drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv10 (Activation)        (None, 1, 1, 1000)   0           conv10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_11 (Gl (None, 1000)         0           relu_conv10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "loss (Activation)               (None, 1000)         0           global_average_pooling2d_11[0][0]\n",
      "==================================================================================================\n",
      "Total params: 1,235,496\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,235,496\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 0\n",
      "Non-trainable params: 722,496\n",
      "__________________________________________________________________________________________________\n",
      "================================================\n",
      "Split: 4\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "40000/40000 [==============================] - 7s 167us/step - loss: 5.5148 - acc: 0.1212 - val_loss: 2.3038 - val_acc: 0.1028\n",
      "Epoch 2/2\n",
      "40000/40000 [==============================] - 6s 147us/step - loss: 2.4861 - acc: 0.1090 - val_loss: 2.3025 - val_acc: 0.1001\n",
      "10000/10000 [==============================] - 3s 256us/step\n",
      "Validation loss: 2.3025289046764374\n",
      "Validation accuracy (NORMALIZED): 0.10010000187158584\n",
      "[[2.3030051221847536, 0.09980000189691782], [2.30229803609848, 0.1000000019222498], [2.302048394441605, 0.10030000187456607], [2.3024360327720643, 0.10060000187158584], [2.3025289046764374, 0.10010000187158584]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#=====================================\n",
    "# Training model and Evaluation\n",
    "#=====================================\n",
    "\n",
    "y_train_categorical = to_categorical(y_train, num_classes=n_classes)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=n_classes)\n",
    "\n",
    "scores = []\n",
    "#model.save_weights(\"temp.h5\")\n",
    "for i in range(folds):\n",
    "    model  = get_squeezenet_ft()\n",
    "    #--- Evaluating the model for split i\n",
    "    print(\"================================================\")\n",
    "    print(\"Split: \"+str(i))\n",
    "    print(\"Number of Epochs: \"+str(n_epochs))\n",
    "    print(\"Train shape:\",X_train[i].shape)\n",
    "    print(\"Train batch size: \"+str(train_batch_size))\n",
    "    print(\"Val batch size: \"+str(val_batch_size))\n",
    "    #print(\"Optimizer:\",opt)\n",
    "    print(\"================================================\")\n",
    "    # Training with data augmentation\n",
    "    '''\n",
    "    aug.fit(X_train[i])\n",
    "    model.fit_generator(aug.flow(X_train[i],y_train_categorical[i], batch_size=train_batch_size),\n",
    "                        steps_per_epoch=X_train.shape[1]//train_batch_size,\n",
    "                        epochs=n_epochs, \n",
    "                        verbose=1)\n",
    "    '''\n",
    "    # Training without data augmentation\n",
    "    model.fit(X_train[i],y_train_categorical[i], batch_size=train_batch_size,\n",
    "              epochs=2, \n",
    "              validation_data=(X_val[i],y_val_categorical[i]),\n",
    "              verbose=1)\n",
    "    #--- Evaluating the model for split i\n",
    "    score = score = model.evaluate(x=X_val[i], y=y_val_categorical[i], batch_size=val_batch_size, verbose=1)\n",
    "    scores.append(score)\n",
    "    print('Validation loss:', score[0])\n",
    "    print('Validation accuracy (NORMALIZED):', score[1])\n",
    "    model.load_weights(\"temp.h5\") #avoid overfitting\n",
    "    \n",
    "#--- Showing scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation loss: 2.302463298034668\n",
      "Mean Validation accuracy (NORMALIZED): 0.10016000188738108\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Evaluate on validation\n",
    "#=====================================\n",
    "\n",
    "#--- The evaluation of the model \n",
    "np_aux = np.array(scores).mean(axis=0)\n",
    "\n",
    "print('Mean Validation loss:', np_aux[0])\n",
    "print('Mean Validation accuracy (NORMALIZED):', np_aux[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "-----------------\n",
    "\n",
    "# Training last 2 Fire Modules + classification layers\n",
    "As we could see, the frozen network performed very poorly. By freezing most layers, we do not allow SqueezeNet to adapt its weights to features present in CIFAR-10.\n",
    "\n",
    "Let's try to unfreeze the last two fire modules and train once more. The architecture will be:\n",
    "<img src=\"partFrozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_squeezenet_ft2():\n",
    "    squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "    #print([layer.name for layer in squeezeNetModel.layers])\n",
    "    #print(squeezeNetModel.layers[-19].name)\n",
    "    #print(len(squeezeNetModel.layers))\n",
    "\n",
    "    #=====================================\n",
    "    # Freezing mentioned layers\n",
    "    #=====================================\n",
    "\n",
    "    trainable_layer_index = 19\n",
    "    for i in range(len(squeezeNetModel.layers)-trainable_layer_index):\n",
    "        squeezeNetModel.layers[i].trainable = False\n",
    "\n",
    "    #--- Check the trainable status of the individual layers\n",
    "    for layer in squeezeNetModel.layers:\n",
    "        print(layer.name, \" ----- \", layer.trainable)\n",
    "\n",
    "    #=====================================\n",
    "    # Add new classification layers\n",
    "    #=====================================\n",
    "\n",
    "    #--- Removing layers until drop 9\n",
    "    squeezeNetModel.layers.pop() #Convolution2D\n",
    "    squeezeNetModel.layers.pop() #Activation ReLU\n",
    "    squeezeNetModel.layers.pop() #Global Avg Pool\n",
    "    squeezeNetModel.layers.pop() #Activation Softmax\n",
    "    squeezeNetModel.summary()\n",
    "\n",
    "    #--- Adding classification layer for 10 classes\n",
    "    out = Convolution2D(n_classes, (1, 1), padding='valid', name='conv10')(squeezeNetModel.layers[-1].output)\n",
    "    out = Activation('relu', name='relu_conv10')(out)\n",
    "\n",
    "    out = GlobalAveragePooling2D()(out)\n",
    "    out = Activation('softmax', name='loss')(out)\n",
    "\n",
    "    #=====================================\n",
    "    # New Model\n",
    "    #=====================================\n",
    "    model = Model(squeezeNetModel.inputs, out, name='squeezenet_new')\n",
    "    opt = optimizer=optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#SGD(lr=learning_rate)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_7  -----  False\n",
      "conv1  -----  False\n",
      "relu_conv1  -----  False\n",
      "pool1  -----  False\n",
      "fire2/squeeze1x1  -----  False\n",
      "fire2/relu_squeeze1x1  -----  False\n",
      "fire2/expand1x1  -----  False\n",
      "fire2/expand3x3  -----  False\n",
      "fire2/relu_expand1x1  -----  False\n",
      "fire2/relu_expand3x3  -----  False\n",
      "fire2/concat  -----  False\n",
      "fire3/squeeze1x1  -----  False\n",
      "fire3/relu_squeeze1x1  -----  False\n",
      "fire3/expand1x1  -----  False\n",
      "fire3/expand3x3  -----  False\n",
      "fire3/relu_expand1x1  -----  False\n",
      "fire3/relu_expand3x3  -----  False\n",
      "fire3/concat  -----  False\n",
      "pool3  -----  False\n",
      "fire4/squeeze1x1  -----  False\n",
      "fire4/relu_squeeze1x1  -----  False\n",
      "fire4/expand1x1  -----  False\n",
      "fire4/expand3x3  -----  False\n",
      "fire4/relu_expand1x1  -----  False\n",
      "fire4/relu_expand3x3  -----  False\n",
      "fire4/concat  -----  False\n",
      "fire5/squeeze1x1  -----  False\n",
      "fire5/relu_squeeze1x1  -----  False\n",
      "fire5/expand1x1  -----  False\n",
      "fire5/expand3x3  -----  False\n",
      "fire5/relu_expand1x1  -----  False\n",
      "fire5/relu_expand3x3  -----  False\n",
      "fire5/concat  -----  False\n",
      "pool5  -----  False\n",
      "fire6/squeeze1x1  -----  False\n",
      "fire6/relu_squeeze1x1  -----  False\n",
      "fire6/expand1x1  -----  False\n",
      "fire6/expand3x3  -----  False\n",
      "fire6/relu_expand1x1  -----  False\n",
      "fire6/relu_expand3x3  -----  False\n",
      "fire6/concat  -----  False\n",
      "fire7/squeeze1x1  -----  False\n",
      "fire7/relu_squeeze1x1  -----  False\n",
      "fire7/expand1x1  -----  False\n",
      "fire7/expand3x3  -----  False\n",
      "fire7/relu_expand1x1  -----  False\n",
      "fire7/relu_expand3x3  -----  False\n",
      "fire7/concat  -----  False\n",
      "fire8/squeeze1x1  -----  True\n",
      "fire8/relu_squeeze1x1  -----  True\n",
      "fire8/expand1x1  -----  True\n",
      "fire8/expand3x3  -----  True\n",
      "fire8/relu_expand1x1  -----  True\n",
      "fire8/relu_expand3x3  -----  True\n",
      "fire8/concat  -----  True\n",
      "fire9/squeeze1x1  -----  True\n",
      "fire9/relu_squeeze1x1  -----  True\n",
      "fire9/expand1x1  -----  True\n",
      "fire9/expand3x3  -----  True\n",
      "fire9/relu_expand1x1  -----  True\n",
      "fire9/relu_expand3x3  -----  True\n",
      "fire9/concat  -----  True\n",
      "drop9  -----  True\n",
      "conv10  -----  True\n",
      "relu_conv10  -----  True\n",
      "global_average_pooling2d_13  -----  True\n",
      "loss  -----  True\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 386,176\n",
      "Non-trainable params: 336,320\n",
      "__________________________________________________________________________________________________\n",
      "================================================\n",
      "Split: 0\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 10s 255us/step - loss: 2.3896 - acc: 0.1617 - val_loss: 2.0943 - val_acc: 0.2752\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 2.0876 - acc: 0.2591 - val_loss: 1.8886 - val_acc: 0.3684\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.9912 - acc: 0.3029 - val_loss: 1.8142 - val_acc: 0.3954\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.8916 - acc: 0.3285 - val_loss: 1.6819 - val_acc: 0.4226\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 1.8144 - acc: 0.3489 - val_loss: 1.6103 - val_acc: 0.4471\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.7710 - acc: 0.3620 - val_loss: 1.6026 - val_acc: 0.4442\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.7299 - acc: 0.3862 - val_loss: 1.5669 - val_acc: 0.4578\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.6985 - acc: 0.3970 - val_loss: 1.5524 - val_acc: 0.4643\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.6715 - acc: 0.4108 - val_loss: 1.5340 - val_acc: 0.4733\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.6431 - acc: 0.4237 - val_loss: 1.5163 - val_acc: 0.4781\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.6136 - acc: 0.4393 - val_loss: 1.4947 - val_acc: 0.4845\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.5877 - acc: 0.4510 - val_loss: 1.4873 - val_acc: 0.4853\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.5631 - acc: 0.4587 - val_loss: 1.4729 - val_acc: 0.4890\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.5453 - acc: 0.4657 - val_loss: 1.4653 - val_acc: 0.4952\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.5235 - acc: 0.4741 - val_loss: 1.4563 - val_acc: 0.4975\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.5075 - acc: 0.4798 - val_loss: 1.4545 - val_acc: 0.5011\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.4863 - acc: 0.4864 - val_loss: 1.4319 - val_acc: 0.5032\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.4630 - acc: 0.4958 - val_loss: 1.4402 - val_acc: 0.5058\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.4487 - acc: 0.4988 - val_loss: 1.4221 - val_acc: 0.5076\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.4367 - acc: 0.5055 - val_loss: 1.4236 - val_acc: 0.5033\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.4197 - acc: 0.5096 - val_loss: 1.4198 - val_acc: 0.5091\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.4105 - acc: 0.5095 - val_loss: 1.4070 - val_acc: 0.5118\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 1.3977 - acc: 0.5161 - val_loss: 1.4117 - val_acc: 0.5071\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.3873 - acc: 0.5209 - val_loss: 1.4167 - val_acc: 0.5065\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.3746 - acc: 0.5231 - val_loss: 1.4143 - val_acc: 0.5101\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.3633 - acc: 0.5278 - val_loss: 1.4106 - val_acc: 0.5085\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.3508 - acc: 0.5291 - val_loss: 1.4040 - val_acc: 0.5126\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.3358 - acc: 0.5367 - val_loss: 1.3956 - val_acc: 0.5180\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.3272 - acc: 0.5383 - val_loss: 1.4142 - val_acc: 0.5102\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.3157 - acc: 0.5410 - val_loss: 1.4064 - val_acc: 0.5133\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.3067 - acc: 0.5441 - val_loss: 1.4130 - val_acc: 0.5162\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.2950 - acc: 0.5471 - val_loss: 1.4146 - val_acc: 0.5158\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.2801 - acc: 0.5530 - val_loss: 1.4019 - val_acc: 0.5172\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.2725 - acc: 0.5537 - val_loss: 1.4129 - val_acc: 0.5158\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.2628 - acc: 0.5557 - val_loss: 1.4258 - val_acc: 0.5129\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.2487 - acc: 0.5616 - val_loss: 1.4446 - val_acc: 0.5159\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.2383 - acc: 0.5615 - val_loss: 1.4246 - val_acc: 0.5162\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.2330 - acc: 0.5662 - val_loss: 1.4310 - val_acc: 0.5132\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.2190 - acc: 0.5705 - val_loss: 1.4341 - val_acc: 0.5068\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.2114 - acc: 0.5716 - val_loss: 1.4227 - val_acc: 0.5148\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.1989 - acc: 0.5755 - val_loss: 1.4617 - val_acc: 0.5137\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.1921 - acc: 0.5775 - val_loss: 1.4365 - val_acc: 0.5169\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.1770 - acc: 0.5847 - val_loss: 1.4389 - val_acc: 0.5121\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.1678 - acc: 0.5836 - val_loss: 1.4415 - val_acc: 0.5167\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.1576 - acc: 0.5892 - val_loss: 1.4524 - val_acc: 0.5123\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.1453 - acc: 0.5900 - val_loss: 1.4627 - val_acc: 0.5086\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.1390 - acc: 0.5942 - val_loss: 1.4688 - val_acc: 0.5154\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.1300 - acc: 0.5957 - val_loss: 1.4714 - val_acc: 0.5099\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 10s 254us/step - loss: 1.1233 - acc: 0.5982 - val_loss: 1.5069 - val_acc: 0.5090\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 10s 254us/step - loss: 1.1127 - acc: 0.6020 - val_loss: 1.4991 - val_acc: 0.5084\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.1015 - acc: 0.6044 - val_loss: 1.4915 - val_acc: 0.5099\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.0946 - acc: 0.6073 - val_loss: 1.5082 - val_acc: 0.5061\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.0840 - acc: 0.6087 - val_loss: 1.5189 - val_acc: 0.5072\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 10s 253us/step - loss: 1.0720 - acc: 0.6171 - val_loss: 1.5483 - val_acc: 0.5067\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 10s 256us/step - loss: 1.0693 - acc: 0.6139 - val_loss: 1.5452 - val_acc: 0.5046\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.0503 - acc: 0.6201 - val_loss: 1.5455 - val_acc: 0.5064\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.0469 - acc: 0.6218 - val_loss: 1.5550 - val_acc: 0.4958\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.0401 - acc: 0.6230 - val_loss: 1.6039 - val_acc: 0.5077\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.0291 - acc: 0.6278 - val_loss: 1.5809 - val_acc: 0.5034\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.0175 - acc: 0.6332 - val_loss: 1.6148 - val_acc: 0.5083\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.0130 - acc: 0.6343 - val_loss: 1.6013 - val_acc: 0.5051\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.0041 - acc: 0.6358 - val_loss: 1.5919 - val_acc: 0.5051\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 0.9969 - acc: 0.6381 - val_loss: 1.6501 - val_acc: 0.5025\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 0.9883 - acc: 0.6432 - val_loss: 1.6170 - val_acc: 0.5029\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 0.9783 - acc: 0.6431 - val_loss: 1.6618 - val_acc: 0.5055\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.9689 - acc: 0.6497 - val_loss: 1.6751 - val_acc: 0.4999\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 0.9614 - acc: 0.6512 - val_loss: 1.6508 - val_acc: 0.4963\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 0.9549 - acc: 0.6502 - val_loss: 1.7108 - val_acc: 0.4978\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 0.9449 - acc: 0.6536 - val_loss: 1.6836 - val_acc: 0.4940\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.9347 - acc: 0.6571 - val_loss: 1.7201 - val_acc: 0.4967\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.9273 - acc: 0.6609 - val_loss: 1.7557 - val_acc: 0.5009\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 0.9208 - acc: 0.6622 - val_loss: 1.7616 - val_acc: 0.4964\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.9105 - acc: 0.6680 - val_loss: 1.7639 - val_acc: 0.4971\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 10s 259us/step - loss: 0.9018 - acc: 0.6685 - val_loss: 1.8125 - val_acc: 0.4890\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 0.8968 - acc: 0.6710 - val_loss: 1.7925 - val_acc: 0.4986\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.8901 - acc: 0.6751 - val_loss: 1.7921 - val_acc: 0.4950\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 0.8814 - acc: 0.6761 - val_loss: 1.8075 - val_acc: 0.4952\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.8729 - acc: 0.6743 - val_loss: 1.8869 - val_acc: 0.4960\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 0.8662 - acc: 0.6822 - val_loss: 1.8389 - val_acc: 0.4911\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 0.8653 - acc: 0.6807 - val_loss: 1.8116 - val_acc: 0.4906\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 0.8483 - acc: 0.6856 - val_loss: 1.9763 - val_acc: 0.4958\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.8485 - acc: 0.6859 - val_loss: 1.9566 - val_acc: 0.4934\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 0.8358 - acc: 0.6926 - val_loss: 1.9744 - val_acc: 0.4927\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.8332 - acc: 0.6887 - val_loss: 1.9574 - val_acc: 0.4937\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.8232 - acc: 0.6957 - val_loss: 1.8950 - val_acc: 0.4911\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 0.8156 - acc: 0.6983 - val_loss: 1.9933 - val_acc: 0.4914\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 0.8149 - acc: 0.6972 - val_loss: 1.9871 - val_acc: 0.4890\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 0.8073 - acc: 0.7012 - val_loss: 2.0722 - val_acc: 0.4933\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.7957 - acc: 0.7053 - val_loss: 1.9778 - val_acc: 0.4870\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 0.7957 - acc: 0.7050 - val_loss: 2.0540 - val_acc: 0.4842\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 0.7816 - acc: 0.7097 - val_loss: 2.0554 - val_acc: 0.4855\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 0.7815 - acc: 0.7103 - val_loss: 2.0671 - val_acc: 0.4882\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 0.7755 - acc: 0.7101 - val_loss: 2.1276 - val_acc: 0.4840\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.7675 - acc: 0.7123 - val_loss: 2.1303 - val_acc: 0.4879\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 0.7609 - acc: 0.7142 - val_loss: 2.0612 - val_acc: 0.4802\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.7557 - acc: 0.7178 - val_loss: 2.1836 - val_acc: 0.4826\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 0.7447 - acc: 0.7226 - val_loss: 2.1664 - val_acc: 0.4858\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 0.7465 - acc: 0.7238 - val_loss: 2.1464 - val_acc: 0.4790\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 10s 256us/step - loss: 0.7383 - acc: 0.7250 - val_loss: 2.1037 - val_acc: 0.4816\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.7317 - acc: 0.7262 - val_loss: 2.2542 - val_acc: 0.4859\n",
      "10000/10000 [==============================] - 3s 283us/step\n",
      "Validation loss: 2.2541904701292514\n",
      "Validation accuracy (NORMALIZED): 0.48590000654011967\n",
      "input_8  -----  False\n",
      "conv1  -----  False\n",
      "relu_conv1  -----  False\n",
      "pool1  -----  False\n",
      "fire2/squeeze1x1  -----  False\n",
      "fire2/relu_squeeze1x1  -----  False\n",
      "fire2/expand1x1  -----  False\n",
      "fire2/expand3x3  -----  False\n",
      "fire2/relu_expand1x1  -----  False\n",
      "fire2/relu_expand3x3  -----  False\n",
      "fire2/concat  -----  False\n",
      "fire3/squeeze1x1  -----  False\n",
      "fire3/relu_squeeze1x1  -----  False\n",
      "fire3/expand1x1  -----  False\n",
      "fire3/expand3x3  -----  False\n",
      "fire3/relu_expand1x1  -----  False\n",
      "fire3/relu_expand3x3  -----  False\n",
      "fire3/concat  -----  False\n",
      "pool3  -----  False\n",
      "fire4/squeeze1x1  -----  False\n",
      "fire4/relu_squeeze1x1  -----  False\n",
      "fire4/expand1x1  -----  False\n",
      "fire4/expand3x3  -----  False\n",
      "fire4/relu_expand1x1  -----  False\n",
      "fire4/relu_expand3x3  -----  False\n",
      "fire4/concat  -----  False\n",
      "fire5/squeeze1x1  -----  False\n",
      "fire5/relu_squeeze1x1  -----  False\n",
      "fire5/expand1x1  -----  False\n",
      "fire5/expand3x3  -----  False\n",
      "fire5/relu_expand1x1  -----  False\n",
      "fire5/relu_expand3x3  -----  False\n",
      "fire5/concat  -----  False\n",
      "pool5  -----  False\n",
      "fire6/squeeze1x1  -----  False\n",
      "fire6/relu_squeeze1x1  -----  False\n",
      "fire6/expand1x1  -----  False\n",
      "fire6/expand3x3  -----  False\n",
      "fire6/relu_expand1x1  -----  False\n",
      "fire6/relu_expand3x3  -----  False\n",
      "fire6/concat  -----  False\n",
      "fire7/squeeze1x1  -----  False\n",
      "fire7/relu_squeeze1x1  -----  False\n",
      "fire7/expand1x1  -----  False\n",
      "fire7/expand3x3  -----  False\n",
      "fire7/relu_expand1x1  -----  False\n",
      "fire7/relu_expand3x3  -----  False\n",
      "fire7/concat  -----  False\n",
      "fire8/squeeze1x1  -----  True\n",
      "fire8/relu_squeeze1x1  -----  True\n",
      "fire8/expand1x1  -----  True\n",
      "fire8/expand3x3  -----  True\n",
      "fire8/relu_expand1x1  -----  True\n",
      "fire8/relu_expand3x3  -----  True\n",
      "fire8/concat  -----  True\n",
      "fire9/squeeze1x1  -----  True\n",
      "fire9/relu_squeeze1x1  -----  True\n",
      "fire9/expand1x1  -----  True\n",
      "fire9/expand3x3  -----  True\n",
      "fire9/relu_expand1x1  -----  True\n",
      "fire9/relu_expand3x3  -----  True\n",
      "fire9/concat  -----  True\n",
      "drop9  -----  True\n",
      "conv10  -----  True\n",
      "relu_conv10  -----  True\n",
      "global_average_pooling2d_15  -----  True\n",
      "loss  -----  True\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 386,176\n",
      "Non-trainable params: 336,320\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "Split: 1\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 11s 269us/step - loss: 2.3600 - acc: 0.1849 - val_loss: 1.9972 - val_acc: 0.3241\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 2.0261 - acc: 0.2570 - val_loss: 1.7922 - val_acc: 0.3843\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.9170 - acc: 0.2996 - val_loss: 1.7176 - val_acc: 0.4064\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.8408 - acc: 0.3320 - val_loss: 1.6708 - val_acc: 0.4176\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.7865 - acc: 0.3504 - val_loss: 1.6206 - val_acc: 0.4384\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.7448 - acc: 0.3720 - val_loss: 1.6038 - val_acc: 0.4360\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.7089 - acc: 0.3893 - val_loss: 1.5724 - val_acc: 0.4467\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.6758 - acc: 0.4004 - val_loss: 1.5498 - val_acc: 0.4659\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.6514 - acc: 0.4118 - val_loss: 1.5476 - val_acc: 0.4664\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.6309 - acc: 0.4255 - val_loss: 1.5134 - val_acc: 0.4685\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.6009 - acc: 0.4378 - val_loss: 1.5113 - val_acc: 0.4808\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 1.5775 - acc: 0.4453 - val_loss: 1.5086 - val_acc: 0.4762\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.5576 - acc: 0.4552 - val_loss: 1.4963 - val_acc: 0.4823\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.5423 - acc: 0.4621 - val_loss: 1.4852 - val_acc: 0.4861\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.5240 - acc: 0.4702 - val_loss: 1.4769 - val_acc: 0.4915\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.5061 - acc: 0.4741 - val_loss: 1.4641 - val_acc: 0.4913\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 1.4884 - acc: 0.4840 - val_loss: 1.4703 - val_acc: 0.4863\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.4701 - acc: 0.4900 - val_loss: 1.4686 - val_acc: 0.4924\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 1.4540 - acc: 0.4946 - val_loss: 1.4551 - val_acc: 0.4938\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 1.4468 - acc: 0.4977 - val_loss: 1.4508 - val_acc: 0.5002\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.4296 - acc: 0.5049 - val_loss: 1.4499 - val_acc: 0.4999\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.4209 - acc: 0.5023 - val_loss: 1.4427 - val_acc: 0.4955\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.4013 - acc: 0.5122 - val_loss: 1.4527 - val_acc: 0.4985\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 10s 256us/step - loss: 1.3957 - acc: 0.5164 - val_loss: 1.4438 - val_acc: 0.5017\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.3749 - acc: 0.5223 - val_loss: 1.4544 - val_acc: 0.5050\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.3739 - acc: 0.5207 - val_loss: 1.4427 - val_acc: 0.5035\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.3567 - acc: 0.5282 - val_loss: 1.4394 - val_acc: 0.5010\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.3410 - acc: 0.5281 - val_loss: 1.4395 - val_acc: 0.5019\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.3323 - acc: 0.5343 - val_loss: 1.4613 - val_acc: 0.5025\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.3222 - acc: 0.5357 - val_loss: 1.4715 - val_acc: 0.5015\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.3104 - acc: 0.5428 - val_loss: 1.4562 - val_acc: 0.5025\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.3010 - acc: 0.5451 - val_loss: 1.4468 - val_acc: 0.5044\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.2854 - acc: 0.5484 - val_loss: 1.4662 - val_acc: 0.5055\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.2772 - acc: 0.5520 - val_loss: 1.4388 - val_acc: 0.5042\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.2675 - acc: 0.5533 - val_loss: 1.4575 - val_acc: 0.5060\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.2570 - acc: 0.5564 - val_loss: 1.4749 - val_acc: 0.5017\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 9s 224us/step - loss: 1.2423 - acc: 0.5617 - val_loss: 1.4522 - val_acc: 0.5059\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 9s 224us/step - loss: 1.2399 - acc: 0.5625 - val_loss: 1.4430 - val_acc: 0.5064\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 9s 224us/step - loss: 1.2264 - acc: 0.5642 - val_loss: 1.4726 - val_acc: 0.5082\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.2154 - acc: 0.5683 - val_loss: 1.4773 - val_acc: 0.5084\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.2090 - acc: 0.5737 - val_loss: 1.4942 - val_acc: 0.5070\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.1972 - acc: 0.5739 - val_loss: 1.5029 - val_acc: 0.5001\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.1846 - acc: 0.5771 - val_loss: 1.5098 - val_acc: 0.5084\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.1761 - acc: 0.5796 - val_loss: 1.4813 - val_acc: 0.5083\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.1705 - acc: 0.5824 - val_loss: 1.4805 - val_acc: 0.5036\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.1586 - acc: 0.5887 - val_loss: 1.4971 - val_acc: 0.5042\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.1508 - acc: 0.5878 - val_loss: 1.5138 - val_acc: 0.5075\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.1449 - acc: 0.5910 - val_loss: 1.5246 - val_acc: 0.5012\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.1323 - acc: 0.5922 - val_loss: 1.5256 - val_acc: 0.5064\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.1251 - acc: 0.5978 - val_loss: 1.5249 - val_acc: 0.5022\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.1172 - acc: 0.6015 - val_loss: 1.5289 - val_acc: 0.5042\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.1053 - acc: 0.6032 - val_loss: 1.5454 - val_acc: 0.5029\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.0964 - acc: 0.6066 - val_loss: 1.6084 - val_acc: 0.5061\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.0865 - acc: 0.6099 - val_loss: 1.5655 - val_acc: 0.5033\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.0786 - acc: 0.6101 - val_loss: 1.5531 - val_acc: 0.5018\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.0671 - acc: 0.6134 - val_loss: 1.6257 - val_acc: 0.5030\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 9s 220us/step - loss: 1.0600 - acc: 0.6145 - val_loss: 1.5804 - val_acc: 0.5069\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 9s 220us/step - loss: 1.0519 - acc: 0.6184 - val_loss: 1.5741 - val_acc: 0.4975\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 9s 221us/step - loss: 1.0432 - acc: 0.6213 - val_loss: 1.5918 - val_acc: 0.4966\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 9s 221us/step - loss: 1.0384 - acc: 0.6220 - val_loss: 1.6096 - val_acc: 0.4947\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 9s 222us/step - loss: 1.0279 - acc: 0.6267 - val_loss: 1.6433 - val_acc: 0.5040\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 9s 222us/step - loss: 1.0181 - acc: 0.6291 - val_loss: 1.5975 - val_acc: 0.4980\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 9s 222us/step - loss: 1.0089 - acc: 0.6326 - val_loss: 1.6628 - val_acc: 0.5007\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 9s 221us/step - loss: 1.0067 - acc: 0.6317 - val_loss: 1.6593 - val_acc: 0.4971\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 9s 222us/step - loss: 0.9963 - acc: 0.6371 - val_loss: 1.6743 - val_acc: 0.4980\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 0.9850 - acc: 0.6388 - val_loss: 1.6787 - val_acc: 0.4944\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 0.9814 - acc: 0.6402 - val_loss: 1.6352 - val_acc: 0.4986\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.9708 - acc: 0.6464 - val_loss: 1.7543 - val_acc: 0.5000\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 0.9640 - acc: 0.6472 - val_loss: 1.7364 - val_acc: 0.4941\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 0.9554 - acc: 0.6494 - val_loss: 1.6908 - val_acc: 0.4984\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.9518 - acc: 0.6531 - val_loss: 1.8049 - val_acc: 0.4963\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.9412 - acc: 0.6562 - val_loss: 1.7796 - val_acc: 0.4959\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.9323 - acc: 0.6571 - val_loss: 1.7606 - val_acc: 0.4918\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.9252 - acc: 0.6591 - val_loss: 1.7913 - val_acc: 0.4977\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.9171 - acc: 0.6644 - val_loss: 1.7801 - val_acc: 0.4927\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 10s 256us/step - loss: 0.9092 - acc: 0.6655 - val_loss: 1.8162 - val_acc: 0.4926\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.9013 - acc: 0.6666 - val_loss: 1.8253 - val_acc: 0.4915\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 0.8959 - acc: 0.6685 - val_loss: 1.8126 - val_acc: 0.4910\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.8867 - acc: 0.6725 - val_loss: 1.8043 - val_acc: 0.4913\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.8847 - acc: 0.6731 - val_loss: 1.8019 - val_acc: 0.4954\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.8732 - acc: 0.6763 - val_loss: 1.8775 - val_acc: 0.4929\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.8665 - acc: 0.6810 - val_loss: 1.8657 - val_acc: 0.4944\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.8654 - acc: 0.6821 - val_loss: 1.8477 - val_acc: 0.4906\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 0.8503 - acc: 0.6870 - val_loss: 1.9142 - val_acc: 0.4873\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 0.8449 - acc: 0.6867 - val_loss: 1.9161 - val_acc: 0.4891\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.8426 - acc: 0.6895 - val_loss: 1.9517 - val_acc: 0.4929\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 0.8348 - acc: 0.6918 - val_loss: 2.1172 - val_acc: 0.4840\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.8255 - acc: 0.6933 - val_loss: 1.9416 - val_acc: 0.4905\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.8234 - acc: 0.6939 - val_loss: 1.9293 - val_acc: 0.4862\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 0.8169 - acc: 0.6976 - val_loss: 1.9717 - val_acc: 0.4846\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 0.8101 - acc: 0.7001 - val_loss: 2.0036 - val_acc: 0.4873\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.8043 - acc: 0.7005 - val_loss: 2.0381 - val_acc: 0.4859\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 0.7983 - acc: 0.7041 - val_loss: 2.0388 - val_acc: 0.4880\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 10s 255us/step - loss: 0.7903 - acc: 0.7058 - val_loss: 2.0283 - val_acc: 0.4884\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.7898 - acc: 0.7041 - val_loss: 2.0400 - val_acc: 0.4865\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.7807 - acc: 0.7096 - val_loss: 2.0929 - val_acc: 0.4853\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 0.7763 - acc: 0.7113 - val_loss: 2.1388 - val_acc: 0.4847\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 0.7672 - acc: 0.7132 - val_loss: 2.0788 - val_acc: 0.4780\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 0.7629 - acc: 0.7138 - val_loss: 2.0513 - val_acc: 0.4802\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.7573 - acc: 0.7176 - val_loss: 2.2080 - val_acc: 0.4861\n",
      "10000/10000 [==============================] - 3s 349us/step\n",
      "Validation loss: 2.2080171611607073\n",
      "Validation accuracy (NORMALIZED): 0.4861000063717365\n",
      "input_9  -----  False\n",
      "conv1  -----  False\n",
      "relu_conv1  -----  False\n",
      "pool1  -----  False\n",
      "fire2/squeeze1x1  -----  False\n",
      "fire2/relu_squeeze1x1  -----  False\n",
      "fire2/expand1x1  -----  False\n",
      "fire2/expand3x3  -----  False\n",
      "fire2/relu_expand1x1  -----  False\n",
      "fire2/relu_expand3x3  -----  False\n",
      "fire2/concat  -----  False\n",
      "fire3/squeeze1x1  -----  False\n",
      "fire3/relu_squeeze1x1  -----  False\n",
      "fire3/expand1x1  -----  False\n",
      "fire3/expand3x3  -----  False\n",
      "fire3/relu_expand1x1  -----  False\n",
      "fire3/relu_expand3x3  -----  False\n",
      "fire3/concat  -----  False\n",
      "pool3  -----  False\n",
      "fire4/squeeze1x1  -----  False\n",
      "fire4/relu_squeeze1x1  -----  False\n",
      "fire4/expand1x1  -----  False\n",
      "fire4/expand3x3  -----  False\n",
      "fire4/relu_expand1x1  -----  False\n",
      "fire4/relu_expand3x3  -----  False\n",
      "fire4/concat  -----  False\n",
      "fire5/squeeze1x1  -----  False\n",
      "fire5/relu_squeeze1x1  -----  False\n",
      "fire5/expand1x1  -----  False\n",
      "fire5/expand3x3  -----  False\n",
      "fire5/relu_expand1x1  -----  False\n",
      "fire5/relu_expand3x3  -----  False\n",
      "fire5/concat  -----  False\n",
      "pool5  -----  False\n",
      "fire6/squeeze1x1  -----  False\n",
      "fire6/relu_squeeze1x1  -----  False\n",
      "fire6/expand1x1  -----  False\n",
      "fire6/expand3x3  -----  False\n",
      "fire6/relu_expand1x1  -----  False\n",
      "fire6/relu_expand3x3  -----  False\n",
      "fire6/concat  -----  False\n",
      "fire7/squeeze1x1  -----  False\n",
      "fire7/relu_squeeze1x1  -----  False\n",
      "fire7/expand1x1  -----  False\n",
      "fire7/expand3x3  -----  False\n",
      "fire7/relu_expand1x1  -----  False\n",
      "fire7/relu_expand3x3  -----  False\n",
      "fire7/concat  -----  False\n",
      "fire8/squeeze1x1  -----  True\n",
      "fire8/relu_squeeze1x1  -----  True\n",
      "fire8/expand1x1  -----  True\n",
      "fire8/expand3x3  -----  True\n",
      "fire8/relu_expand1x1  -----  True\n",
      "fire8/relu_expand3x3  -----  True\n",
      "fire8/concat  -----  True\n",
      "fire9/squeeze1x1  -----  True\n",
      "fire9/relu_squeeze1x1  -----  True\n",
      "fire9/expand1x1  -----  True\n",
      "fire9/expand3x3  -----  True\n",
      "fire9/relu_expand1x1  -----  True\n",
      "fire9/relu_expand3x3  -----  True\n",
      "fire9/concat  -----  True\n",
      "drop9  -----  True\n",
      "conv10  -----  True\n",
      "relu_conv10  -----  True\n",
      "global_average_pooling2d_17  -----  True\n",
      "loss  -----  True\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 386,176\n",
      "Non-trainable params: 336,320\n",
      "__________________________________________________________________________________________________\n",
      "================================================\n",
      "Split: 2\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 11s 287us/step - loss: 2.3633 - acc: 0.1924 - val_loss: 1.9625 - val_acc: 0.3501\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 1.9885 - acc: 0.2867 - val_loss: 1.7326 - val_acc: 0.4089\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 1.8533 - acc: 0.3349 - val_loss: 1.6432 - val_acc: 0.4372\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 10s 251us/step - loss: 1.7902 - acc: 0.3579 - val_loss: 1.5801 - val_acc: 0.4508\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.7401 - acc: 0.3750 - val_loss: 1.5763 - val_acc: 0.4630\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.7015 - acc: 0.3919 - val_loss: 1.5557 - val_acc: 0.4695\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 1.6786 - acc: 0.4049 - val_loss: 1.5250 - val_acc: 0.4756\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.6460 - acc: 0.4214 - val_loss: 1.5110 - val_acc: 0.4765\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.6254 - acc: 0.4267 - val_loss: 1.4877 - val_acc: 0.4798\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.6103 - acc: 0.4341 - val_loss: 1.4781 - val_acc: 0.4803\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.5823 - acc: 0.4451 - val_loss: 1.4722 - val_acc: 0.4847\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.5681 - acc: 0.4552 - val_loss: 1.4539 - val_acc: 0.4877\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.5419 - acc: 0.4626 - val_loss: 1.4434 - val_acc: 0.4931\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.5295 - acc: 0.4656 - val_loss: 1.4454 - val_acc: 0.4954\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.5126 - acc: 0.4765 - val_loss: 1.4407 - val_acc: 0.5004\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.4962 - acc: 0.4810 - val_loss: 1.4375 - val_acc: 0.4999\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.4839 - acc: 0.4846 - val_loss: 1.4363 - val_acc: 0.4920\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.4704 - acc: 0.4902 - val_loss: 1.4183 - val_acc: 0.5026\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.4573 - acc: 0.4959 - val_loss: 1.4121 - val_acc: 0.5042\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.4456 - acc: 0.5034 - val_loss: 1.4165 - val_acc: 0.5076\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.4323 - acc: 0.5018 - val_loss: 1.4187 - val_acc: 0.5070\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.4249 - acc: 0.5063 - val_loss: 1.4064 - val_acc: 0.5069\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 1.4123 - acc: 0.5126 - val_loss: 1.4125 - val_acc: 0.5092\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.3950 - acc: 0.5191 - val_loss: 1.4088 - val_acc: 0.5086\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 11s 265us/step - loss: 1.3865 - acc: 0.5177 - val_loss: 1.4049 - val_acc: 0.5116\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 10s 256us/step - loss: 1.3740 - acc: 0.5232 - val_loss: 1.4054 - val_acc: 0.5095\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.3649 - acc: 0.5246 - val_loss: 1.4075 - val_acc: 0.5117\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.3526 - acc: 0.5284 - val_loss: 1.4040 - val_acc: 0.5126\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.3440 - acc: 0.5333 - val_loss: 1.3944 - val_acc: 0.5158\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.3325 - acc: 0.5353 - val_loss: 1.4067 - val_acc: 0.5148\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.3280 - acc: 0.5374 - val_loss: 1.3976 - val_acc: 0.5177\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.3155 - acc: 0.5438 - val_loss: 1.4107 - val_acc: 0.5121\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.3022 - acc: 0.5456 - val_loss: 1.4184 - val_acc: 0.5107\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.2960 - acc: 0.5494 - val_loss: 1.4022 - val_acc: 0.5191\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.2854 - acc: 0.5515 - val_loss: 1.4237 - val_acc: 0.5165\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.2756 - acc: 0.5537 - val_loss: 1.4168 - val_acc: 0.5157\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 1.2653 - acc: 0.5559 - val_loss: 1.4261 - val_acc: 0.5176\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 1.2520 - acc: 0.5625 - val_loss: 1.4344 - val_acc: 0.5174\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.2420 - acc: 0.5626 - val_loss: 1.4241 - val_acc: 0.5156\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.2399 - acc: 0.5643 - val_loss: 1.4320 - val_acc: 0.5193\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.2262 - acc: 0.5683 - val_loss: 1.4501 - val_acc: 0.5183\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.2164 - acc: 0.5724 - val_loss: 1.4271 - val_acc: 0.5211\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.2108 - acc: 0.5760 - val_loss: 1.4517 - val_acc: 0.5107\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 1.1989 - acc: 0.5762 - val_loss: 1.4458 - val_acc: 0.5150\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 1.1869 - acc: 0.5786 - val_loss: 1.4489 - val_acc: 0.5117\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.1809 - acc: 0.5820 - val_loss: 1.4573 - val_acc: 0.5197\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.1732 - acc: 0.5826 - val_loss: 1.4760 - val_acc: 0.5164\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 1.1603 - acc: 0.5890 - val_loss: 1.4732 - val_acc: 0.5146\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 10s 262us/step - loss: 1.1514 - acc: 0.5904 - val_loss: 1.4888 - val_acc: 0.5205\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 1.1420 - acc: 0.5940 - val_loss: 1.4762 - val_acc: 0.5169\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 1.1356 - acc: 0.5963 - val_loss: 1.5088 - val_acc: 0.5151\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 10s 251us/step - loss: 1.1253 - acc: 0.5977 - val_loss: 1.4948 - val_acc: 0.5158\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 10s 253us/step - loss: 1.1171 - acc: 0.5986 - val_loss: 1.5285 - val_acc: 0.5176\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 10s 254us/step - loss: 1.1061 - acc: 0.6044 - val_loss: 1.4960 - val_acc: 0.5142\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 1.0958 - acc: 0.6066 - val_loss: 1.5350 - val_acc: 0.5127\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.0894 - acc: 0.6093 - val_loss: 1.5398 - val_acc: 0.5127\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.0774 - acc: 0.6102 - val_loss: 1.5226 - val_acc: 0.5160\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.0728 - acc: 0.6179 - val_loss: 1.5554 - val_acc: 0.5090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.0659 - acc: 0.6170 - val_loss: 1.5647 - val_acc: 0.5093\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.0558 - acc: 0.6216 - val_loss: 1.5871 - val_acc: 0.5132\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.0482 - acc: 0.6214 - val_loss: 1.5881 - val_acc: 0.5112\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.0380 - acc: 0.6252 - val_loss: 1.5765 - val_acc: 0.5105\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.0309 - acc: 0.6276 - val_loss: 1.6148 - val_acc: 0.5116\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.0212 - acc: 0.6297 - val_loss: 1.5838 - val_acc: 0.5113\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.0113 - acc: 0.6348 - val_loss: 1.5881 - val_acc: 0.5110\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.0035 - acc: 0.6369 - val_loss: 1.6532 - val_acc: 0.5165\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 0.9985 - acc: 0.6371 - val_loss: 1.6268 - val_acc: 0.5125\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 0.9881 - acc: 0.6409 - val_loss: 1.6506 - val_acc: 0.5068\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 0.9825 - acc: 0.6425 - val_loss: 1.6434 - val_acc: 0.5043\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 0.9695 - acc: 0.6475 - val_loss: 1.7199 - val_acc: 0.5062\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 0.9673 - acc: 0.6469 - val_loss: 1.6969 - val_acc: 0.5083\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 0.9559 - acc: 0.6498 - val_loss: 1.7128 - val_acc: 0.5065\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 10s 251us/step - loss: 0.9506 - acc: 0.6571 - val_loss: 1.6812 - val_acc: 0.5059\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 11s 268us/step - loss: 0.9431 - acc: 0.6554 - val_loss: 1.7777 - val_acc: 0.5048\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 10s 254us/step - loss: 0.9352 - acc: 0.6590 - val_loss: 1.7446 - val_acc: 0.5112\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.9248 - acc: 0.6638 - val_loss: 1.7439 - val_acc: 0.5093\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 0.9224 - acc: 0.6603 - val_loss: 1.7629 - val_acc: 0.5063\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 0.9089 - acc: 0.6685 - val_loss: 1.7648 - val_acc: 0.5092\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 0.9075 - acc: 0.6693 - val_loss: 1.7958 - val_acc: 0.5043\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 0.8959 - acc: 0.6690 - val_loss: 1.7925 - val_acc: 0.5020\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 0.8904 - acc: 0.6707 - val_loss: 1.8292 - val_acc: 0.5047\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 0.8847 - acc: 0.6749 - val_loss: 1.8068 - val_acc: 0.5015\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.8782 - acc: 0.6764 - val_loss: 1.9284 - val_acc: 0.5035\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 0.8705 - acc: 0.6796 - val_loss: 1.8788 - val_acc: 0.5047\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.8651 - acc: 0.6807 - val_loss: 1.9165 - val_acc: 0.5023\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 0.8566 - acc: 0.6835 - val_loss: 1.9047 - val_acc: 0.4981\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 10s 260us/step - loss: 0.8503 - acc: 0.6835 - val_loss: 1.9279 - val_acc: 0.5014\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 11s 271us/step - loss: 0.8427 - acc: 0.6885 - val_loss: 1.8905 - val_acc: 0.4976\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 11s 279us/step - loss: 0.8409 - acc: 0.6871 - val_loss: 1.9355 - val_acc: 0.5052\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.8298 - acc: 0.6912 - val_loss: 1.9461 - val_acc: 0.5004\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 0.8240 - acc: 0.6943 - val_loss: 1.9482 - val_acc: 0.4951\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.8169 - acc: 0.6960 - val_loss: 1.9044 - val_acc: 0.4993\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 0.8147 - acc: 0.6982 - val_loss: 2.0001 - val_acc: 0.4969\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 0.8063 - acc: 0.7002 - val_loss: 1.9815 - val_acc: 0.4999\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 0.8007 - acc: 0.7016 - val_loss: 2.0195 - val_acc: 0.5009\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.7964 - acc: 0.7046 - val_loss: 2.0264 - val_acc: 0.5031\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 0.7882 - acc: 0.7053 - val_loss: 2.0513 - val_acc: 0.4930\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 0.7825 - acc: 0.7065 - val_loss: 2.0980 - val_acc: 0.4990\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.7802 - acc: 0.7068 - val_loss: 2.0715 - val_acc: 0.4937\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 0.7758 - acc: 0.7091 - val_loss: 2.0706 - val_acc: 0.4986\n",
      "10000/10000 [==============================] - 3s 272us/step\n",
      "Validation loss: 2.0705572418570517\n",
      "Validation accuracy (NORMALIZED): 0.49860000690817835\n",
      "input_10  -----  False\n",
      "conv1  -----  False\n",
      "relu_conv1  -----  False\n",
      "pool1  -----  False\n",
      "fire2/squeeze1x1  -----  False\n",
      "fire2/relu_squeeze1x1  -----  False\n",
      "fire2/expand1x1  -----  False\n",
      "fire2/expand3x3  -----  False\n",
      "fire2/relu_expand1x1  -----  False\n",
      "fire2/relu_expand3x3  -----  False\n",
      "fire2/concat  -----  False\n",
      "fire3/squeeze1x1  -----  False\n",
      "fire3/relu_squeeze1x1  -----  False\n",
      "fire3/expand1x1  -----  False\n",
      "fire3/expand3x3  -----  False\n",
      "fire3/relu_expand1x1  -----  False\n",
      "fire3/relu_expand3x3  -----  False\n",
      "fire3/concat  -----  False\n",
      "pool3  -----  False\n",
      "fire4/squeeze1x1  -----  False\n",
      "fire4/relu_squeeze1x1  -----  False\n",
      "fire4/expand1x1  -----  False\n",
      "fire4/expand3x3  -----  False\n",
      "fire4/relu_expand1x1  -----  False\n",
      "fire4/relu_expand3x3  -----  False\n",
      "fire4/concat  -----  False\n",
      "fire5/squeeze1x1  -----  False\n",
      "fire5/relu_squeeze1x1  -----  False\n",
      "fire5/expand1x1  -----  False\n",
      "fire5/expand3x3  -----  False\n",
      "fire5/relu_expand1x1  -----  False\n",
      "fire5/relu_expand3x3  -----  False\n",
      "fire5/concat  -----  False\n",
      "pool5  -----  False\n",
      "fire6/squeeze1x1  -----  False\n",
      "fire6/relu_squeeze1x1  -----  False\n",
      "fire6/expand1x1  -----  False\n",
      "fire6/expand3x3  -----  False\n",
      "fire6/relu_expand1x1  -----  False\n",
      "fire6/relu_expand3x3  -----  False\n",
      "fire6/concat  -----  False\n",
      "fire7/squeeze1x1  -----  False\n",
      "fire7/relu_squeeze1x1  -----  False\n",
      "fire7/expand1x1  -----  False\n",
      "fire7/expand3x3  -----  False\n",
      "fire7/relu_expand1x1  -----  False\n",
      "fire7/relu_expand3x3  -----  False\n",
      "fire7/concat  -----  False\n",
      "fire8/squeeze1x1  -----  True\n",
      "fire8/relu_squeeze1x1  -----  True\n",
      "fire8/expand1x1  -----  True\n",
      "fire8/expand3x3  -----  True\n",
      "fire8/relu_expand1x1  -----  True\n",
      "fire8/relu_expand3x3  -----  True\n",
      "fire8/concat  -----  True\n",
      "fire9/squeeze1x1  -----  True\n",
      "fire9/relu_squeeze1x1  -----  True\n",
      "fire9/expand1x1  -----  True\n",
      "fire9/expand3x3  -----  True\n",
      "fire9/relu_expand1x1  -----  True\n",
      "fire9/relu_expand3x3  -----  True\n",
      "fire9/concat  -----  True\n",
      "drop9  -----  True\n",
      "conv10  -----  True\n",
      "relu_conv10  -----  True\n",
      "global_average_pooling2d_19  -----  True\n",
      "loss  -----  True\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 386,176\n",
      "Non-trainable params: 336,320\n",
      "__________________________________________________________________________________________________\n",
      "================================================\n",
      "Split: 3\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 11s 274us/step - loss: 2.3492 - acc: 0.1867 - val_loss: 1.9735 - val_acc: 0.3317\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 2.0302 - acc: 0.2711 - val_loss: 1.8424 - val_acc: 0.3896\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.9238 - acc: 0.3168 - val_loss: 1.7488 - val_acc: 0.4158\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.8491 - acc: 0.3425 - val_loss: 1.6836 - val_acc: 0.4308\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.8011 - acc: 0.3621 - val_loss: 1.6178 - val_acc: 0.4455\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.7513 - acc: 0.3716 - val_loss: 1.5980 - val_acc: 0.4476\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.7193 - acc: 0.3854 - val_loss: 1.5613 - val_acc: 0.4552\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 10s 253us/step - loss: 1.6958 - acc: 0.3977 - val_loss: 1.5445 - val_acc: 0.4625\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 1.6690 - acc: 0.4098 - val_loss: 1.5416 - val_acc: 0.4575\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.6355 - acc: 0.4248 - val_loss: 1.5124 - val_acc: 0.4764\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.6113 - acc: 0.4376 - val_loss: 1.5087 - val_acc: 0.4728\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.5860 - acc: 0.4479 - val_loss: 1.4899 - val_acc: 0.4815\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.5677 - acc: 0.4543 - val_loss: 1.4740 - val_acc: 0.4820\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.5455 - acc: 0.4642 - val_loss: 1.4584 - val_acc: 0.4901\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.5298 - acc: 0.4711 - val_loss: 1.4534 - val_acc: 0.4949\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.5074 - acc: 0.4763 - val_loss: 1.4369 - val_acc: 0.4989\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.4927 - acc: 0.4809 - val_loss: 1.4413 - val_acc: 0.4973\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.4807 - acc: 0.4879 - val_loss: 1.4262 - val_acc: 0.5009\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.4661 - acc: 0.4919 - val_loss: 1.4453 - val_acc: 0.4971\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.4465 - acc: 0.5017 - val_loss: 1.4265 - val_acc: 0.4991\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.4345 - acc: 0.5041 - val_loss: 1.4263 - val_acc: 0.5079\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.4218 - acc: 0.5058 - val_loss: 1.4205 - val_acc: 0.5081\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 10s 257us/step - loss: 1.4088 - acc: 0.5096 - val_loss: 1.4177 - val_acc: 0.5078\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 11s 276us/step - loss: 1.3994 - acc: 0.5157 - val_loss: 1.4219 - val_acc: 0.5032\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.3843 - acc: 0.5194 - val_loss: 1.4266 - val_acc: 0.5092\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 9s 236us/step - loss: 1.3791 - acc: 0.5206 - val_loss: 1.4279 - val_acc: 0.5061\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.3589 - acc: 0.5239 - val_loss: 1.4071 - val_acc: 0.5124\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.3508 - acc: 0.5300 - val_loss: 1.4052 - val_acc: 0.5143\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.3441 - acc: 0.5339 - val_loss: 1.4040 - val_acc: 0.5139\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.3315 - acc: 0.5371 - val_loss: 1.4082 - val_acc: 0.5164\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.3209 - acc: 0.5370 - val_loss: 1.4096 - val_acc: 0.5130\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.3118 - acc: 0.5403 - val_loss: 1.4125 - val_acc: 0.5164\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.3013 - acc: 0.5413 - val_loss: 1.4212 - val_acc: 0.5177\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.2860 - acc: 0.5473 - val_loss: 1.4103 - val_acc: 0.5189\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 1.2748 - acc: 0.5544 - val_loss: 1.4215 - val_acc: 0.5118\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.2673 - acc: 0.5531 - val_loss: 1.4416 - val_acc: 0.5186\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.2601 - acc: 0.5555 - val_loss: 1.4431 - val_acc: 0.5155\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.2490 - acc: 0.5590 - val_loss: 1.4255 - val_acc: 0.5186\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.2421 - acc: 0.5642 - val_loss: 1.4227 - val_acc: 0.5209\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.2278 - acc: 0.5660 - val_loss: 1.4352 - val_acc: 0.5165\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 1.2215 - acc: 0.5683 - val_loss: 1.4741 - val_acc: 0.5182\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 10s 254us/step - loss: 1.2078 - acc: 0.5713 - val_loss: 1.4509 - val_acc: 0.5215\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 10s 256us/step - loss: 1.1986 - acc: 0.5759 - val_loss: 1.4447 - val_acc: 0.5163\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 10s 257us/step - loss: 1.1903 - acc: 0.5763 - val_loss: 1.4659 - val_acc: 0.5188\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 10s 255us/step - loss: 1.1805 - acc: 0.5791 - val_loss: 1.4639 - val_acc: 0.5180\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 10s 256us/step - loss: 1.1725 - acc: 0.5819 - val_loss: 1.4604 - val_acc: 0.5169\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 10s 253us/step - loss: 1.1617 - acc: 0.5859 - val_loss: 1.4823 - val_acc: 0.5132\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 11s 263us/step - loss: 1.1514 - acc: 0.5901 - val_loss: 1.4913 - val_acc: 0.5181\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 10s 257us/step - loss: 1.1447 - acc: 0.5931 - val_loss: 1.4853 - val_acc: 0.5140\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 1.1336 - acc: 0.5928 - val_loss: 1.4720 - val_acc: 0.5187\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 1.1257 - acc: 0.5980 - val_loss: 1.4889 - val_acc: 0.5156\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.1117 - acc: 0.6006 - val_loss: 1.4859 - val_acc: 0.5124\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.1056 - acc: 0.6035 - val_loss: 1.5059 - val_acc: 0.5151\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.0922 - acc: 0.6067 - val_loss: 1.4982 - val_acc: 0.5162\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.0866 - acc: 0.6068 - val_loss: 1.5334 - val_acc: 0.5162\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.0790 - acc: 0.6100 - val_loss: 1.5153 - val_acc: 0.5129\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.0693 - acc: 0.6156 - val_loss: 1.5430 - val_acc: 0.5166\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.0599 - acc: 0.6144 - val_loss: 1.5668 - val_acc: 0.5117\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.0481 - acc: 0.6203 - val_loss: 1.5986 - val_acc: 0.5144\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.0401 - acc: 0.6217 - val_loss: 1.5513 - val_acc: 0.5158\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.0362 - acc: 0.6238 - val_loss: 1.6097 - val_acc: 0.5141\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.0268 - acc: 0.6298 - val_loss: 1.6737 - val_acc: 0.5104\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.0228 - acc: 0.6281 - val_loss: 1.6104 - val_acc: 0.5112\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 1.0082 - acc: 0.6318 - val_loss: 1.6988 - val_acc: 0.5084\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 1.0000 - acc: 0.6361 - val_loss: 1.6422 - val_acc: 0.5101\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.9962 - acc: 0.6355 - val_loss: 1.6164 - val_acc: 0.5090\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.9880 - acc: 0.6404 - val_loss: 1.6622 - val_acc: 0.5128\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 11s 271us/step - loss: 0.9783 - acc: 0.6426 - val_loss: 1.6865 - val_acc: 0.5047\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 11s 266us/step - loss: 0.9695 - acc: 0.6471 - val_loss: 1.6690 - val_acc: 0.5072\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 10s 260us/step - loss: 0.9639 - acc: 0.6486 - val_loss: 1.6751 - val_acc: 0.5063\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 11s 264us/step - loss: 0.9545 - acc: 0.6514 - val_loss: 1.7308 - val_acc: 0.5088\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 0.9492 - acc: 0.6557 - val_loss: 1.6769 - val_acc: 0.5032\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 10s 254us/step - loss: 0.9399 - acc: 0.6566 - val_loss: 1.7455 - val_acc: 0.5072\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.9318 - acc: 0.6581 - val_loss: 1.7078 - val_acc: 0.5027\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.9246 - acc: 0.6615 - val_loss: 1.7319 - val_acc: 0.5047\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.9186 - acc: 0.6641 - val_loss: 1.7809 - val_acc: 0.5095\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.9111 - acc: 0.6652 - val_loss: 1.7609 - val_acc: 0.5092\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 0.9001 - acc: 0.6670 - val_loss: 1.7832 - val_acc: 0.5029\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 0.8930 - acc: 0.6738 - val_loss: 1.8346 - val_acc: 0.5043\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 0.8878 - acc: 0.6734 - val_loss: 1.7755 - val_acc: 0.5001\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 0.8808 - acc: 0.6762 - val_loss: 1.7851 - val_acc: 0.4976\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.8734 - acc: 0.6780 - val_loss: 1.8923 - val_acc: 0.5067\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 0.8625 - acc: 0.6799 - val_loss: 1.8435 - val_acc: 0.4961\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.8618 - acc: 0.6817 - val_loss: 1.8619 - val_acc: 0.5022\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 10s 252us/step - loss: 0.8553 - acc: 0.6829 - val_loss: 1.8367 - val_acc: 0.5029\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 9s 235us/step - loss: 0.8471 - acc: 0.6851 - val_loss: 1.8914 - val_acc: 0.5030\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 9s 237us/step - loss: 0.8417 - acc: 0.6891 - val_loss: 1.9153 - val_acc: 0.4970\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 11s 270us/step - loss: 0.8328 - acc: 0.6908 - val_loss: 2.0230 - val_acc: 0.4969\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 11s 265us/step - loss: 0.8281 - acc: 0.6942 - val_loss: 1.9134 - val_acc: 0.4961\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 10s 260us/step - loss: 0.8188 - acc: 0.6975 - val_loss: 1.9871 - val_acc: 0.5036\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 10s 256us/step - loss: 0.8167 - acc: 0.6966 - val_loss: 1.9512 - val_acc: 0.4993\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.8108 - acc: 0.6954 - val_loss: 2.0194 - val_acc: 0.4965\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 0.8036 - acc: 0.7030 - val_loss: 2.0605 - val_acc: 0.4973\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.7995 - acc: 0.7035 - val_loss: 2.0496 - val_acc: 0.4991\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.7958 - acc: 0.7023 - val_loss: 2.0159 - val_acc: 0.4948\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 0.7834 - acc: 0.7079 - val_loss: 2.0361 - val_acc: 0.4908\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 0.7833 - acc: 0.7083 - val_loss: 2.0886 - val_acc: 0.4951\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 11s 263us/step - loss: 0.7704 - acc: 0.7103 - val_loss: 2.1005 - val_acc: 0.4978\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 0.7647 - acc: 0.7157 - val_loss: 2.1460 - val_acc: 0.4932\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.7646 - acc: 0.7127 - val_loss: 2.1195 - val_acc: 0.4934\n",
      "10000/10000 [==============================] - 3s 294us/step\n",
      "Validation loss: 2.1195410302877424\n",
      "Validation accuracy (NORMALIZED): 0.49340000670403245\n",
      "input_11  -----  False\n",
      "conv1  -----  False\n",
      "relu_conv1  -----  False\n",
      "pool1  -----  False\n",
      "fire2/squeeze1x1  -----  False\n",
      "fire2/relu_squeeze1x1  -----  False\n",
      "fire2/expand1x1  -----  False\n",
      "fire2/expand3x3  -----  False\n",
      "fire2/relu_expand1x1  -----  False\n",
      "fire2/relu_expand3x3  -----  False\n",
      "fire2/concat  -----  False\n",
      "fire3/squeeze1x1  -----  False\n",
      "fire3/relu_squeeze1x1  -----  False\n",
      "fire3/expand1x1  -----  False\n",
      "fire3/expand3x3  -----  False\n",
      "fire3/relu_expand1x1  -----  False\n",
      "fire3/relu_expand3x3  -----  False\n",
      "fire3/concat  -----  False\n",
      "pool3  -----  False\n",
      "fire4/squeeze1x1  -----  False\n",
      "fire4/relu_squeeze1x1  -----  False\n",
      "fire4/expand1x1  -----  False\n",
      "fire4/expand3x3  -----  False\n",
      "fire4/relu_expand1x1  -----  False\n",
      "fire4/relu_expand3x3  -----  False\n",
      "fire4/concat  -----  False\n",
      "fire5/squeeze1x1  -----  False\n",
      "fire5/relu_squeeze1x1  -----  False\n",
      "fire5/expand1x1  -----  False\n",
      "fire5/expand3x3  -----  False\n",
      "fire5/relu_expand1x1  -----  False\n",
      "fire5/relu_expand3x3  -----  False\n",
      "fire5/concat  -----  False\n",
      "pool5  -----  False\n",
      "fire6/squeeze1x1  -----  False\n",
      "fire6/relu_squeeze1x1  -----  False\n",
      "fire6/expand1x1  -----  False\n",
      "fire6/expand3x3  -----  False\n",
      "fire6/relu_expand1x1  -----  False\n",
      "fire6/relu_expand3x3  -----  False\n",
      "fire6/concat  -----  False\n",
      "fire7/squeeze1x1  -----  False\n",
      "fire7/relu_squeeze1x1  -----  False\n",
      "fire7/expand1x1  -----  False\n",
      "fire7/expand3x3  -----  False\n",
      "fire7/relu_expand1x1  -----  False\n",
      "fire7/relu_expand3x3  -----  False\n",
      "fire7/concat  -----  False\n",
      "fire8/squeeze1x1  -----  True\n",
      "fire8/relu_squeeze1x1  -----  True\n",
      "fire8/expand1x1  -----  True\n",
      "fire8/expand3x3  -----  True\n",
      "fire8/relu_expand1x1  -----  True\n",
      "fire8/relu_expand3x3  -----  True\n",
      "fire8/concat  -----  True\n",
      "fire9/squeeze1x1  -----  True\n",
      "fire9/relu_squeeze1x1  -----  True\n",
      "fire9/expand1x1  -----  True\n",
      "fire9/expand3x3  -----  True\n",
      "fire9/relu_expand1x1  -----  True\n",
      "fire9/relu_expand3x3  -----  True\n",
      "fire9/concat  -----  True\n",
      "drop9  -----  True\n",
      "conv10  -----  True\n",
      "relu_conv10  -----  True\n",
      "global_average_pooling2d_21  -----  True\n",
      "loss  -----  True\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 722,496\n",
      "Trainable params: 386,176\n",
      "Non-trainable params: 336,320\n",
      "__________________________________________________________________________________________________\n",
      "================================================\n",
      "Split: 4\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 12s 309us/step - loss: 2.3666 - acc: 0.1843 - val_loss: 1.9815 - val_acc: 0.3206\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 2.0363 - acc: 0.2604 - val_loss: 1.8120 - val_acc: 0.3709\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 9s 228us/step - loss: 1.9380 - acc: 0.2960 - val_loss: 1.7256 - val_acc: 0.4017\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 10s 245us/step - loss: 1.8609 - acc: 0.3272 - val_loss: 1.6527 - val_acc: 0.4136\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.7952 - acc: 0.3530 - val_loss: 1.6075 - val_acc: 0.4425\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.7545 - acc: 0.3674 - val_loss: 1.5865 - val_acc: 0.4505\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.7241 - acc: 0.3831 - val_loss: 1.5596 - val_acc: 0.4590\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.6958 - acc: 0.3954 - val_loss: 1.5564 - val_acc: 0.4561\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.6715 - acc: 0.4077 - val_loss: 1.5420 - val_acc: 0.4642\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.6406 - acc: 0.4245 - val_loss: 1.5149 - val_acc: 0.4736\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.6188 - acc: 0.4357 - val_loss: 1.4950 - val_acc: 0.4781\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.5879 - acc: 0.4446 - val_loss: 1.4858 - val_acc: 0.4834\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.5660 - acc: 0.4567 - val_loss: 1.4746 - val_acc: 0.4913\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.5460 - acc: 0.4621 - val_loss: 1.4538 - val_acc: 0.4923\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.5308 - acc: 0.4671 - val_loss: 1.4639 - val_acc: 0.4958\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.5140 - acc: 0.4765 - val_loss: 1.4496 - val_acc: 0.4995\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.4909 - acc: 0.4829 - val_loss: 1.4514 - val_acc: 0.5017\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.4833 - acc: 0.4861 - val_loss: 1.4460 - val_acc: 0.4982\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.4654 - acc: 0.4878 - val_loss: 1.4276 - val_acc: 0.5019\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.4501 - acc: 0.4980 - val_loss: 1.4253 - val_acc: 0.5053\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 9s 234us/step - loss: 1.4315 - acc: 0.5038 - val_loss: 1.4263 - val_acc: 0.5082\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 1.4205 - acc: 0.5056 - val_loss: 1.4250 - val_acc: 0.5058\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 1.4072 - acc: 0.5102 - val_loss: 1.4181 - val_acc: 0.5066\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.3925 - acc: 0.5157 - val_loss: 1.4162 - val_acc: 0.5087\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.3816 - acc: 0.5167 - val_loss: 1.4284 - val_acc: 0.5106\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.3693 - acc: 0.5234 - val_loss: 1.4208 - val_acc: 0.5103\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.3563 - acc: 0.5270 - val_loss: 1.4117 - val_acc: 0.5096\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.3461 - acc: 0.5290 - val_loss: 1.4157 - val_acc: 0.5115\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.3352 - acc: 0.5331 - val_loss: 1.4207 - val_acc: 0.5072\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 10s 241us/step - loss: 1.3226 - acc: 0.5363 - val_loss: 1.4104 - val_acc: 0.5129\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 10s 244us/step - loss: 1.3110 - acc: 0.5391 - val_loss: 1.4078 - val_acc: 0.5150\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 10s 240us/step - loss: 1.3000 - acc: 0.5456 - val_loss: 1.4070 - val_acc: 0.5148\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.2916 - acc: 0.5460 - val_loss: 1.4254 - val_acc: 0.5123\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.2837 - acc: 0.5501 - val_loss: 1.4225 - val_acc: 0.5145\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 1.2728 - acc: 0.5512 - val_loss: 1.4461 - val_acc: 0.5111\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.2607 - acc: 0.5555 - val_loss: 1.4276 - val_acc: 0.5142\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 10s 239us/step - loss: 1.2549 - acc: 0.5593 - val_loss: 1.4294 - val_acc: 0.5077\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 10s 243us/step - loss: 1.2429 - acc: 0.5623 - val_loss: 1.4394 - val_acc: 0.5162\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 9s 233us/step - loss: 1.2351 - acc: 0.5615 - val_loss: 1.4445 - val_acc: 0.5170\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.2256 - acc: 0.5671 - val_loss: 1.4299 - val_acc: 0.5168\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.2157 - acc: 0.5696 - val_loss: 1.4412 - val_acc: 0.5151\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.2086 - acc: 0.5707 - val_loss: 1.4488 - val_acc: 0.5147\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.1973 - acc: 0.5742 - val_loss: 1.4695 - val_acc: 0.5166\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.1828 - acc: 0.5774 - val_loss: 1.4657 - val_acc: 0.5178\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.1748 - acc: 0.5815 - val_loss: 1.4658 - val_acc: 0.5094\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.1680 - acc: 0.5855 - val_loss: 1.4734 - val_acc: 0.5121\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.1574 - acc: 0.5883 - val_loss: 1.4593 - val_acc: 0.5135\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 10s 242us/step - loss: 1.1498 - acc: 0.5901 - val_loss: 1.4687 - val_acc: 0.5145\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.1370 - acc: 0.5951 - val_loss: 1.4976 - val_acc: 0.5162\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 9s 229us/step - loss: 1.1323 - acc: 0.5945 - val_loss: 1.5439 - val_acc: 0.5144\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 9s 230us/step - loss: 1.1227 - acc: 0.5957 - val_loss: 1.5113 - val_acc: 0.5144\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 1.1097 - acc: 0.6012 - val_loss: 1.5171 - val_acc: 0.5117\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.0993 - acc: 0.6041 - val_loss: 1.5415 - val_acc: 0.5122\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.0972 - acc: 0.6041 - val_loss: 1.5360 - val_acc: 0.5075\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.0861 - acc: 0.6109 - val_loss: 1.5721 - val_acc: 0.5094\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.0732 - acc: 0.6137 - val_loss: 1.5569 - val_acc: 0.5065\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 9s 227us/step - loss: 1.0666 - acc: 0.6137 - val_loss: 1.5890 - val_acc: 0.5088\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 1.0590 - acc: 0.6191 - val_loss: 1.5682 - val_acc: 0.5148\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.0458 - acc: 0.6194 - val_loss: 1.5696 - val_acc: 0.5082\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.0397 - acc: 0.6254 - val_loss: 1.5931 - val_acc: 0.5062\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.0301 - acc: 0.6274 - val_loss: 1.6081 - val_acc: 0.5029\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.0223 - acc: 0.6276 - val_loss: 1.5951 - val_acc: 0.5010\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.0157 - acc: 0.6315 - val_loss: 1.6163 - val_acc: 0.5048\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 1.0082 - acc: 0.6353 - val_loss: 1.6436 - val_acc: 0.5067\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 1.0015 - acc: 0.6358 - val_loss: 1.6020 - val_acc: 0.4999\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 0.9918 - acc: 0.6425 - val_loss: 1.6603 - val_acc: 0.4966\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 9s 224us/step - loss: 0.9831 - acc: 0.6409 - val_loss: 1.7149 - val_acc: 0.5034\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.9712 - acc: 0.6477 - val_loss: 1.7023 - val_acc: 0.5033\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.9651 - acc: 0.6468 - val_loss: 1.6750 - val_acc: 0.5075\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 9s 225us/step - loss: 0.9573 - acc: 0.6507 - val_loss: 1.6660 - val_acc: 0.5061\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 9s 226us/step - loss: 0.9491 - acc: 0.6524 - val_loss: 1.7000 - val_acc: 0.5036\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 9s 231us/step - loss: 0.9425 - acc: 0.6540 - val_loss: 1.7352 - val_acc: 0.5012\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 0.9329 - acc: 0.6568 - val_loss: 1.7900 - val_acc: 0.5036\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 9s 232us/step - loss: 0.9300 - acc: 0.6591 - val_loss: 1.7687 - val_acc: 0.4997\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 10s 238us/step - loss: 0.9178 - acc: 0.6617 - val_loss: 1.7707 - val_acc: 0.5063\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 10s 255us/step - loss: 0.9126 - acc: 0.6647 - val_loss: 1.7490 - val_acc: 0.4980\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 10s 254us/step - loss: 0.9038 - acc: 0.6675 - val_loss: 1.8211 - val_acc: 0.5026\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 10s 257us/step - loss: 0.8919 - acc: 0.6688 - val_loss: 1.7912 - val_acc: 0.4924\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 0.8906 - acc: 0.6714 - val_loss: 1.8346 - val_acc: 0.4964\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 10s 248us/step - loss: 0.8818 - acc: 0.6732 - val_loss: 1.8564 - val_acc: 0.4957\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 10s 249us/step - loss: 0.8745 - acc: 0.6758 - val_loss: 1.8299 - val_acc: 0.4990\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 10s 251us/step - loss: 0.8624 - acc: 0.6810 - val_loss: 1.9275 - val_acc: 0.5007\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 10s 252us/step - loss: 0.8573 - acc: 0.6821 - val_loss: 1.9057 - val_acc: 0.4988\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 10s 259us/step - loss: 0.8529 - acc: 0.6824 - val_loss: 1.9191 - val_acc: 0.4990\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 10s 250us/step - loss: 0.8459 - acc: 0.6865 - val_loss: 1.9376 - val_acc: 0.4963\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 10s 246us/step - loss: 0.8335 - acc: 0.6879 - val_loss: 1.9467 - val_acc: 0.4910\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 10s 252us/step - loss: 0.8322 - acc: 0.6910 - val_loss: 1.9625 - val_acc: 0.4928\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 10s 251us/step - loss: 0.8268 - acc: 0.6943 - val_loss: 1.9181 - val_acc: 0.4917\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 10s 255us/step - loss: 0.8142 - acc: 0.6987 - val_loss: 1.9970 - val_acc: 0.4925\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 10s 258us/step - loss: 0.8140 - acc: 0.6976 - val_loss: 1.9662 - val_acc: 0.4889\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 10s 251us/step - loss: 0.8019 - acc: 0.7028 - val_loss: 2.0259 - val_acc: 0.4938\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 10s 253us/step - loss: 0.7985 - acc: 0.7037 - val_loss: 2.0212 - val_acc: 0.4885\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 10s 247us/step - loss: 0.7935 - acc: 0.7035 - val_loss: 2.0115 - val_acc: 0.4910\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 10s 256us/step - loss: 0.7882 - acc: 0.7057 - val_loss: 2.0200 - val_acc: 0.4905\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 10s 258us/step - loss: 0.7808 - acc: 0.7080 - val_loss: 2.0600 - val_acc: 0.4918\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 10s 262us/step - loss: 0.7755 - acc: 0.7084 - val_loss: 2.0791 - val_acc: 0.4937\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 10s 251us/step - loss: 0.7671 - acc: 0.7134 - val_loss: 2.0801 - val_acc: 0.4894\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 11s 267us/step - loss: 0.7623 - acc: 0.7137 - val_loss: 2.0910 - val_acc: 0.4933\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 11s 277us/step - loss: 0.7586 - acc: 0.7167 - val_loss: 2.0963 - val_acc: 0.4912\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 10s 262us/step - loss: 0.7550 - acc: 0.7188 - val_loss: 2.1727 - val_acc: 0.4909\n",
      "10000/10000 [==============================] - 3s 330us/step\n",
      "Validation loss: 2.172682840794325\n",
      "Validation accuracy (NORMALIZED): 0.4909000065326691\n",
      "[[2.2541904701292514, 0.48590000654011967], [2.2080171611607073, 0.4861000063717365], [2.0705572418570517, 0.49860000690817835], [2.1195410302877424, 0.49340000670403245], [2.172682840794325, 0.4909000065326691]]\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Compile model\n",
    "#=====================================\n",
    "\n",
    "#--- Compile the model\n",
    "# It means to configure the model for training.\n",
    "# Other types of optimizer:\n",
    "#    optimizers.Adam(lr=1e-3)\n",
    "\n",
    "#=====================================\n",
    "# Training model and Evaluation\n",
    "#=====================================\n",
    "\n",
    "y_train_categorical = to_categorical(y_train, num_classes=n_classes)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=n_classes)\n",
    "\n",
    "scores = []\n",
    "for i in range(folds):\n",
    "    model = get_squeezenet_ft2()    \n",
    "    \n",
    "    #--- Evaluating the model for split i\n",
    "    print(\"================================================\")\n",
    "    print(\"Split: \"+str(i))\n",
    "    print(\"Number of Epochs: \"+str(n_epochs))\n",
    "    print(\"Train shape:\",X_train[i].shape)\n",
    "    print(\"Train batch size: \"+str(train_batch_size))\n",
    "    print(\"Val batch size: \"+str(val_batch_size))\n",
    "    #print(\"Optimizer:\",opt)\n",
    "    print(\"================================================\")\n",
    "    # Training with data augmentation\n",
    "    '''\n",
    "    aug.fit(X_train[i])\n",
    "    model.fit_generator(aug.flow(X_train[i],y_train_categorical[i], batch_size=train_batch_size),\n",
    "                        steps_per_epoch=X_train.shape[1]//train_batch_size,\n",
    "                        epochs=n_epochs, \n",
    "                        verbose=1)\n",
    "    '''\n",
    "    # Training without data augmentation\n",
    "    model.fit(X_train[i],y_train_categorical[i], batch_size=train_batch_size,\n",
    "              epochs=n_epochs, \n",
    "              validation_data=(X_val[i],y_val_categorical[i]),              \n",
    "              verbose=1)\n",
    "    #--- Evaluating the model for split i\n",
    "    score = score = model.evaluate(x=X_val[i], y=y_val_categorical[i], batch_size=val_batch_size, verbose=1)\n",
    "    scores.append(score)\n",
    "    print('Validation loss:', score[0])\n",
    "    print('Validation accuracy (NORMALIZED):', score[1])\n",
    "    #model.load_weights(\"temp.h5\") #avoid overfitting\n",
    "    \n",
    "#--- Showing scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation loss: 2.1649977488458156\n",
      "Mean Validation accuracy (NORMALIZED): 0.4909800066113473\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Evaluate on validation\n",
    "#=====================================\n",
    "\n",
    "#--- The evaluation of the model \n",
    "np_aux = np.array(scores).mean(axis=0)\n",
    "\n",
    "print('Mean Validation loss:', np_aux[0])\n",
    "print('Mean Validation accuracy (NORMALIZED):', np_aux[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "# Tensorboard\n",
    "\n",
    "Tensorboard is a visualization tool for Tensorflow. Among other things, it allows us to monitor the progress of our training, plot metrics per epochs, visualize the architecture's schematics. \n",
    "\n",
    "Just like for Early Stopping, we will use the [Tensorboard callback](https://keras.io/callbacks/#tensorboard) to log the information about our training. An example of usage, would be:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Just an example, DON'T RUN! \n",
    "### You will need to change <<LOG_DIR>>\n",
    "import keras.callbacks as callbacks\n",
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./<<LOG_DIR>>\")\n",
    "model.fit(..., callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your training progresses, Keras will log the metrics (e.g., loss, accuracy) to `<<LOG_DIR>>` (**make sure `<<LOG_DIR>>` is a valid directory)**. On your terminal, you will need to run Tensorboard, assign a port and access it via browser (just like jupyter).\n",
    "\n",
    "#### ----> MAKE SURE YOU USE A DIFFERENT PORT FOR JUPYTER AND TENSORBOARD <----\n",
    "\n",
    "### Docker\n",
    "For those using docker, open a new terminal and create a new container (using the same image) running Tensorboard:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ docker run -it -p <<port_host>>:<<port_container>>\n",
    "            --volume=<<LOG_DIR>>:<<LOG_DIR>>\n",
    "            --name=<<container_name>> <<docker_image>> \n",
    "            tensorboard --logdir=<<LOG_DIR>> --port=<<port_container>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ docker run -it -p 8887:8887\n",
    "            --volume=/your/path/ml2018/:/ml2018\n",
    "            --name=mdc_container_tensorboard mdc-keras:cpu\n",
    "            tensorboard --logdir=/ml2018/logs --port=8887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After starting Tensorboard, access it via browser on `http://localhost:<<port_container>>`.\n",
    "\n",
    "### Anaconda\n",
    "$ tensorboard --logdir=<<LOG_DIR>> --port=<<port>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After starting Tensorboard, access it via browser on `http://localhost:<<port>>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "\n",
    "# Fine-tuning all layers\n",
    "\n",
    "What if we fine-tune all layers of SqueezeNet?\n",
    "<img src=\"unfrozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_squeezenet_ft3():\n",
    "    squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "    for layer in squeezeNetModel.layers:\n",
    "        layer.trainable = True       #by default they are all trainable, but just for clarification\n",
    "\n",
    "    #=====================================\n",
    "    # Add new classification layers\n",
    "    #=====================================\n",
    "\n",
    "    #--- Removing layers until drop 9\n",
    "    squeezeNetModel.layers.pop() #Convolution2D\n",
    "    squeezeNetModel.layers.pop() #Activation ReLU\n",
    "    squeezeNetModel.layers.pop() #Global Avg Pool\n",
    "    squeezeNetModel.layers.pop() #Activation Softmax\n",
    "\n",
    "    #--- Adding classification layer for 10 classes\n",
    "    out = Convolution2D(n_classes, (1, 1), padding='valid', name='conv10')(squeezeNetModel.layers[-1].output)\n",
    "    out = Activation('relu', name='relu_conv10')(out)\n",
    "\n",
    "    out = GlobalAveragePooling2D()(out)\n",
    "    out = Activation('softmax', name='loss')(out)\n",
    "\n",
    "    #=====================================\n",
    "    # New Model\n",
    "    #=====================================\n",
    "    model = Model(squeezeNetModel.inputs, out, name='squeezenet_new')\n",
    "    opt = optimizer=optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)#SGD(lr=learning_rate)\n",
    "    print(\"--- Compiling model\")\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing tensorboard\n",
      "Log Dir:  logs/1542573239.299271\n",
      "--- Start training\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 0\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 20s 490us/step - loss: 2.1825 - acc: 0.2348 - val_loss: 1.7779 - val_acc: 0.4526\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 19s 466us/step - loss: 1.5964 - acc: 0.4753 - val_loss: 1.2177 - val_acc: 0.5964\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 19s 484us/step - loss: 1.2681 - acc: 0.5876 - val_loss: 1.1004 - val_acc: 0.6428\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 19s 468us/step - loss: 1.1099 - acc: 0.6419 - val_loss: 1.0106 - val_acc: 0.6652\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 19s 470us/step - loss: 1.0089 - acc: 0.6753 - val_loss: 0.9959 - val_acc: 0.6766\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 19s 480us/step - loss: 0.9221 - acc: 0.7038 - val_loss: 0.9386 - val_acc: 0.6949\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 19s 464us/step - loss: 0.8499 - acc: 0.7273 - val_loss: 0.9083 - val_acc: 0.7076\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 19s 469us/step - loss: 0.7985 - acc: 0.7446 - val_loss: 0.8989 - val_acc: 0.7103\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 19s 471us/step - loss: 0.7467 - acc: 0.7599 - val_loss: 0.8816 - val_acc: 0.7168\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 19s 474us/step - loss: 0.6970 - acc: 0.7738 - val_loss: 0.8598 - val_acc: 0.7187\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 20s 490us/step - loss: 0.6606 - acc: 0.7844 - val_loss: 0.8653 - val_acc: 0.7260\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 19s 473us/step - loss: 0.6192 - acc: 0.7967 - val_loss: 0.9236 - val_acc: 0.7261\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 19s 469us/step - loss: 0.5795 - acc: 0.8091 - val_loss: 0.8956 - val_acc: 0.7362\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 19s 466us/step - loss: 0.5475 - acc: 0.8202 - val_loss: 0.9562 - val_acc: 0.7300\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 19s 464us/step - loss: 0.5201 - acc: 0.8304 - val_loss: 0.9224 - val_acc: 0.7324\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 19s 483us/step - loss: 0.4822 - acc: 0.8411 - val_loss: 0.9609 - val_acc: 0.7375\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 19s 474us/step - loss: 0.4552 - acc: 0.8499 - val_loss: 0.9260 - val_acc: 0.7378\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 18s 462us/step - loss: 0.4281 - acc: 0.8593 - val_loss: 0.9809 - val_acc: 0.7331\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 19s 471us/step - loss: 0.4031 - acc: 0.8672 - val_loss: 0.9944 - val_acc: 0.7427\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 19s 464us/step - loss: 0.3771 - acc: 0.8729 - val_loss: 1.0667 - val_acc: 0.7312\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 19s 479us/step - loss: 0.3608 - acc: 0.8795 - val_loss: 1.0384 - val_acc: 0.7407\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 20s 488us/step - loss: 0.3401 - acc: 0.8852 - val_loss: 1.0632 - val_acc: 0.7398\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 20s 489us/step - loss: 0.3206 - acc: 0.8933 - val_loss: 1.0833 - val_acc: 0.7357\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 19s 485us/step - loss: 0.3002 - acc: 0.8974 - val_loss: 1.1461 - val_acc: 0.7360\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 19s 472us/step - loss: 0.2899 - acc: 0.9026 - val_loss: 1.1203 - val_acc: 0.7392\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 19s 479us/step - loss: 0.2763 - acc: 0.9074 - val_loss: 1.2025 - val_acc: 0.7408\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 19s 465us/step - loss: 0.2594 - acc: 0.9130 - val_loss: 1.2290 - val_acc: 0.7374\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.2485 - acc: 0.9172 - val_loss: 1.2816 - val_acc: 0.7342\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 19s 477us/step - loss: 0.2339 - acc: 0.9200 - val_loss: 1.2863 - val_acc: 0.7389\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 18s 456us/step - loss: 0.2217 - acc: 0.9253 - val_loss: 1.4659 - val_acc: 0.7303\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 19s 475us/step - loss: 0.2195 - acc: 0.9261 - val_loss: 1.4731 - val_acc: 0.7348\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 20s 502us/step - loss: 0.2105 - acc: 0.9304 - val_loss: 1.4043 - val_acc: 0.7389\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 19s 476us/step - loss: 0.1986 - acc: 0.9344 - val_loss: 1.4303 - val_acc: 0.7442\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 19s 470us/step - loss: 0.1919 - acc: 0.9370 - val_loss: 1.4206 - val_acc: 0.7427\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 19s 486us/step - loss: 0.1795 - acc: 0.9396 - val_loss: 1.4589 - val_acc: 0.7405\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.1825 - acc: 0.9403 - val_loss: 1.4935 - val_acc: 0.7295\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 19s 474us/step - loss: 0.1666 - acc: 0.9446 - val_loss: 1.4390 - val_acc: 0.7413\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 19s 478us/step - loss: 0.1715 - acc: 0.9441 - val_loss: 1.5223 - val_acc: 0.7374\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 19s 467us/step - loss: 0.1551 - acc: 0.9508 - val_loss: 1.3960 - val_acc: 0.7389\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 19s 464us/step - loss: 0.1545 - acc: 0.9510 - val_loss: 1.5067 - val_acc: 0.7382\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 18s 455us/step - loss: 0.1484 - acc: 0.9527 - val_loss: 1.5673 - val_acc: 0.7321\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.1449 - acc: 0.9532 - val_loss: 1.5692 - val_acc: 0.7378\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 19s 470us/step - loss: 0.1410 - acc: 0.9544 - val_loss: 1.5068 - val_acc: 0.7363\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 19s 472us/step - loss: 0.1335 - acc: 0.9571 - val_loss: 1.5435 - val_acc: 0.7422\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 18s 462us/step - loss: 0.1262 - acc: 0.9603 - val_loss: 1.4632 - val_acc: 0.7375\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 19s 464us/step - loss: 0.1262 - acc: 0.9599 - val_loss: 1.7083 - val_acc: 0.7300\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.1242 - acc: 0.9608 - val_loss: 1.7148 - val_acc: 0.7375\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 17s 422us/step - loss: 0.1236 - acc: 0.9613 - val_loss: 1.4891 - val_acc: 0.7285\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 16s 395us/step - loss: 0.1153 - acc: 0.9627 - val_loss: 1.5786 - val_acc: 0.7332\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 17s 431us/step - loss: 0.1092 - acc: 0.9646 - val_loss: 1.6296 - val_acc: 0.7336\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.1144 - acc: 0.9645 - val_loss: 1.6535 - val_acc: 0.7428\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 16s 403us/step - loss: 0.1144 - acc: 0.9646 - val_loss: 1.7016 - val_acc: 0.7350\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 17s 420us/step - loss: 0.1034 - acc: 0.9676 - val_loss: 1.6314 - val_acc: 0.7394\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 0.1058 - acc: 0.9669 - val_loss: 1.5074 - val_acc: 0.7333\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.0996 - acc: 0.9686 - val_loss: 1.7612 - val_acc: 0.7376\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0985 - acc: 0.9702 - val_loss: 1.7283 - val_acc: 0.7365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0984 - acc: 0.9692 - val_loss: 1.6634 - val_acc: 0.7328\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.1000 - acc: 0.9683 - val_loss: 1.6927 - val_acc: 0.7294\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 19s 469us/step - loss: 0.0999 - acc: 0.9681 - val_loss: 1.7942 - val_acc: 0.7334\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0865 - acc: 0.9736 - val_loss: 1.7308 - val_acc: 0.7399\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 17s 437us/step - loss: 0.0847 - acc: 0.9725 - val_loss: 1.8836 - val_acc: 0.7303\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.0876 - acc: 0.9729 - val_loss: 1.7918 - val_acc: 0.7342\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.0864 - acc: 0.9738 - val_loss: 1.7927 - val_acc: 0.7374\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0892 - acc: 0.9726 - val_loss: 1.7962 - val_acc: 0.7390\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.0816 - acc: 0.9743 - val_loss: 1.8237 - val_acc: 0.7430\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0723 - acc: 0.9765 - val_loss: 1.6745 - val_acc: 0.7383\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0788 - acc: 0.9749 - val_loss: 1.8164 - val_acc: 0.7314\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 19s 463us/step - loss: 0.0797 - acc: 0.9761 - val_loss: 1.8926 - val_acc: 0.7382\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 17s 436us/step - loss: 0.0813 - acc: 0.9758 - val_loss: 1.9050 - val_acc: 0.7367\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 19s 469us/step - loss: 0.0717 - acc: 0.9777 - val_loss: 1.8128 - val_acc: 0.7380\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 19s 466us/step - loss: 0.0729 - acc: 0.9777 - val_loss: 1.9910 - val_acc: 0.7359\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.0722 - acc: 0.9777 - val_loss: 2.0378 - val_acc: 0.7370\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 17s 433us/step - loss: 0.0801 - acc: 0.9755 - val_loss: 1.7937 - val_acc: 0.7347\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0679 - acc: 0.9782 - val_loss: 1.9036 - val_acc: 0.7318\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0710 - acc: 0.9779 - val_loss: 1.8707 - val_acc: 0.7362\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 17s 432us/step - loss: 0.0643 - acc: 0.9803 - val_loss: 1.9411 - val_acc: 0.7291\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 19s 473us/step - loss: 0.0632 - acc: 0.9808 - val_loss: 1.9905 - val_acc: 0.7326\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 19s 477us/step - loss: 0.0653 - acc: 0.9800 - val_loss: 1.9079 - val_acc: 0.7368\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 19s 463us/step - loss: 0.0637 - acc: 0.9801 - val_loss: 1.9391 - val_acc: 0.7399\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 19s 475us/step - loss: 0.0724 - acc: 0.9774 - val_loss: 1.9831 - val_acc: 0.7379\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.0588 - acc: 0.9819 - val_loss: 2.0271 - val_acc: 0.7326\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0685 - acc: 0.9788 - val_loss: 1.9402 - val_acc: 0.7444\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.0590 - acc: 0.9825 - val_loss: 1.9534 - val_acc: 0.7384\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 19s 474us/step - loss: 0.0620 - acc: 0.9813 - val_loss: 1.8266 - val_acc: 0.7422\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 19s 470us/step - loss: 0.0583 - acc: 0.9819 - val_loss: 1.9654 - val_acc: 0.7348\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 19s 485us/step - loss: 0.0619 - acc: 0.9809 - val_loss: 1.8346 - val_acc: 0.7356\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 18s 454us/step - loss: 0.0605 - acc: 0.9812 - val_loss: 1.8632 - val_acc: 0.7354\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 20s 492us/step - loss: 0.0547 - acc: 0.9827 - val_loss: 1.9822 - val_acc: 0.7339\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 19s 473us/step - loss: 0.0605 - acc: 0.9819 - val_loss: 2.0560 - val_acc: 0.7361\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.0585 - acc: 0.9818 - val_loss: 1.7790 - val_acc: 0.7341\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 18s 453us/step - loss: 0.0528 - acc: 0.9844 - val_loss: 2.0830 - val_acc: 0.7246\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 19s 464us/step - loss: 0.0603 - acc: 0.9820 - val_loss: 2.0056 - val_acc: 0.7375\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 18s 453us/step - loss: 0.0535 - acc: 0.9838 - val_loss: 1.9466 - val_acc: 0.7380\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 18s 462us/step - loss: 0.0551 - acc: 0.9833 - val_loss: 2.0698 - val_acc: 0.7408\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 19s 471us/step - loss: 0.0601 - acc: 0.9821 - val_loss: 1.9284 - val_acc: 0.7412\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 19s 470us/step - loss: 0.0522 - acc: 0.9842 - val_loss: 1.9099 - val_acc: 0.7294\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.0588 - acc: 0.9834 - val_loss: 1.8778 - val_acc: 0.7418\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 19s 469us/step - loss: 0.0563 - acc: 0.9826 - val_loss: 1.9153 - val_acc: 0.7401\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 19s 463us/step - loss: 0.0486 - acc: 0.9851 - val_loss: 2.0382 - val_acc: 0.7314\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 19s 465us/step - loss: 0.0593 - acc: 0.9827 - val_loss: 1.8518 - val_acc: 0.7349\n",
      "10000/10000 [==============================] - 3s 317us/step\n",
      "Validation loss: 1.8517724102961868\n",
      "Validation accuracy (NORMALIZED): 0.7348999998271465\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 1\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 20s 509us/step - loss: 2.2205 - acc: 0.1938 - val_loss: 1.7914 - val_acc: 0.3903\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 19s 483us/step - loss: 1.6897 - acc: 0.3929 - val_loss: 1.3130 - val_acc: 0.5250\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 20s 491us/step - loss: 1.3962 - acc: 0.5247 - val_loss: 1.1787 - val_acc: 0.6163\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 19s 468us/step - loss: 1.1970 - acc: 0.6086 - val_loss: 1.0464 - val_acc: 0.6530\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 19s 478us/step - loss: 1.0621 - acc: 0.6595 - val_loss: 1.0267 - val_acc: 0.6606\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 20s 505us/step - loss: 0.9694 - acc: 0.6882 - val_loss: 0.9991 - val_acc: 0.6761\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 19s 487us/step - loss: 0.8951 - acc: 0.7173 - val_loss: 0.9275 - val_acc: 0.6889\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 20s 495us/step - loss: 0.8295 - acc: 0.7336 - val_loss: 0.8866 - val_acc: 0.7102\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 19s 480us/step - loss: 0.7745 - acc: 0.7490 - val_loss: 0.9222 - val_acc: 0.7091\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 19s 479us/step - loss: 0.7188 - acc: 0.7647 - val_loss: 0.8920 - val_acc: 0.7204\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 20s 511us/step - loss: 0.6808 - acc: 0.7773 - val_loss: 0.9101 - val_acc: 0.7208\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 19s 473us/step - loss: 0.6475 - acc: 0.7853 - val_loss: 0.8967 - val_acc: 0.7262\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 19s 464us/step - loss: 0.6019 - acc: 0.8001 - val_loss: 0.8870 - val_acc: 0.7345\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 19s 465us/step - loss: 0.5730 - acc: 0.8108 - val_loss: 0.8826 - val_acc: 0.7319\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 19s 473us/step - loss: 0.5365 - acc: 0.8229 - val_loss: 0.9049 - val_acc: 0.7334\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 19s 472us/step - loss: 0.5065 - acc: 0.8302 - val_loss: 0.9029 - val_acc: 0.7378\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 19s 465us/step - loss: 0.4778 - acc: 0.8404 - val_loss: 0.9551 - val_acc: 0.7366\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.4523 - acc: 0.8506 - val_loss: 1.0326 - val_acc: 0.7371\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 18s 459us/step - loss: 0.4303 - acc: 0.8571 - val_loss: 0.9783 - val_acc: 0.7383\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 18s 458us/step - loss: 0.3990 - acc: 0.8652 - val_loss: 1.0098 - val_acc: 0.7325\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.3757 - acc: 0.8726 - val_loss: 1.0590 - val_acc: 0.7296\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 18s 462us/step - loss: 0.3589 - acc: 0.8799 - val_loss: 1.0697 - val_acc: 0.7295\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 0.3374 - acc: 0.8862 - val_loss: 1.0142 - val_acc: 0.7389\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.3232 - acc: 0.8913 - val_loss: 1.2299 - val_acc: 0.7371\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 19s 473us/step - loss: 0.3056 - acc: 0.8994 - val_loss: 1.1845 - val_acc: 0.7392\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 18s 461us/step - loss: 0.2902 - acc: 0.9026 - val_loss: 1.2362 - val_acc: 0.7352\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 19s 476us/step - loss: 0.2706 - acc: 0.9104 - val_loss: 1.2718 - val_acc: 0.7347\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 19s 468us/step - loss: 0.2559 - acc: 0.9142 - val_loss: 1.2933 - val_acc: 0.7399\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 19s 471us/step - loss: 0.2544 - acc: 0.9152 - val_loss: 1.2835 - val_acc: 0.7399\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 19s 481us/step - loss: 0.2354 - acc: 0.9199 - val_loss: 1.1551 - val_acc: 0.7265\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 20s 508us/step - loss: 0.2250 - acc: 0.9247 - val_loss: 1.3641 - val_acc: 0.7340\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 20s 498us/step - loss: 0.2137 - acc: 0.9282 - val_loss: 1.3774 - val_acc: 0.7350\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 20s 498us/step - loss: 0.2039 - acc: 0.9322 - val_loss: 1.4139 - val_acc: 0.7331\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 21s 514us/step - loss: 0.2002 - acc: 0.9339 - val_loss: 1.3761 - val_acc: 0.7288\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 20s 492us/step - loss: 0.1837 - acc: 0.9398 - val_loss: 1.4890 - val_acc: 0.7357\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 20s 492us/step - loss: 0.1774 - acc: 0.9415 - val_loss: 1.6149 - val_acc: 0.7407\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 19s 467us/step - loss: 0.1784 - acc: 0.9424 - val_loss: 1.4171 - val_acc: 0.7369\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 20s 499us/step - loss: 0.1729 - acc: 0.9443 - val_loss: 1.4321 - val_acc: 0.7283\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 19s 480us/step - loss: 0.1598 - acc: 0.9478 - val_loss: 1.5125 - val_acc: 0.7348\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 20s 496us/step - loss: 0.1565 - acc: 0.9490 - val_loss: 1.4916 - val_acc: 0.7326\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 20s 499us/step - loss: 0.1439 - acc: 0.9530 - val_loss: 1.5319 - val_acc: 0.7279\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 21s 518us/step - loss: 0.1454 - acc: 0.9526 - val_loss: 1.5845 - val_acc: 0.7344\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 20s 497us/step - loss: 0.1327 - acc: 0.9577 - val_loss: 1.7969 - val_acc: 0.7354\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 20s 505us/step - loss: 0.1296 - acc: 0.9569 - val_loss: 1.6946 - val_acc: 0.7339\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 20s 495us/step - loss: 0.1369 - acc: 0.9582 - val_loss: 1.4924 - val_acc: 0.7316\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 21s 523us/step - loss: 0.1193 - acc: 0.9609 - val_loss: 1.5944 - val_acc: 0.7324\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 20s 503us/step - loss: 0.1177 - acc: 0.9622 - val_loss: 1.6004 - val_acc: 0.7279\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 19s 480us/step - loss: 0.1197 - acc: 0.9615 - val_loss: 1.6462 - val_acc: 0.7377\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 19s 487us/step - loss: 0.1130 - acc: 0.9643 - val_loss: 1.6737 - val_acc: 0.7348\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 19s 481us/step - loss: 0.1123 - acc: 0.9642 - val_loss: 1.6855 - val_acc: 0.7332\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 19s 476us/step - loss: 0.1145 - acc: 0.9638 - val_loss: 1.7866 - val_acc: 0.7324\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 19s 483us/step - loss: 0.1063 - acc: 0.9662 - val_loss: 1.7350 - val_acc: 0.7311\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 20s 498us/step - loss: 0.1088 - acc: 0.9656 - val_loss: 1.6881 - val_acc: 0.7378\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 19s 465us/step - loss: 0.0966 - acc: 0.9697 - val_loss: 1.8312 - val_acc: 0.7372\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 17s 430us/step - loss: 0.1074 - acc: 0.9665 - val_loss: 1.7188 - val_acc: 0.7355\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 17s 429us/step - loss: 0.0934 - acc: 0.9714 - val_loss: 1.7336 - val_acc: 0.7315\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 17s 428us/step - loss: 0.0958 - acc: 0.9696 - val_loss: 1.8098 - val_acc: 0.7282\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 17s 431us/step - loss: 0.0879 - acc: 0.9733 - val_loss: 1.8939 - val_acc: 0.7391\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0875 - acc: 0.9722 - val_loss: 1.8434 - val_acc: 0.7440\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 19s 483us/step - loss: 0.0951 - acc: 0.9710 - val_loss: 1.7199 - val_acc: 0.7327\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 22s 542us/step - loss: 0.0874 - acc: 0.9733 - val_loss: 1.8068 - val_acc: 0.7327\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 20s 490us/step - loss: 0.0853 - acc: 0.9736 - val_loss: 1.9860 - val_acc: 0.7279\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 19s 482us/step - loss: 0.0838 - acc: 0.9742 - val_loss: 1.7696 - val_acc: 0.7360\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 19s 477us/step - loss: 0.0829 - acc: 0.9743 - val_loss: 1.8193 - val_acc: 0.7380\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 19s 484us/step - loss: 0.0793 - acc: 0.9756 - val_loss: 1.7520 - val_acc: 0.7384\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 20s 493us/step - loss: 0.0785 - acc: 0.9759 - val_loss: 1.8116 - val_acc: 0.7350\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 20s 494us/step - loss: 0.0858 - acc: 0.9738 - val_loss: 1.8343 - val_acc: 0.7382\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 19s 482us/step - loss: 0.0716 - acc: 0.9778 - val_loss: 1.7854 - val_acc: 0.7332\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 19s 481us/step - loss: 0.0780 - acc: 0.9763 - val_loss: 1.8427 - val_acc: 0.7383\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 19s 477us/step - loss: 0.0729 - acc: 0.9775 - val_loss: 1.8418 - val_acc: 0.7365\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 19s 467us/step - loss: 0.0728 - acc: 0.9775 - val_loss: 1.8833 - val_acc: 0.7340\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 20s 490us/step - loss: 0.0730 - acc: 0.9775 - val_loss: 1.9590 - val_acc: 0.7340\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 19s 481us/step - loss: 0.0767 - acc: 0.9768 - val_loss: 1.8879 - val_acc: 0.7322\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 19s 481us/step - loss: 0.0731 - acc: 0.9781 - val_loss: 1.7540 - val_acc: 0.7378\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 19s 480us/step - loss: 0.0721 - acc: 0.9786 - val_loss: 1.8247 - val_acc: 0.7436\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 19s 484us/step - loss: 0.0652 - acc: 0.9803 - val_loss: 1.7527 - val_acc: 0.7384\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 19s 486us/step - loss: 0.0618 - acc: 0.9810 - val_loss: 1.9459 - val_acc: 0.7367\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 20s 493us/step - loss: 0.0686 - acc: 0.9787 - val_loss: 1.9123 - val_acc: 0.7357\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 20s 499us/step - loss: 0.0683 - acc: 0.9798 - val_loss: 1.6415 - val_acc: 0.7321\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 20s 499us/step - loss: 0.0725 - acc: 0.9786 - val_loss: 1.8428 - val_acc: 0.7361\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 20s 497us/step - loss: 0.0630 - acc: 0.9813 - val_loss: 1.9499 - val_acc: 0.7182\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 20s 498us/step - loss: 0.0645 - acc: 0.9808 - val_loss: 1.9561 - val_acc: 0.7344\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 19s 487us/step - loss: 0.0650 - acc: 0.9797 - val_loss: 1.8503 - val_acc: 0.7382\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 19s 479us/step - loss: 0.0624 - acc: 0.9815 - val_loss: 1.8284 - val_acc: 0.7417\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 19s 478us/step - loss: 0.0544 - acc: 0.9833 - val_loss: 2.0643 - val_acc: 0.7314\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 19s 472us/step - loss: 0.0664 - acc: 0.9805 - val_loss: 1.8425 - val_acc: 0.7380\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 19s 474us/step - loss: 0.0529 - acc: 0.9836 - val_loss: 2.0846 - val_acc: 0.7345\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 19s 477us/step - loss: 0.0607 - acc: 0.9811 - val_loss: 1.8408 - val_acc: 0.7366\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 19s 473us/step - loss: 0.0510 - acc: 0.9843 - val_loss: 2.1013 - val_acc: 0.7400\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 20s 488us/step - loss: 0.0585 - acc: 0.9821 - val_loss: 1.9800 - val_acc: 0.7402\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 19s 487us/step - loss: 0.0555 - acc: 0.9833 - val_loss: 2.0038 - val_acc: 0.7405\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 19s 465us/step - loss: 0.0597 - acc: 0.9820 - val_loss: 2.0478 - val_acc: 0.7396\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 19s 472us/step - loss: 0.0524 - acc: 0.9835 - val_loss: 1.9836 - val_acc: 0.7371\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 19s 468us/step - loss: 0.0578 - acc: 0.9820 - val_loss: 2.0513 - val_acc: 0.7379\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 18s 444us/step - loss: 0.0556 - acc: 0.9831 - val_loss: 1.9923 - val_acc: 0.7395\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0486 - acc: 0.9850 - val_loss: 2.0732 - val_acc: 0.7383\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0602 - acc: 0.9826 - val_loss: 2.0393 - val_acc: 0.7417\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0531 - acc: 0.9841 - val_loss: 1.9337 - val_acc: 0.7389\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0580 - acc: 0.9828 - val_loss: 2.0793 - val_acc: 0.7359\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0569 - acc: 0.9828 - val_loss: 1.9474 - val_acc: 0.7415\n",
      "10000/10000 [==============================] - 3s 307us/step\n",
      "Validation loss: 1.9473785817496638\n",
      "Validation accuracy (NORMALIZED): 0.7414999999403954\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 2\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 19s 478us/step - loss: 2.2013 - acc: 0.2217 - val_loss: 1.8562 - val_acc: 0.4021\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 1.8588 - acc: 0.3553 - val_loss: 1.5308 - val_acc: 0.4842\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 1.5218 - acc: 0.4927 - val_loss: 1.1753 - val_acc: 0.6169\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 1.2032 - acc: 0.6240 - val_loss: 1.0008 - val_acc: 0.6700\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 1.0473 - acc: 0.6691 - val_loss: 1.0084 - val_acc: 0.6774\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.9475 - acc: 0.7026 - val_loss: 0.9435 - val_acc: 0.6916\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.8660 - acc: 0.7240 - val_loss: 0.9068 - val_acc: 0.7063\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.8011 - acc: 0.7442 - val_loss: 0.8732 - val_acc: 0.7204\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.7544 - acc: 0.7602 - val_loss: 0.9064 - val_acc: 0.7118\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 18s 446us/step - loss: 0.7017 - acc: 0.7741 - val_loss: 0.8305 - val_acc: 0.7313\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 18s 443us/step - loss: 0.6641 - acc: 0.7839 - val_loss: 0.8424 - val_acc: 0.7310\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.6168 - acc: 0.7988 - val_loss: 0.8328 - val_acc: 0.7383\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 17s 423us/step - loss: 0.5847 - acc: 0.8085 - val_loss: 0.8297 - val_acc: 0.7410\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.5503 - acc: 0.8176 - val_loss: 0.8542 - val_acc: 0.7352\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.5203 - acc: 0.8286 - val_loss: 0.9458 - val_acc: 0.7359\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.4838 - acc: 0.8389 - val_loss: 0.8776 - val_acc: 0.7421\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 17s 424us/step - loss: 0.4544 - acc: 0.8484 - val_loss: 0.9532 - val_acc: 0.7409\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 17s 424us/step - loss: 0.4271 - acc: 0.8565 - val_loss: 0.9641 - val_acc: 0.7391\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.4050 - acc: 0.8647 - val_loss: 1.0371 - val_acc: 0.7433\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 17s 425us/step - loss: 0.3743 - acc: 0.8742 - val_loss: 1.0092 - val_acc: 0.7416\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 17s 423us/step - loss: 0.3571 - acc: 0.8793 - val_loss: 1.0097 - val_acc: 0.7383\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 17s 424us/step - loss: 0.3370 - acc: 0.8868 - val_loss: 1.0676 - val_acc: 0.7287\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 17s 427us/step - loss: 0.3187 - acc: 0.8932 - val_loss: 1.0170 - val_acc: 0.7397\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 0.3014 - acc: 0.9006 - val_loss: 1.0702 - val_acc: 0.7416\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.2816 - acc: 0.9051 - val_loss: 1.1623 - val_acc: 0.7438\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.2664 - acc: 0.9102 - val_loss: 1.1818 - val_acc: 0.7442\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 17s 420us/step - loss: 0.2510 - acc: 0.9153 - val_loss: 1.2189 - val_acc: 0.7320\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.2461 - acc: 0.9190 - val_loss: 1.2885 - val_acc: 0.7428\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.2317 - acc: 0.9218 - val_loss: 1.2730 - val_acc: 0.7432\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 17s 418us/step - loss: 0.2186 - acc: 0.9270 - val_loss: 1.3203 - val_acc: 0.7395\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.2134 - acc: 0.9289 - val_loss: 1.2774 - val_acc: 0.7437\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.1940 - acc: 0.9351 - val_loss: 1.4132 - val_acc: 0.7416\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.1960 - acc: 0.9337 - val_loss: 1.4575 - val_acc: 0.7385\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.1815 - acc: 0.9389 - val_loss: 1.4294 - val_acc: 0.7395\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.1699 - acc: 0.9446 - val_loss: 1.4173 - val_acc: 0.7375\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.1744 - acc: 0.9422 - val_loss: 1.3965 - val_acc: 0.7372\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.1564 - acc: 0.9490 - val_loss: 1.4326 - val_acc: 0.7376\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.1612 - acc: 0.9461 - val_loss: 1.5419 - val_acc: 0.7391\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.1470 - acc: 0.9520 - val_loss: 1.4686 - val_acc: 0.7292\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.1440 - acc: 0.9528 - val_loss: 1.5340 - val_acc: 0.7371\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 17s 420us/step - loss: 0.1393 - acc: 0.9551 - val_loss: 1.5183 - val_acc: 0.7394\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 17s 418us/step - loss: 0.1343 - acc: 0.9562 - val_loss: 1.5649 - val_acc: 0.7348\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.1259 - acc: 0.9590 - val_loss: 1.6232 - val_acc: 0.7355\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.1262 - acc: 0.9592 - val_loss: 1.5246 - val_acc: 0.7371\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.1206 - acc: 0.9619 - val_loss: 1.7410 - val_acc: 0.7318\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 17s 420us/step - loss: 0.1252 - acc: 0.9598 - val_loss: 1.5890 - val_acc: 0.7314\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.1099 - acc: 0.9660 - val_loss: 1.6449 - val_acc: 0.7352\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.1104 - acc: 0.9649 - val_loss: 1.7621 - val_acc: 0.7328\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.1147 - acc: 0.9638 - val_loss: 1.6262 - val_acc: 0.7338\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.1066 - acc: 0.9670 - val_loss: 1.6636 - val_acc: 0.7336\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.1019 - acc: 0.9685 - val_loss: 1.5427 - val_acc: 0.7330\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 17s 418us/step - loss: 0.0978 - acc: 0.9694 - val_loss: 1.7380 - val_acc: 0.7421\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.1004 - acc: 0.9695 - val_loss: 1.7457 - val_acc: 0.7368\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 17s 418us/step - loss: 0.0928 - acc: 0.9702 - val_loss: 1.7633 - val_acc: 0.7386\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.0899 - acc: 0.9716 - val_loss: 1.8639 - val_acc: 0.7245\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 17s 422us/step - loss: 0.1042 - acc: 0.9678 - val_loss: 1.7022 - val_acc: 0.7357\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 17s 421us/step - loss: 0.0870 - acc: 0.9729 - val_loss: 1.8296 - val_acc: 0.7400\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.0866 - acc: 0.9726 - val_loss: 1.6712 - val_acc: 0.7406\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.0867 - acc: 0.9733 - val_loss: 1.8917 - val_acc: 0.7372\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 17s 421us/step - loss: 0.0902 - acc: 0.9718 - val_loss: 1.7383 - val_acc: 0.7403\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 17s 418us/step - loss: 0.0726 - acc: 0.9779 - val_loss: 1.8178 - val_acc: 0.7420\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.0737 - acc: 0.9770 - val_loss: 1.8804 - val_acc: 0.7404\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 17s 421us/step - loss: 0.0849 - acc: 0.9743 - val_loss: 1.8407 - val_acc: 0.7371\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.0731 - acc: 0.9769 - val_loss: 1.8316 - val_acc: 0.7368\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 17s 418us/step - loss: 0.0764 - acc: 0.9757 - val_loss: 1.8860 - val_acc: 0.7324\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.0743 - acc: 0.9775 - val_loss: 1.9319 - val_acc: 0.7391\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 17s 418us/step - loss: 0.0772 - acc: 0.9754 - val_loss: 1.7980 - val_acc: 0.7383\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 17s 420us/step - loss: 0.0731 - acc: 0.9776 - val_loss: 1.8885 - val_acc: 0.7316\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 17s 418us/step - loss: 0.0725 - acc: 0.9782 - val_loss: 1.8279 - val_acc: 0.7320\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.0698 - acc: 0.9781 - val_loss: 1.9984 - val_acc: 0.7400\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.0647 - acc: 0.9798 - val_loss: 2.0736 - val_acc: 0.7345\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 17s 422us/step - loss: 0.0712 - acc: 0.9782 - val_loss: 1.9022 - val_acc: 0.7298\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 17s 420us/step - loss: 0.0713 - acc: 0.9781 - val_loss: 1.8181 - val_acc: 0.7260\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.0624 - acc: 0.9803 - val_loss: 1.9974 - val_acc: 0.7378\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 17s 420us/step - loss: 0.0689 - acc: 0.9793 - val_loss: 1.6960 - val_acc: 0.7392\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.0678 - acc: 0.9788 - val_loss: 1.8155 - val_acc: 0.7318\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 17s 418us/step - loss: 0.0645 - acc: 0.9798 - val_loss: 1.6962 - val_acc: 0.7384\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 17s 420us/step - loss: 0.0632 - acc: 0.9807 - val_loss: 1.9981 - val_acc: 0.7320\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 17s 418us/step - loss: 0.0599 - acc: 0.9817 - val_loss: 1.9796 - val_acc: 0.7356\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 17s 418us/step - loss: 0.0598 - acc: 0.9817 - val_loss: 2.0037 - val_acc: 0.7352\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.0672 - acc: 0.9789 - val_loss: 1.7903 - val_acc: 0.7375\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 17s 421us/step - loss: 0.0568 - acc: 0.9830 - val_loss: 2.0555 - val_acc: 0.7359\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.0652 - acc: 0.9797 - val_loss: 1.9201 - val_acc: 0.7305\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.0557 - acc: 0.9836 - val_loss: 1.8560 - val_acc: 0.7317\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.0601 - acc: 0.9821 - val_loss: 1.9684 - val_acc: 0.7323\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.0598 - acc: 0.9813 - val_loss: 1.7867 - val_acc: 0.7336\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 0.0601 - acc: 0.9822 - val_loss: 1.9422 - val_acc: 0.7400\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.0554 - acc: 0.9825 - val_loss: 1.8278 - val_acc: 0.7313\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.0536 - acc: 0.9835 - val_loss: 1.7275 - val_acc: 0.7244\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.0521 - acc: 0.9832 - val_loss: 1.9833 - val_acc: 0.7383\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.0565 - acc: 0.9821 - val_loss: 1.8248 - val_acc: 0.7363\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.0522 - acc: 0.9846 - val_loss: 1.9778 - val_acc: 0.7349\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.0599 - acc: 0.9827 - val_loss: 1.8460 - val_acc: 0.7360\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.0541 - acc: 0.9837 - val_loss: 1.8631 - val_acc: 0.7446\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 17s 417us/step - loss: 0.0495 - acc: 0.9848 - val_loss: 2.1145 - val_acc: 0.7330\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 17s 414us/step - loss: 0.0505 - acc: 0.9844 - val_loss: 1.8910 - val_acc: 0.7404\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 17s 415us/step - loss: 0.0528 - acc: 0.9844 - val_loss: 1.9352 - val_acc: 0.7429\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 17s 420us/step - loss: 0.0515 - acc: 0.9841 - val_loss: 1.8226 - val_acc: 0.7432\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 17s 419us/step - loss: 0.0576 - acc: 0.9824 - val_loss: 1.9373 - val_acc: 0.7388\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 17s 416us/step - loss: 0.0493 - acc: 0.9841 - val_loss: 1.9275 - val_acc: 0.7318\n",
      "10000/10000 [==============================] - 3s 309us/step\n",
      "Validation loss: 1.92754946593768\n",
      "Validation accuracy (NORMALIZED): 0.7318000001013278\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 3\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 19s 467us/step - loss: 2.1638 - acc: 0.2277 - val_loss: 1.6515 - val_acc: 0.4512\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 17s 433us/step - loss: 1.6439 - acc: 0.4556 - val_loss: 1.3399 - val_acc: 0.5738\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 17s 434us/step - loss: 1.3386 - acc: 0.5736 - val_loss: 1.1498 - val_acc: 0.6270\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 17s 433us/step - loss: 1.1428 - acc: 0.6376 - val_loss: 1.0360 - val_acc: 0.6607\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 17s 433us/step - loss: 1.0191 - acc: 0.6772 - val_loss: 1.0340 - val_acc: 0.6650\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 17s 435us/step - loss: 0.9331 - acc: 0.7040 - val_loss: 0.9295 - val_acc: 0.6889\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 17s 435us/step - loss: 0.8669 - acc: 0.7255 - val_loss: 0.9028 - val_acc: 0.6998\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 17s 436us/step - loss: 0.7997 - acc: 0.7477 - val_loss: 0.9198 - val_acc: 0.7051\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 17s 433us/step - loss: 0.7503 - acc: 0.7590 - val_loss: 0.8484 - val_acc: 0.7194\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.7056 - acc: 0.7725 - val_loss: 0.8589 - val_acc: 0.7188\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.6641 - acc: 0.7862 - val_loss: 0.8741 - val_acc: 0.7285\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.6253 - acc: 0.7964 - val_loss: 0.9011 - val_acc: 0.7220\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.5872 - acc: 0.8107 - val_loss: 0.8821 - val_acc: 0.7278\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.5520 - acc: 0.8198 - val_loss: 0.8954 - val_acc: 0.7320\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.5222 - acc: 0.8286 - val_loss: 0.8931 - val_acc: 0.7336\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.4894 - acc: 0.8399 - val_loss: 0.8995 - val_acc: 0.7325\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.4629 - acc: 0.8481 - val_loss: 0.9351 - val_acc: 0.7368\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.4324 - acc: 0.8567 - val_loss: 0.9632 - val_acc: 0.7293\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.4087 - acc: 0.8649 - val_loss: 0.9760 - val_acc: 0.7356\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.3824 - acc: 0.8730 - val_loss: 1.0148 - val_acc: 0.7363\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.3601 - acc: 0.8795 - val_loss: 1.0462 - val_acc: 0.7354\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.3416 - acc: 0.8863 - val_loss: 1.0668 - val_acc: 0.7355\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.3186 - acc: 0.8935 - val_loss: 1.1272 - val_acc: 0.7303\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.3008 - acc: 0.8982 - val_loss: 1.1849 - val_acc: 0.7321\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.2875 - acc: 0.9047 - val_loss: 1.1677 - val_acc: 0.7315\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.2713 - acc: 0.9089 - val_loss: 1.1893 - val_acc: 0.7231\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.2636 - acc: 0.9129 - val_loss: 1.2342 - val_acc: 0.7204\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.2459 - acc: 0.9191 - val_loss: 1.2784 - val_acc: 0.7288\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.2371 - acc: 0.9211 - val_loss: 1.3166 - val_acc: 0.7219\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.2224 - acc: 0.9263 - val_loss: 1.2276 - val_acc: 0.7354\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.2129 - acc: 0.9302 - val_loss: 1.3192 - val_acc: 0.7258\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.1990 - acc: 0.9343 - val_loss: 1.3820 - val_acc: 0.7345\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.2003 - acc: 0.9349 - val_loss: 1.3377 - val_acc: 0.7351\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.1860 - acc: 0.9390 - val_loss: 1.4263 - val_acc: 0.7297\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1751 - acc: 0.9425 - val_loss: 1.4200 - val_acc: 0.7351\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1698 - acc: 0.9461 - val_loss: 1.4025 - val_acc: 0.7307\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.1667 - acc: 0.9461 - val_loss: 1.4791 - val_acc: 0.7322\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 17s 437us/step - loss: 0.1708 - acc: 0.9467 - val_loss: 1.4051 - val_acc: 0.7309\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1482 - acc: 0.9528 - val_loss: 1.4105 - val_acc: 0.7281\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 17s 436us/step - loss: 0.1446 - acc: 0.9544 - val_loss: 1.3872 - val_acc: 0.7269\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.1424 - acc: 0.9545 - val_loss: 1.5730 - val_acc: 0.7314\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.1364 - acc: 0.9574 - val_loss: 1.5947 - val_acc: 0.7259\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1355 - acc: 0.9581 - val_loss: 1.5488 - val_acc: 0.7358\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 17s 437us/step - loss: 0.1253 - acc: 0.9601 - val_loss: 1.7560 - val_acc: 0.7269\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1244 - acc: 0.9607 - val_loss: 1.5583 - val_acc: 0.7285\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.1211 - acc: 0.9619 - val_loss: 1.6974 - val_acc: 0.7336\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1240 - acc: 0.9616 - val_loss: 1.4698 - val_acc: 0.7319\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1128 - acc: 0.9638 - val_loss: 1.6934 - val_acc: 0.7314\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.1155 - acc: 0.9635 - val_loss: 1.6849 - val_acc: 0.7257\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1025 - acc: 0.9683 - val_loss: 1.7454 - val_acc: 0.7322\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1070 - acc: 0.9670 - val_loss: 1.7227 - val_acc: 0.7243\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.1047 - acc: 0.9676 - val_loss: 1.5979 - val_acc: 0.7340\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.1021 - acc: 0.9678 - val_loss: 1.7526 - val_acc: 0.7314\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0958 - acc: 0.9700 - val_loss: 1.8846 - val_acc: 0.7265\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0978 - acc: 0.9697 - val_loss: 1.7633 - val_acc: 0.7273\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0965 - acc: 0.9701 - val_loss: 1.7165 - val_acc: 0.7325\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.0959 - acc: 0.9706 - val_loss: 1.7286 - val_acc: 0.7344\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0880 - acc: 0.9719 - val_loss: 1.7462 - val_acc: 0.7222\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 17s 437us/step - loss: 0.0885 - acc: 0.9726 - val_loss: 1.7812 - val_acc: 0.7293\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0963 - acc: 0.9707 - val_loss: 1.8383 - val_acc: 0.7248\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0865 - acc: 0.9732 - val_loss: 1.7634 - val_acc: 0.7311\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0820 - acc: 0.9749 - val_loss: 1.7277 - val_acc: 0.7264\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0822 - acc: 0.9742 - val_loss: 1.8172 - val_acc: 0.7336\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0786 - acc: 0.9752 - val_loss: 1.8162 - val_acc: 0.7249\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0816 - acc: 0.9754 - val_loss: 1.8454 - val_acc: 0.7286\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0770 - acc: 0.9765 - val_loss: 1.8407 - val_acc: 0.7332\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0786 - acc: 0.9761 - val_loss: 1.7757 - val_acc: 0.7307\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.0689 - acc: 0.9797 - val_loss: 1.9284 - val_acc: 0.7307\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0806 - acc: 0.9749 - val_loss: 1.7913 - val_acc: 0.7372\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0750 - acc: 0.9770 - val_loss: 1.8306 - val_acc: 0.7321\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0701 - acc: 0.9779 - val_loss: 1.8758 - val_acc: 0.7253\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0732 - acc: 0.9772 - val_loss: 1.9868 - val_acc: 0.7329\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0733 - acc: 0.9772 - val_loss: 1.8852 - val_acc: 0.7319\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0676 - acc: 0.9786 - val_loss: 2.0476 - val_acc: 0.7371\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0698 - acc: 0.9790 - val_loss: 1.8882 - val_acc: 0.7280\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0573 - acc: 0.9823 - val_loss: 2.0242 - val_acc: 0.7305\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0778 - acc: 0.9771 - val_loss: 1.8215 - val_acc: 0.7261\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0679 - acc: 0.9794 - val_loss: 1.8666 - val_acc: 0.7323\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0582 - acc: 0.9819 - val_loss: 2.0028 - val_acc: 0.7284\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0691 - acc: 0.9791 - val_loss: 1.8000 - val_acc: 0.7260\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 18s 440us/step - loss: 0.0621 - acc: 0.9812 - val_loss: 1.9235 - val_acc: 0.7295\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0579 - acc: 0.9823 - val_loss: 1.9772 - val_acc: 0.7340\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0602 - acc: 0.9819 - val_loss: 1.9016 - val_acc: 0.7324\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0605 - acc: 0.9808 - val_loss: 2.0129 - val_acc: 0.7372\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 18s 442us/step - loss: 0.0687 - acc: 0.9791 - val_loss: 2.0337 - val_acc: 0.7347\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.0585 - acc: 0.9824 - val_loss: 1.9540 - val_acc: 0.7232\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 18s 441us/step - loss: 0.0650 - acc: 0.9805 - val_loss: 1.9085 - val_acc: 0.7307\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.0554 - acc: 0.9835 - val_loss: 2.0160 - val_acc: 0.7350\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0622 - acc: 0.9817 - val_loss: 1.9302 - val_acc: 0.7309\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0574 - acc: 0.9822 - val_loss: 1.9328 - val_acc: 0.7364\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0592 - acc: 0.9814 - val_loss: 2.0140 - val_acc: 0.7146\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.0527 - acc: 0.9836 - val_loss: 2.0093 - val_acc: 0.7337\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 17s 437us/step - loss: 0.0608 - acc: 0.9809 - val_loss: 1.9340 - val_acc: 0.7398\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.0485 - acc: 0.9847 - val_loss: 1.8981 - val_acc: 0.7331\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 18s 439us/step - loss: 0.0555 - acc: 0.9829 - val_loss: 2.0206 - val_acc: 0.7358\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 17s 436us/step - loss: 0.0563 - acc: 0.9830 - val_loss: 1.9973 - val_acc: 0.7347\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.0575 - acc: 0.9840 - val_loss: 1.8833 - val_acc: 0.7352\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 17s 436us/step - loss: 0.0492 - acc: 0.9849 - val_loss: 1.7923 - val_acc: 0.7451\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 17s 437us/step - loss: 0.0516 - acc: 0.9843 - val_loss: 1.8095 - val_acc: 0.7356\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 18s 438us/step - loss: 0.0544 - acc: 0.9833 - val_loss: 1.9276 - val_acc: 0.7388\n",
      "10000/10000 [==============================] - 3s 323us/step\n",
      "Validation loss: 1.9275811698712715\n",
      "Validation accuracy (NORMALIZED): 0.7387999992370605\n",
      "--- Compiling model\n",
      "================================================\n",
      "Split: 4\n",
      "Number of Epochs: 100\n",
      "Train shape: (40000, 32, 32, 3)\n",
      "Train batch size: 32\n",
      "Val batch size: 10\n",
      "================================================\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 19s 482us/step - loss: 2.1688 - acc: 0.2294 - val_loss: 1.6440 - val_acc: 0.4409\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 1.6280 - acc: 0.4312 - val_loss: 1.3017 - val_acc: 0.5541\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 1.3619 - acc: 0.5355 - val_loss: 1.1406 - val_acc: 0.6116\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 1.1879 - acc: 0.6050 - val_loss: 1.0699 - val_acc: 0.6437\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 1.0527 - acc: 0.6555 - val_loss: 1.0251 - val_acc: 0.6677\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.9533 - acc: 0.6914 - val_loss: 0.9315 - val_acc: 0.6976\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.8782 - acc: 0.7176 - val_loss: 0.8944 - val_acc: 0.7047\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.8046 - acc: 0.7408 - val_loss: 0.8962 - val_acc: 0.7126\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.7543 - acc: 0.7554 - val_loss: 0.8904 - val_acc: 0.7126\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.7064 - acc: 0.7705 - val_loss: 0.8973 - val_acc: 0.7196\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.6642 - acc: 0.7827 - val_loss: 0.8646 - val_acc: 0.7251\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.6136 - acc: 0.7960 - val_loss: 0.8852 - val_acc: 0.7308\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.5855 - acc: 0.8064 - val_loss: 0.9437 - val_acc: 0.7274\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.5485 - acc: 0.8190 - val_loss: 0.9372 - val_acc: 0.7304\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.5134 - acc: 0.8275 - val_loss: 0.9182 - val_acc: 0.7317\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.4839 - acc: 0.8388 - val_loss: 0.9305 - val_acc: 0.7342\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.4551 - acc: 0.8457 - val_loss: 0.9280 - val_acc: 0.7335\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.4219 - acc: 0.8574 - val_loss: 0.9849 - val_acc: 0.7314\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.3998 - acc: 0.8651 - val_loss: 1.0418 - val_acc: 0.7280\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.3826 - acc: 0.8711 - val_loss: 1.0732 - val_acc: 0.7346\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.3578 - acc: 0.8793 - val_loss: 1.1806 - val_acc: 0.7228\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.3343 - acc: 0.8867 - val_loss: 1.0885 - val_acc: 0.7357\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.3145 - acc: 0.8935 - val_loss: 1.1509 - val_acc: 0.7337\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.3023 - acc: 0.8979 - val_loss: 1.1436 - val_acc: 0.7363\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.2822 - acc: 0.9055 - val_loss: 1.2125 - val_acc: 0.7330\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.2732 - acc: 0.9072 - val_loss: 1.2805 - val_acc: 0.7195\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.2553 - acc: 0.9146 - val_loss: 1.3632 - val_acc: 0.7327\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.2495 - acc: 0.9162 - val_loss: 1.2578 - val_acc: 0.7348\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.2335 - acc: 0.9220 - val_loss: 1.3104 - val_acc: 0.7298\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.2252 - acc: 0.9241 - val_loss: 1.4297 - val_acc: 0.7323\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.2120 - acc: 0.9288 - val_loss: 1.2971 - val_acc: 0.7278\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.2001 - acc: 0.9326 - val_loss: 1.3487 - val_acc: 0.7327\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 18s 454us/step - loss: 0.1924 - acc: 0.9345 - val_loss: 1.4526 - val_acc: 0.7255\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.1749 - acc: 0.9409 - val_loss: 1.6501 - val_acc: 0.7234\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.1796 - acc: 0.9410 - val_loss: 1.4720 - val_acc: 0.7195\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.1663 - acc: 0.9463 - val_loss: 1.5636 - val_acc: 0.7223\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.1744 - acc: 0.9429 - val_loss: 1.5414 - val_acc: 0.7249\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.1508 - acc: 0.9510 - val_loss: 1.6677 - val_acc: 0.7250\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.1509 - acc: 0.9501 - val_loss: 1.5899 - val_acc: 0.7282\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.1448 - acc: 0.9529 - val_loss: 1.6144 - val_acc: 0.7288\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.1367 - acc: 0.9560 - val_loss: 1.5335 - val_acc: 0.7246\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.1362 - acc: 0.9557 - val_loss: 1.6511 - val_acc: 0.7232\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.1316 - acc: 0.9567 - val_loss: 1.7014 - val_acc: 0.7236\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.1228 - acc: 0.9603 - val_loss: 1.7537 - val_acc: 0.7248\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.1226 - acc: 0.9609 - val_loss: 1.6820 - val_acc: 0.7255\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.1251 - acc: 0.9601 - val_loss: 1.7471 - val_acc: 0.7257\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.1135 - acc: 0.9642 - val_loss: 1.6485 - val_acc: 0.7289\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.1157 - acc: 0.9633 - val_loss: 1.7599 - val_acc: 0.7299\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.1084 - acc: 0.9657 - val_loss: 1.7150 - val_acc: 0.7325\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.1077 - acc: 0.9654 - val_loss: 1.6671 - val_acc: 0.7212\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 18s 447us/step - loss: 0.1025 - acc: 0.9681 - val_loss: 1.7779 - val_acc: 0.7295\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.1020 - acc: 0.9673 - val_loss: 1.6893 - val_acc: 0.7306\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.1034 - acc: 0.9680 - val_loss: 1.6468 - val_acc: 0.7325\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0917 - acc: 0.9719 - val_loss: 1.8935 - val_acc: 0.7311\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0942 - acc: 0.9700 - val_loss: 1.8534 - val_acc: 0.7298\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0946 - acc: 0.9710 - val_loss: 1.8390 - val_acc: 0.7271\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0906 - acc: 0.9721 - val_loss: 1.7991 - val_acc: 0.7376\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0905 - acc: 0.9721 - val_loss: 1.8606 - val_acc: 0.7322\n",
      "Epoch 59/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0787 - acc: 0.9753 - val_loss: 2.0518 - val_acc: 0.7297\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0881 - acc: 0.9728 - val_loss: 1.7360 - val_acc: 0.7284\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0810 - acc: 0.9742 - val_loss: 1.9031 - val_acc: 0.7338\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0782 - acc: 0.9750 - val_loss: 1.9178 - val_acc: 0.7271\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0796 - acc: 0.9754 - val_loss: 1.9020 - val_acc: 0.7258\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0782 - acc: 0.9751 - val_loss: 1.8679 - val_acc: 0.7309\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0718 - acc: 0.9772 - val_loss: 1.9490 - val_acc: 0.7284\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.0763 - acc: 0.9770 - val_loss: 1.7974 - val_acc: 0.7258\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.0756 - acc: 0.9771 - val_loss: 1.6989 - val_acc: 0.7289\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0762 - acc: 0.9765 - val_loss: 1.9760 - val_acc: 0.7353\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0714 - acc: 0.9774 - val_loss: 2.0051 - val_acc: 0.7341\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0681 - acc: 0.9788 - val_loss: 1.8782 - val_acc: 0.7291\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 18s 448us/step - loss: 0.0634 - acc: 0.9807 - val_loss: 2.0348 - val_acc: 0.7337\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.0781 - acc: 0.9761 - val_loss: 2.0431 - val_acc: 0.7295\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0640 - acc: 0.9805 - val_loss: 1.8931 - val_acc: 0.7332\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0714 - acc: 0.9785 - val_loss: 1.9611 - val_acc: 0.7271\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0622 - acc: 0.9807 - val_loss: 1.7947 - val_acc: 0.7305\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.0636 - acc: 0.9800 - val_loss: 1.9212 - val_acc: 0.7280\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.0662 - acc: 0.9794 - val_loss: 2.0880 - val_acc: 0.7322\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 0.0577 - acc: 0.9815 - val_loss: 2.0055 - val_acc: 0.7306\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.0645 - acc: 0.9800 - val_loss: 1.8967 - val_acc: 0.7318\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.0655 - acc: 0.9802 - val_loss: 1.8226 - val_acc: 0.7378\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0592 - acc: 0.9818 - val_loss: 1.8231 - val_acc: 0.7351\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.0590 - acc: 0.9818 - val_loss: 2.0392 - val_acc: 0.7274\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.0598 - acc: 0.9815 - val_loss: 2.0159 - val_acc: 0.7350\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.0608 - acc: 0.9813 - val_loss: 1.8528 - val_acc: 0.7364\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.0569 - acc: 0.9827 - val_loss: 1.9389 - val_acc: 0.7373\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.0568 - acc: 0.9825 - val_loss: 2.0977 - val_acc: 0.7381\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0571 - acc: 0.9824 - val_loss: 2.0751 - val_acc: 0.7289\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.0585 - acc: 0.9821 - val_loss: 1.9605 - val_acc: 0.7307\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0520 - acc: 0.9838 - val_loss: 2.0457 - val_acc: 0.7331\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.0547 - acc: 0.9828 - val_loss: 2.0601 - val_acc: 0.7329\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0643 - acc: 0.9801 - val_loss: 1.9840 - val_acc: 0.7380\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 18s 453us/step - loss: 0.0473 - acc: 0.9861 - val_loss: 2.1507 - val_acc: 0.7325\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 18s 454us/step - loss: 0.0569 - acc: 0.9829 - val_loss: 2.0128 - val_acc: 0.7331\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.0553 - acc: 0.9832 - val_loss: 1.9534 - val_acc: 0.7255\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.0553 - acc: 0.9831 - val_loss: 2.1420 - val_acc: 0.7272\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 18s 451us/step - loss: 0.0503 - acc: 0.9849 - val_loss: 2.1368 - val_acc: 0.7289\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 18s 453us/step - loss: 0.0517 - acc: 0.9845 - val_loss: 1.9404 - val_acc: 0.7337\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 18s 450us/step - loss: 0.0545 - acc: 0.9838 - val_loss: 2.0648 - val_acc: 0.7358\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 18s 452us/step - loss: 0.0543 - acc: 0.9837 - val_loss: 1.8230 - val_acc: 0.7309\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 18s 454us/step - loss: 0.0471 - acc: 0.9855 - val_loss: 2.1817 - val_acc: 0.7291\n",
      "10000/10000 [==============================] - 3s 344us/step\n",
      "Validation loss: 2.181651924790132\n",
      "Validation accuracy (NORMALIZED): 0.729099999576807\n",
      "[[1.8517724102961868, 0.7348999998271465], [1.9473785817496638, 0.7414999999403954], [1.92754946593768, 0.7318000001013278], [1.9275811698712715, 0.7387999992370605], [2.181651924790132, 0.729099999576807]]\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "#=====================================\n",
    "# Compile model\n",
    "#=====================================\n",
    "\n",
    "#--- Compile the model\n",
    "# It means to configure the model for training.\n",
    "# Other types of optimizer:\n",
    "#    optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "\n",
    "#=====================================\n",
    "# Tensorboard callback\n",
    "#=====================================\n",
    "\n",
    "print(\"--- Preparing tensorboard\")\n",
    "log_dir = \"logs/{}\".format(time())\n",
    "print(\"Log Dir: \", log_dir)\n",
    "tbCallBack = TensorBoard(log_dir=log_dir, write_graph=True)\n",
    "\n",
    "#=====================================\n",
    "# Training model and Evaluation\n",
    "#=====================================\n",
    "print(\"--- Start training\")\n",
    "y_train_categorical = to_categorical(y_train, num_classes=n_classes)\n",
    "y_val_categorical = to_categorical(y_val, num_classes=n_classes)\n",
    "scores = []\n",
    "#model.save_weights(\"temp.h5\")\n",
    "for i in range(folds):\n",
    "    #--- Evaluating the model for split i\n",
    "    model = get_squeezenet_ft3()\n",
    "    print(\"================================================\")\n",
    "    print(\"Split: \"+str(i))\n",
    "    print(\"Number of Epochs: \"+str(n_epochs))\n",
    "    print(\"Train shape:\",X_train[i].shape)\n",
    "    print(\"Train batch size: \"+str(train_batch_size))\n",
    "    print(\"Val batch size: \"+str(val_batch_size))\n",
    "    #print(\"Optimizer:\", opt)\n",
    "    print(\"================================================\")\n",
    "    # Training with data augmentation\n",
    "    '''\n",
    "    aug.fit(X_train[i])\n",
    "    model.fit_generator(aug.flow(X_train[i],y_train_categorical[i], batch_size=train_batch_size),\n",
    "                        steps_per_epoch=X_train.shape[1]//train_batch_size,\n",
    "                        epochs=n_epochs, \n",
    "                        verbose=1,\n",
    "                        callbacks=[tbCallBack])\n",
    "    '''\n",
    "    # Training without data augmentation\n",
    "    model.fit(X_train[i],y_train_categorical[i], batch_size=train_batch_size,\n",
    "              epochs=n_epochs, \n",
    "              validation_data=(X_val[i],y_val_categorical[i]),              \n",
    "              verbose=1,\n",
    "              callbacks=[tbCallBack])\n",
    "    #--- Evaluating the model for split i\n",
    "    score = model.evaluate(x=X_val[i], y=y_val_categorical[i], batch_size=val_batch_size, verbose=1)\n",
    "    scores.append(score)\n",
    "    print('Validation loss:', score[0])\n",
    "    print('Validation accuracy (NORMALIZED):', score[1])\n",
    "#     model.load_weights(\"temp.h5\")\n",
    "    \n",
    "    \n",
    "#--- Showing scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation loss: 1.967186710528987\n",
      "Mean Validation accuracy (NORMALIZED): 0.7352199997365474\n"
     ]
    }
   ],
   "source": [
    "#=====================================\n",
    "# Evaluate on validation\n",
    "#=====================================\n",
    "\n",
    "#--- The evaluation of the model \n",
    "np_aux = np.array(scores).mean(axis=0)\n",
    "\n",
    "print('Mean Validation loss:', np_aux[0])\n",
    "print('Mean Validation accuracy (NORMALIZED):', np_aux[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your best model on test\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "Now that we are working on more complex tasks and our trainings are starting to take more time it is usually a good idea to save the trained model from time to time. [Keras has a lot of ways of saving and loading the model](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model), but in this exercise we will use the simplest of them all: `model.save()`. It saves the architecture, the weights, the choice of loss function/optimizer/metrics and even the current state of the training, so you can resume your training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a model\n",
    "Once we have our model trained, we can load it using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.181651924790132\n",
      "Test accuracy (NORMALIZED): 0.729099999576807\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "del model  # Will delete model, only to check if load_model is working\n",
    "\n",
    "# returns a compiled model identical to the previous one\n",
    "model = load_model('my_model.h5')\n",
    "\n",
    "# evaluate test set again... should give us the same result\n",
    "# ...\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy (NORMALIZED):', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
